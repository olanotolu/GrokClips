<!DOCTYPE html><html lang="en" class="bg-surface-base antialiased"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, interactive-widget=resizes-content"/><link rel="stylesheet" href="/_next/static/css/62c4caba71dfda84.css" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/eb3d87f98fe1565f.css" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1b5e561215938d4d.css" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/0227d069a630d414.css" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/f87fff2ab93d05a7.css" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5" href="/_next/static/chunks/webpack-e121ed42680f327e.js"/><script src="/_next/static/chunks/78a669d9-e7993486b22c4915.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/40c4a5a7-abdabb07419d1cfc.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/2230-f7c87dc9fa57c408.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/main-app-536d4b8fca62396a.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/63f0ec43-8ee6a76d70472249.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/7670-7326298c9856172b.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/282-691fffb366e24ca5.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/7515-336759ef5dad2b52.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/927-34e2a6da3e15e26b.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/5855-243eeca8f0e4cabd.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/4393-1c8dff25ec904469.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/2225-454cf9f44775e7ce.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/7618-43536a8fb0dd3bfe.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/app/page/%5Bslug%5D/layout-55a344716dd57c44.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/7720-3a1e7e411adba2d3.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/7086-1f1c4891d766e04f.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/app/page/%5Bslug%5D/not-found-69a3edc7db5749d6.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/app/global-error-4d07d20223cd4b4c.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/8208b75a-a48e5a4507a0de91.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/5497-ab85ef3ea59dd353.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/6281-c6e84786dade3614.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/2660-d983a7f287e89f18.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/5002-9735c25beda556ba.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/3655-6717081f7512305a.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/8945-e4e3cf487f5e27c7.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/9214-a10614844a67ba31.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/4789-2080f6497f78b5b6.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/app/layout-226f2bd71acf9f9e.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/24cf1b50-159cca90b09285e0.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/9ffa21ba-c069766d809bd4c7.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/600-9a9fcafaaa6c1c4c.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/5448-2a3cfd853d899c9a.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/8-8ca70ca619d8e099.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/app/error-4a29e9399afba038.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><script src="/_next/static/chunks/app/not-found-dd95690acf732f18.js" async="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script><meta name="next-size-adjust" content=""/><title>Grokipedia</title><meta name="description" content="Grokipedia is an open source, comprehensive collection of all knowledge."/><link rel="icon" type="image/x-icon" href="/favicon.ico" sizes="48x48"/><link rel="icon" href="/images/icon-dark.png" media="(prefers-color-scheme: light)" type="image/png"/><link rel="icon" href="/images/icon-light.png" media="(prefers-color-scheme: dark)" type="image/png"/><link rel="apple-touch-icon" href="/icon-192x192.png"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-snippet:-1"/><meta property="og:title" content="Grokipedia"/><meta property="og:description" content="Grokipedia is an open source, comprehensive collection of all knowledge."/><meta property="og:url" content="https://grokipedia.com"/><meta property="og:site_name" content="Grokipedia"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta property="og:image" content="https://grokipedia.com/icon-512x512.png"/><meta property="og:image:width" content="512"/><meta property="og:image:height" content="512"/><meta property="og:image:alt" content="Grokipedia"/><meta name="twitter:card" content="summary"/><meta name="twitter:creator" content="@Grokipedia"/><meta name="twitter:title" content="Grokipedia"/><meta name="twitter:description" content="Grokipedia is an open source, comprehensive collection of all knowledge."/><meta name="twitter:image" content="https://grokipedia.com/icon-512x512.png"/><title>LessWrong</title><meta name="description" content="LessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action. It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as The Sequences, originally developed on the predecessor blog Overcoming Bias...."/><meta name="author" content="system"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="keywords" content="LW, Less Wrong"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-snippet:-1"/><link rel="canonical" href="https://grokipedia.com/page/LessWrong"/><meta property="og:title" content="LessWrong"/><meta property="og:description" content="LessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action. It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as The Sequences, originally developed on the predecessor blog Overcoming Bias...."/><meta property="og:url" content="https://grokipedia.com/page/LessWrong"/><meta property="og:site_name" content="Grokipedia"/><meta property="og:locale" content="en"/><meta property="og:image" content="https://grokipedia.com/icon-512x512.png"/><meta property="og:image:width" content="512"/><meta property="og:image:height" content="512"/><meta property="og:image:alt" content="LessWrong"/><meta property="og:type" content="article"/><meta property="article:modified_time" content="1970-01-21T09:19:43.867Z"/><meta name="twitter:card" content="summary"/><meta name="twitter:creator" content="@Grokipedia"/><meta name="twitter:title" content="LessWrong"/><meta name="twitter:description" content="LessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action. It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as The Sequences, originally developed on the predecessor blog Overcoming Bias...."/><meta name="twitter:image" content="https://grokipedia.com/icon-512x512.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="sentry-trace" content="fb15c7ff105f3efad8f44467c450f019-eca485c02d517332-1"/><meta name="baggage" content="sentry-environment=production,sentry-public_key=5f2258f71198ee26a355127af230c3a6,sentry-trace_id=fb15c7ff105f3efad8f44467c450f019,sentry-org_id=4508179396558848,sentry-transaction=GET%20%2Fpage%2F%5Bslug%5D,sentry-sampled=true,sentry-sample_rand=0.7263644511544904,sentry-sample_rate=1"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule="" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5"></script></head><body class="flex h-[100svh] w-full flex-col __variable_13c637 __variable_8a0ba0 __variable_779740 __variable_2484fd __variable_525cc3 __variable_13486b"><div hidden=""><!--$--><!--/$--></div><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","dark",null,["light","dark"],null,true,true)</script><header class="h-16 bg-surface-base fixed top-0 z-50 w-full"><div class="hidden h-full grid-cols-[1fr_3fr_1fr] items-center gap-4 !py-0 md:grid max-w-full py-6 px-4 w-full mx-auto"><div class="-ml-2 justify-self-start"><a class="cursor-pointer" href="/"><svg width="200" height="auto" viewBox="0 0 955 225" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M99.6937 159.214C90.008 159.214 81.5652 157.414 74.3652 153.814C67.1652 150.214 61.5509 144.986 57.5223 138.129C53.5794 131.271 51.608 123.043 51.608 113.443C51.608 103.843 53.5794 95.4857 57.5223 88.3714C61.5509 81.2572 67.1652 75.7286 74.3652 71.7857C81.6509 67.8429 90.1794 65.8714 99.9509 65.8714C103.208 65.8714 106.679 66.1286 110.365 66.6429C114.051 67.0714 117.222 67.6714 119.879 68.4429C121.508 68.8714 123.008 69.2572 124.379 69.6C125.751 69.9429 127.122 70.1143 128.494 70.1143C129.522 70.1143 130.551 69.9857 131.579 69.7286C131.751 73.5 131.922 77.4 132.094 81.4286C132.265 85.4572 132.522 89.6572 132.865 94.0286C131.065 94.2857 129.565 94.3714 128.365 94.2857C126.651 86.4 123.522 80.5714 118.979 76.8C114.437 72.9429 108.394 71.0143 100.851 71.0143C94.8509 71.0143 89.708 72.1286 85.4223 74.3572C81.2223 76.5 77.7937 79.4572 75.1366 83.2286C72.5652 87 70.6794 91.3714 69.4794 96.3429C68.2794 101.229 67.6794 106.457 67.6794 112.029C67.6794 120.171 68.9223 127.371 71.408 133.629C73.8937 139.886 77.6652 144.814 82.7223 148.414C87.8652 151.929 94.2937 153.686 102.008 153.686C104.408 153.686 107.065 153.471 109.979 153.043C112.894 152.529 115.679 151.757 118.337 150.729V134.529C118.337 131.871 118.208 129.814 117.951 128.357C117.779 126.814 117.222 125.7 116.279 125.014C115.422 124.329 114.008 123.857 112.037 123.6C110.151 123.257 107.537 122.957 104.194 122.7C103.937 121.329 103.937 119.957 104.194 118.586C105.994 118.586 108.179 118.629 110.751 118.714C113.322 118.714 115.894 118.757 118.465 118.843C121.122 118.843 123.308 118.843 125.022 118.843C127.679 118.843 130.722 118.8 134.151 118.714C137.665 118.629 140.665 118.586 143.151 118.586C143.322 119.871 143.322 121.2 143.151 122.571C139.637 123 137.108 123.429 135.565 123.857C134.022 124.286 133.079 125.143 132.737 126.429C132.394 127.714 132.222 129.9 132.222 132.986V137.1C132.222 141.129 132.308 144.514 132.479 147.257C132.737 150 132.951 151.971 133.122 153.171C121.208 157.2 110.065 159.214 99.6937 159.214ZM148.19 157.414C147.933 156.043 147.933 154.714 148.19 153.429C151.105 153.257 153.248 153 154.619 152.657C155.99 152.229 156.89 151.371 157.319 150.086C157.748 148.8 157.962 146.743 157.962 143.914V115.114C157.962 111.771 157.79 109.286 157.448 107.657C157.19 106.029 156.376 104.914 155.005 104.314C153.719 103.629 151.49 103.071 148.319 102.643C148.062 101.443 148.062 100.329 148.319 99.3C151.748 98.6143 155.09 97.8429 158.348 96.9857C161.605 96.0429 165.033 94.8429 168.633 93.3857L170.819 94.1572V105.471C176.819 97.8429 182.948 94.0286 189.205 94.0286C192.205 94.0286 194.433 94.8429 195.89 96.4714C197.348 98.0143 198.076 99.7714 198.076 101.743C198.076 104.057 197.305 105.857 195.762 107.143C194.219 108.343 192.462 108.943 190.49 108.943C188.862 108.943 187.233 108.514 185.605 107.657C184.062 106.8 182.905 105.471 182.133 103.671C179.219 103.671 176.605 104.829 174.29 107.143C172.062 109.371 170.948 111.986 170.948 114.986V142.629C170.948 145.971 171.119 148.371 171.462 149.829C171.89 151.286 172.919 152.229 174.548 152.657C176.262 153 179.005 153.257 182.776 153.429C182.948 154.629 182.948 155.957 182.776 157.414C179.862 157.414 176.862 157.371 173.776 157.286C170.69 157.2 167.519 157.157 164.262 157.157C161.09 157.157 158.262 157.2 155.776 157.286C153.376 157.371 150.848 157.414 148.19 157.414ZM229.285 158.829C223.028 158.829 217.542 157.5 212.828 154.843C208.199 152.1 204.599 148.371 202.028 143.657C199.457 138.857 198.171 133.371 198.171 127.2C198.171 120.514 199.499 114.686 202.157 109.714C204.899 104.743 208.714 100.886 213.599 98.1429C218.485 95.4 224.099 94.0286 230.442 94.0286C236.699 94.0286 242.142 95.4 246.771 98.1429C251.399 100.886 254.999 104.657 257.571 109.457C260.142 114.257 261.428 119.7 261.428 125.786C261.428 132.043 260.057 137.7 257.314 142.757C254.657 147.729 250.928 151.671 246.128 154.586C241.328 157.414 235.714 158.829 229.285 158.829ZM212.699 125.657C212.699 134.4 214.114 141.343 216.942 146.486C219.857 151.543 224.185 154.071 229.928 154.071C235.414 154.071 239.614 151.671 242.528 146.871C245.442 141.986 246.899 135.471 246.899 127.329C246.899 118.671 245.442 111.771 242.528 106.629C239.614 101.486 235.371 98.9143 229.799 98.9143C224.314 98.9143 220.071 101.271 217.071 105.986C214.157 110.7 212.699 117.257 212.699 125.657ZM267.394 157.414C267.308 157.071 267.265 156.729 267.265 156.386C267.265 156.043 267.265 155.7 267.265 155.357C267.265 155.014 267.265 154.714 267.265 154.457C267.265 154.114 267.308 153.771 267.394 153.429C270.308 153.257 272.451 153 273.822 152.657C275.194 152.229 276.094 151.371 276.522 150.086C276.951 148.8 277.165 146.743 277.165 143.914V79.5C277.165 76.8429 276.908 74.8714 276.394 73.5857C275.965 72.2143 274.979 71.2714 273.437 70.7572C271.979 70.1572 269.751 69.7286 266.751 69.4714C266.665 69.1286 266.622 68.8286 266.622 68.5714C266.622 68.3143 266.622 68.0572 266.622 67.8C266.622 67.4572 266.622 67.1572 266.622 66.9C266.622 66.6429 266.665 66.3429 266.751 66C270.179 65.5714 273.694 64.9286 277.294 64.0714C280.894 63.1286 284.579 61.8429 288.351 60.2143L290.537 60.9857C290.451 62.8714 290.365 65.0143 290.279 67.4143C290.279 69.8143 290.279 72.4286 290.279 75.2572V122.957C291.308 122.957 292.165 122.786 292.851 122.443C293.537 122.1 294.094 121.757 294.522 121.414C294.694 121.243 295.037 120.943 295.551 120.514C296.065 120 296.965 119.1 298.251 117.814C299.537 116.529 301.379 114.6 303.779 112.029C306.008 109.543 307.765 107.614 309.051 106.243C310.422 104.786 311.108 103.586 311.108 102.643C311.108 101.957 310.508 101.4 309.308 100.971C308.194 100.457 306.651 100.157 304.679 100.071C304.594 99.7286 304.551 99.3857 304.551 99.0429C304.551 98.7 304.551 98.3572 304.551 98.0143C304.551 97.6714 304.551 97.3286 304.551 96.9857C304.551 96.6429 304.594 96.3 304.679 95.9572C306.394 95.9572 308.537 96 311.108 96.0857C313.765 96.1714 316.122 96.2143 318.179 96.2143C319.208 96.2143 320.665 96.2143 322.551 96.2143C324.522 96.1286 326.494 96.0857 328.465 96.0857C330.437 96.0857 331.894 96.0857 332.837 96.0857C332.922 96.4286 332.965 96.7714 332.965 97.1143C333.051 97.4572 333.094 97.8 333.094 98.1429C333.094 98.4857 333.051 98.8286 332.965 99.1714C332.965 99.4286 332.922 99.7286 332.837 100.071C328.379 100.157 324.608 101.271 321.522 103.414C318.437 105.471 315.479 107.914 312.651 110.743L303.394 120L321.137 143.4C323.022 145.886 324.565 147.857 325.765 149.314C327.051 150.686 328.422 151.671 329.879 152.271C331.337 152.871 333.351 153.257 335.922 153.429C336.094 154.629 336.094 155.957 335.922 157.414C334.808 157.414 333.137 157.371 330.908 157.286C328.765 157.2 325.379 157.157 320.751 157.157C320.065 157.157 319.037 157.157 317.665 157.157C316.294 157.157 315.008 157.243 313.808 157.414C313.808 156.471 313.294 155.186 312.265 153.557C311.237 151.843 310.422 150.6 309.822 149.829C309.565 149.4 308.922 148.5 307.894 147.129C306.865 145.671 305.622 144 304.165 142.114C302.794 140.143 301.379 138.171 299.922 136.2C298.465 134.143 297.137 132.343 295.937 130.8C294.994 129.514 294.094 128.529 293.237 127.843C292.465 127.071 291.479 126.686 290.279 126.686V142.629C290.279 145.971 290.408 148.371 290.665 149.829C291.008 151.286 291.737 152.229 292.851 152.657C294.051 153 295.851 153.257 298.251 153.429C298.422 154.714 298.422 156.043 298.251 157.414C296.022 157.414 293.665 157.371 291.179 157.286C288.779 157.2 286.165 157.157 283.337 157.157C280.594 157.157 277.894 157.2 275.237 157.286C272.579 157.371 269.965 157.414 267.394 157.414ZM369.34 157.414C366.94 157.414 364.454 157.371 361.883 157.286C359.311 157.2 356.526 157.157 353.526 157.157C350.783 157.157 347.997 157.2 345.169 157.286C342.426 157.371 339.769 157.414 337.197 157.414C336.94 156.043 336.94 154.714 337.197 153.429C340.111 153.257 342.254 153 343.626 152.657C344.997 152.229 345.897 151.371 346.326 150.086C346.754 148.8 346.969 146.743 346.969 143.914V115.114C346.969 111.771 346.84 109.286 346.583 107.657C346.326 106.029 345.511 104.914 344.14 104.314C342.854 103.629 340.583 103.071 337.326 102.643C337.069 101.443 337.069 100.329 337.326 99.3C341.097 98.6143 344.697 97.7572 348.126 96.7286C351.554 95.7 354.854 94.5857 358.026 93.3857L360.211 94.1572C360.126 96.8143 360.04 99.3 359.954 101.614C359.954 103.929 359.954 106.114 359.954 108.171V142.629C359.954 145.971 360.126 148.371 360.469 149.829C360.897 151.286 361.754 152.229 363.04 152.657C364.411 153 366.511 153.257 369.34 153.429C369.597 154.714 369.597 156.043 369.34 157.414ZM343.626 71.5286C343.626 69.0429 344.483 66.9429 346.197 65.2286C347.997 63.5143 350.14 62.6572 352.626 62.6572C355.026 62.6572 357.083 63.5143 358.797 65.2286C360.597 66.9429 361.497 69 361.497 71.4C361.497 73.6286 360.64 75.6857 358.926 77.5715C357.211 79.3714 355.026 80.2714 352.369 80.2714C349.969 80.2714 347.911 79.4143 346.197 77.7C344.483 75.9857 343.626 73.9286 343.626 71.5286ZM372.678 188.914C372.592 187.543 372.592 186.214 372.678 184.929C375.678 184.757 377.864 184.457 379.235 184.029C380.607 183.6 381.464 182.743 381.807 181.457C382.235 180.257 382.45 178.286 382.45 175.543V115.114C382.45 111.771 382.278 109.286 381.935 107.657C381.678 106.029 380.864 104.914 379.492 104.314C378.207 103.629 375.978 103.071 372.807 102.643C372.635 101.443 372.635 100.329 372.807 99.3C376.321 98.6143 379.75 97.8 383.092 96.8572C386.435 95.9143 389.907 94.7572 393.507 93.3857L395.307 94.2857C395.221 96.4286 395.178 98.2714 395.178 99.8143C395.178 101.271 395.178 102.686 395.178 104.057C398.521 100.543 401.821 98.0143 405.078 96.4714C408.335 94.8429 411.807 94.0286 415.492 94.0286C420.892 94.0286 425.435 95.4429 429.121 98.2714C432.892 101.1 435.764 104.786 437.735 109.329C439.707 113.871 440.692 118.8 440.692 124.114C440.692 130.371 439.321 136.157 436.578 141.471C433.921 146.7 430.192 150.9 425.392 154.071C420.592 157.243 415.021 158.829 408.678 158.829C406.192 158.829 403.835 158.614 401.607 158.186C399.378 157.843 397.278 157.329 395.307 156.643V174C395.307 177.343 395.564 179.743 396.078 181.2C396.592 182.657 397.707 183.557 399.421 183.9C401.135 184.329 403.835 184.629 407.521 184.8C407.607 186.171 407.607 187.543 407.521 188.914C404.607 188.914 401.65 188.871 398.65 188.786C395.735 188.7 392.521 188.657 389.007 188.657C385.664 188.657 382.792 188.7 380.392 188.786C377.992 188.871 375.421 188.914 372.678 188.914ZM395.178 146.1C398.864 151.414 403.75 154.071 409.835 154.071C414.121 154.071 417.507 152.871 419.992 150.471C422.564 148.071 424.407 144.943 425.521 141.086C426.721 137.229 427.321 133.157 427.321 128.871C427.321 124.586 426.764 120.386 425.65 116.271C424.535 112.157 422.692 108.771 420.121 106.114C417.635 103.371 414.207 102 409.835 102C404.607 102 399.721 104.529 395.178 109.586V146.1ZM477.335 158.829C471.25 158.829 466.107 157.414 461.907 154.586C457.707 151.757 454.493 147.986 452.264 143.271C450.121 138.471 449.05 133.2 449.05 127.457C449.05 121.543 450.164 116.057 452.393 111C454.707 105.943 458.05 101.871 462.421 98.7857C466.793 95.6143 472.107 94.0286 478.364 94.0286C485.907 94.0286 491.778 96.3 495.978 100.843C500.264 105.3 502.407 111.086 502.407 118.2C502.407 119.057 502.364 119.829 502.278 120.514C502.278 121.114 502.235 121.629 502.15 122.057L461.65 121.671C461.65 122.014 461.65 122.314 461.65 122.571C461.65 130.971 463.578 137.571 467.435 142.371C471.293 147.171 476.693 149.571 483.635 149.571C489.464 149.571 495.207 147.686 500.864 143.914C501.721 144.943 502.364 145.929 502.793 146.871C495.507 154.843 487.021 158.829 477.335 158.829ZM462.035 116.914L488.65 116.4C488.735 116.229 488.778 116.014 488.778 115.757C488.778 115.414 488.778 115.2 488.778 115.114C488.778 110.486 487.75 106.629 485.693 103.543C483.721 100.457 480.764 98.9143 476.821 98.9143C473.135 98.9143 469.921 100.414 467.178 103.414C464.435 106.414 462.721 110.914 462.035 116.914ZM559.644 158.957L557.587 158.057L557.073 149.186C554.073 152.443 550.987 154.886 547.816 156.514C544.73 158.057 541.302 158.829 537.53 158.829C532.216 158.829 527.544 157.414 523.516 154.586C519.573 151.671 516.53 147.9 514.387 143.271C512.244 138.643 511.173 133.629 511.173 128.229C511.173 121.971 512.502 116.271 515.159 111.129C517.902 105.986 521.716 101.871 526.602 98.7857C531.573 95.6143 537.359 94.0286 543.959 94.0286C545.93 94.0286 547.987 94.2 550.13 94.5429C552.273 94.8 554.502 95.2714 556.816 95.9572V79.5C556.816 76.8429 556.559 74.8714 556.044 73.5857C555.53 72.2143 554.502 71.2714 552.959 70.7572C551.502 70.1572 549.273 69.7286 546.273 69.4714C546.016 68.3572 546.016 67.2 546.273 66C549.702 65.5714 553.216 64.9286 556.816 64.0714C560.416 63.1286 564.102 61.8429 567.873 60.2143L570.059 60.9857C569.973 62.8714 569.887 65.0143 569.802 67.4143C569.802 69.8143 569.802 72.4286 569.802 75.2572V139.029C569.802 142.286 569.93 144.729 570.187 146.357C570.445 147.986 571.216 149.143 572.502 149.829C573.787 150.429 575.973 150.986 579.059 151.5C579.316 152.614 579.316 153.771 579.059 154.971C575.63 155.486 572.287 156.043 569.03 156.643C565.773 157.243 562.644 158.014 559.644 158.957ZM556.944 106.886C553.259 101.829 548.416 99.3 542.416 99.3C536.502 99.3 532.044 101.486 529.044 105.857C526.044 110.143 524.544 116.1 524.544 123.729C524.544 128.186 525.144 132.471 526.344 136.586C527.544 140.7 529.516 144.086 532.259 146.743C535.002 149.4 538.644 150.729 543.187 150.729C548.93 150.729 553.516 148.243 556.944 143.271V106.886ZM615.699 157.414C613.299 157.414 610.813 157.371 608.242 157.286C605.67 157.2 602.885 157.157 599.885 157.157C597.142 157.157 594.356 157.2 591.527 157.286C588.785 157.371 586.127 157.414 583.556 157.414C583.299 156.043 583.299 154.714 583.556 153.429C586.47 153.257 588.613 153 589.985 152.657C591.356 152.229 592.256 151.371 592.685 150.086C593.113 148.8 593.327 146.743 593.327 143.914V115.114C593.327 111.771 593.199 109.286 592.942 107.657C592.685 106.029 591.87 104.914 590.499 104.314C589.213 103.629 586.942 103.071 583.685 102.643C583.427 101.443 583.427 100.329 583.685 99.3C587.456 98.6143 591.056 97.7572 594.485 96.7286C597.913 95.7 601.213 94.5857 604.385 93.3857L606.57 94.1572C606.485 96.8143 606.399 99.3 606.313 101.614C606.313 103.929 606.313 106.114 606.313 108.171V142.629C606.313 145.971 606.485 148.371 606.827 149.829C607.256 151.286 608.113 152.229 609.399 152.657C610.77 153 612.87 153.257 615.699 153.429C615.956 154.714 615.956 156.043 615.699 157.414ZM589.985 71.5286C589.985 69.0429 590.842 66.9429 592.556 65.2286C594.356 63.5143 596.499 62.6572 598.985 62.6572C601.385 62.6572 603.442 63.5143 605.156 65.2286C606.956 66.9429 607.856 69 607.856 71.4C607.856 73.6286 606.999 75.6857 605.285 77.5715C603.57 79.3714 601.385 80.2714 598.727 80.2714C596.327 80.2714 594.27 79.4143 592.556 77.7C590.842 75.9857 589.985 73.9286 589.985 71.5286ZM665.837 158.571C660.18 158.571 656.623 155.743 655.165 150.086C649.08 155.914 642.865 158.829 636.523 158.829C632.151 158.829 628.423 157.543 625.337 154.971C622.337 152.314 620.837 148.671 620.837 144.043C620.837 132.729 632.365 125.614 655.423 122.7C655.423 120.643 655.423 118.543 655.423 116.4C655.508 114.257 655.551 111.986 655.551 109.586C655.551 106.586 654.437 104.271 652.208 102.643C650.065 100.929 647.451 100.071 644.365 100.071C642.137 100.071 640.251 100.414 638.708 101.1C638.708 103.071 638.28 105.086 637.423 107.143C636.565 109.2 635.365 110.957 633.823 112.414C632.365 113.786 630.565 114.471 628.423 114.471C626.537 114.471 625.037 113.957 623.923 112.929C622.894 111.814 622.38 110.486 622.38 108.943C622.38 106.886 623.323 104.957 625.208 103.157C627.18 101.271 629.665 99.6857 632.665 98.4C635.665 97.0286 638.794 95.9572 642.051 95.1857C645.308 94.4143 648.223 94.0286 650.794 94.0286C653.965 94.0286 656.88 94.6286 659.537 95.8286C662.28 96.9429 664.465 98.6572 666.094 100.971C667.808 103.2 668.665 105.986 668.665 109.329C668.665 111.386 668.623 114.086 668.537 117.429C668.451 120.686 668.365 124.2 668.28 127.971C668.28 131.657 668.237 135.171 668.151 138.514C668.065 141.857 668.023 144.557 668.023 146.614C668.023 149.357 669.223 150.729 671.623 150.729C673.165 150.729 675.523 150.214 678.694 149.186C679.037 149.614 679.251 150.086 679.337 150.6C679.508 151.114 679.637 151.586 679.723 152.014C677.58 154.329 675.308 156 672.908 157.029C670.594 158.057 668.237 158.571 665.837 158.571ZM655.165 146.614L655.423 127.329C647.537 128.357 642.094 130.029 639.094 132.343C636.18 134.657 634.723 137.614 634.723 141.214C634.723 144.214 635.494 146.529 637.037 148.157C638.665 149.7 640.68 150.471 643.08 150.471C644.623 150.471 646.337 150.129 648.223 149.443C650.194 148.757 652.508 147.814 655.165 146.614Z" fill="currentColor"></path><rect x="715" y="65" width="195" height="105" rx="52.5" fill="currentColor" fill-opacity="0.05"></rect><path d="M767.529 142.875L754.049 107.938H762.552L769.309 127.582C769.705 128.812 770.078 130.032 770.43 131.24C770.781 132.449 771.078 133.559 771.32 134.569H771.616C771.858 133.559 772.144 132.449 772.473 131.24C772.825 130.032 773.198 128.812 773.594 127.582L780.186 107.938H788.689L775.472 142.875H767.529ZM810.856 143.633C806.901 143.633 803.528 142.71 800.737 140.865C797.969 138.997 795.871 136.305 794.442 132.79C793.014 129.252 792.3 124.989 792.3 120.001V118.255C792.3 113.245 793.014 108.982 794.442 105.467C795.871 101.929 797.969 99.2373 800.737 97.3916C803.528 95.5239 806.901 94.5901 810.856 94.5901C814.789 94.5901 818.129 95.5129 820.875 97.3586C823.644 99.2043 825.731 101.907 827.138 105.467C828.566 109.004 829.28 113.267 829.28 118.255V120.001C829.28 124.989 828.577 129.252 827.171 132.79C825.764 136.327 823.677 139.019 820.908 140.865C818.162 142.71 814.811 143.633 810.856 143.633ZM810.889 136.382C813.064 136.382 814.877 135.789 816.327 134.602C817.799 133.416 818.898 131.658 819.623 129.329C820.348 126.978 820.711 124.066 820.711 120.595V117.694C820.711 114.223 820.337 111.311 819.59 108.96C818.865 106.609 817.777 104.84 816.327 103.654C814.877 102.445 813.064 101.841 810.889 101.841C808.714 101.841 806.879 102.434 805.385 103.621C803.912 104.785 802.792 106.554 802.023 108.927C801.276 111.278 800.902 114.201 800.902 117.694V120.595C800.902 124.044 801.287 126.945 802.056 129.296C802.825 131.647 803.945 133.416 805.418 134.602C806.89 135.789 808.714 136.382 810.889 136.382ZM838.988 143.205C838 143.205 837.099 142.985 836.286 142.545C835.495 142.106 834.879 141.491 834.44 140.7C834.001 139.909 833.781 139.019 833.781 138.03C833.781 137.019 834.001 136.118 834.44 135.327C834.879 134.536 835.495 133.921 836.286 133.482C837.099 133.042 838 132.823 838.988 132.823C839.977 132.823 840.867 133.042 841.658 133.482C842.449 133.921 843.064 134.536 843.504 135.327C843.943 136.118 844.163 137.019 844.163 138.03C844.163 139.019 843.943 139.909 843.504 140.7C843.064 141.491 842.449 142.106 841.658 142.545C840.867 142.985 839.977 143.205 838.988 143.205ZM857.365 142.875V104.511L846.39 111.663V103.357L858.453 95.3481H865.802V142.875H857.365Z" fill="currentColor"></path></svg></a></div><div class="mx-auto flex w-full"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 border-input text-primary hover:border-primary/15 border hover:bg-overlay-hover py-2 max-w-full px-3 shadow-none sm:w-80 focus-visible:z-1 mx-auto h-full w-full rounded-full bg-surface-l1" type="button"><div class="flex items-center justify-between sm:w-full gap-4"><div class="flex items-center justify-start gap-2"><span class="inline-flex items-center justify-center p-0 m-0 w-4 h-4 text-muted" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-4 h-4" focusable="false" style="fill:currentColor"><path d="m18.031 16.617 4.283 4.282-1.415 1.415-4.282-4.283A8.96 8.96 0 0 1 11 20c-4.968 0-9-4.032-9-9s4.032-9 9-9 9 4.032 9 9a8.96 8.96 0 0 1-1.969 5.617m-2.006-.742A6.98 6.98 0 0 0 18 11c0-3.867-3.133-7-7-7s-7 3.133-7 7 3.133 7 7 7a6.98 6.98 0 0 0 4.875-1.975z"></path></svg></span><p class="text-sm text-muted hidden sm:block">Search</p></div><span class="hidden sm:block"><div class="bg-foreground/10 text-muted inline-flex items-center rounded-md px-1 py-0.5 text-center font-sans text-xs font-normal tracking-widest rtl:space-x-reverse"><span>âŒ˜</span><span class="text-xs">K</span></div></span></div></button></div><div class="flex items-center gap-2 justify-self-end"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover px-4 py-2 w-9 h-9 flex-shrink-0" type="button" id="radix-_R_7apfiumdb_" aria-haspopup="menu" aria-expanded="false" data-state="closed"><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M12 18a6 6 0 1 1 0-12 6 6 0 0 1 0 12m0-2a4 4 0 1 0 0-8 4 4 0 0 0 0 8M11 1h2v3h-2zm0 19h2v3h-2zM3.515 4.929l1.414-1.414L7.05 5.636 5.636 7.05zM16.95 18.364l1.414-1.414 2.121 2.121-1.414 1.414zm2.121-14.85 1.414 1.415-2.121 2.121-1.414-1.414zM5.636 16.95l1.414 1.414-2.121 2.121-1.414-1.414zM23 11v2h-3v-2zM4 11v2H1v-2z"></path></svg></span><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 absolute rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M10 7a7 7 0 0 0 12 4.9v.1c0 5.523-4.477 10-10 10S2 17.523 2 12 6.477 2 12 2h.1A6.98 6.98 0 0 0 10 7m-6 5a8 8 0 0 0 15.062 3.762A9 9 0 0 1 8.238 4.938 8 8 0 0 0 4 12"></path></svg></span><span class="sr-only">Toggle theme</span></button></div></div><div class="flex h-full items-center md:hidden justify-between max-w-full py-6 px-4 w-full mx-auto pt-8"><div class="flex items-center"><div class="-ml-2"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover h-9 w-9" type="button" aria-label="Toggle table of contents"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-list h-6 w-6"><path d="M3 12h.01"></path><path d="M3 18h.01"></path><path d="M3 6h.01"></path><path d="M8 12h13"></path><path d="M8 18h13"></path><path d="M8 6h13"></path></svg></button></div><a class="cursor-pointer" href="/"><svg width="160" height="auto" viewBox="0 0 955 225" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M99.6937 159.214C90.008 159.214 81.5652 157.414 74.3652 153.814C67.1652 150.214 61.5509 144.986 57.5223 138.129C53.5794 131.271 51.608 123.043 51.608 113.443C51.608 103.843 53.5794 95.4857 57.5223 88.3714C61.5509 81.2572 67.1652 75.7286 74.3652 71.7857C81.6509 67.8429 90.1794 65.8714 99.9509 65.8714C103.208 65.8714 106.679 66.1286 110.365 66.6429C114.051 67.0714 117.222 67.6714 119.879 68.4429C121.508 68.8714 123.008 69.2572 124.379 69.6C125.751 69.9429 127.122 70.1143 128.494 70.1143C129.522 70.1143 130.551 69.9857 131.579 69.7286C131.751 73.5 131.922 77.4 132.094 81.4286C132.265 85.4572 132.522 89.6572 132.865 94.0286C131.065 94.2857 129.565 94.3714 128.365 94.2857C126.651 86.4 123.522 80.5714 118.979 76.8C114.437 72.9429 108.394 71.0143 100.851 71.0143C94.8509 71.0143 89.708 72.1286 85.4223 74.3572C81.2223 76.5 77.7937 79.4572 75.1366 83.2286C72.5652 87 70.6794 91.3714 69.4794 96.3429C68.2794 101.229 67.6794 106.457 67.6794 112.029C67.6794 120.171 68.9223 127.371 71.408 133.629C73.8937 139.886 77.6652 144.814 82.7223 148.414C87.8652 151.929 94.2937 153.686 102.008 153.686C104.408 153.686 107.065 153.471 109.979 153.043C112.894 152.529 115.679 151.757 118.337 150.729V134.529C118.337 131.871 118.208 129.814 117.951 128.357C117.779 126.814 117.222 125.7 116.279 125.014C115.422 124.329 114.008 123.857 112.037 123.6C110.151 123.257 107.537 122.957 104.194 122.7C103.937 121.329 103.937 119.957 104.194 118.586C105.994 118.586 108.179 118.629 110.751 118.714C113.322 118.714 115.894 118.757 118.465 118.843C121.122 118.843 123.308 118.843 125.022 118.843C127.679 118.843 130.722 118.8 134.151 118.714C137.665 118.629 140.665 118.586 143.151 118.586C143.322 119.871 143.322 121.2 143.151 122.571C139.637 123 137.108 123.429 135.565 123.857C134.022 124.286 133.079 125.143 132.737 126.429C132.394 127.714 132.222 129.9 132.222 132.986V137.1C132.222 141.129 132.308 144.514 132.479 147.257C132.737 150 132.951 151.971 133.122 153.171C121.208 157.2 110.065 159.214 99.6937 159.214ZM148.19 157.414C147.933 156.043 147.933 154.714 148.19 153.429C151.105 153.257 153.248 153 154.619 152.657C155.99 152.229 156.89 151.371 157.319 150.086C157.748 148.8 157.962 146.743 157.962 143.914V115.114C157.962 111.771 157.79 109.286 157.448 107.657C157.19 106.029 156.376 104.914 155.005 104.314C153.719 103.629 151.49 103.071 148.319 102.643C148.062 101.443 148.062 100.329 148.319 99.3C151.748 98.6143 155.09 97.8429 158.348 96.9857C161.605 96.0429 165.033 94.8429 168.633 93.3857L170.819 94.1572V105.471C176.819 97.8429 182.948 94.0286 189.205 94.0286C192.205 94.0286 194.433 94.8429 195.89 96.4714C197.348 98.0143 198.076 99.7714 198.076 101.743C198.076 104.057 197.305 105.857 195.762 107.143C194.219 108.343 192.462 108.943 190.49 108.943C188.862 108.943 187.233 108.514 185.605 107.657C184.062 106.8 182.905 105.471 182.133 103.671C179.219 103.671 176.605 104.829 174.29 107.143C172.062 109.371 170.948 111.986 170.948 114.986V142.629C170.948 145.971 171.119 148.371 171.462 149.829C171.89 151.286 172.919 152.229 174.548 152.657C176.262 153 179.005 153.257 182.776 153.429C182.948 154.629 182.948 155.957 182.776 157.414C179.862 157.414 176.862 157.371 173.776 157.286C170.69 157.2 167.519 157.157 164.262 157.157C161.09 157.157 158.262 157.2 155.776 157.286C153.376 157.371 150.848 157.414 148.19 157.414ZM229.285 158.829C223.028 158.829 217.542 157.5 212.828 154.843C208.199 152.1 204.599 148.371 202.028 143.657C199.457 138.857 198.171 133.371 198.171 127.2C198.171 120.514 199.499 114.686 202.157 109.714C204.899 104.743 208.714 100.886 213.599 98.1429C218.485 95.4 224.099 94.0286 230.442 94.0286C236.699 94.0286 242.142 95.4 246.771 98.1429C251.399 100.886 254.999 104.657 257.571 109.457C260.142 114.257 261.428 119.7 261.428 125.786C261.428 132.043 260.057 137.7 257.314 142.757C254.657 147.729 250.928 151.671 246.128 154.586C241.328 157.414 235.714 158.829 229.285 158.829ZM212.699 125.657C212.699 134.4 214.114 141.343 216.942 146.486C219.857 151.543 224.185 154.071 229.928 154.071C235.414 154.071 239.614 151.671 242.528 146.871C245.442 141.986 246.899 135.471 246.899 127.329C246.899 118.671 245.442 111.771 242.528 106.629C239.614 101.486 235.371 98.9143 229.799 98.9143C224.314 98.9143 220.071 101.271 217.071 105.986C214.157 110.7 212.699 117.257 212.699 125.657ZM267.394 157.414C267.308 157.071 267.265 156.729 267.265 156.386C267.265 156.043 267.265 155.7 267.265 155.357C267.265 155.014 267.265 154.714 267.265 154.457C267.265 154.114 267.308 153.771 267.394 153.429C270.308 153.257 272.451 153 273.822 152.657C275.194 152.229 276.094 151.371 276.522 150.086C276.951 148.8 277.165 146.743 277.165 143.914V79.5C277.165 76.8429 276.908 74.8714 276.394 73.5857C275.965 72.2143 274.979 71.2714 273.437 70.7572C271.979 70.1572 269.751 69.7286 266.751 69.4714C266.665 69.1286 266.622 68.8286 266.622 68.5714C266.622 68.3143 266.622 68.0572 266.622 67.8C266.622 67.4572 266.622 67.1572 266.622 66.9C266.622 66.6429 266.665 66.3429 266.751 66C270.179 65.5714 273.694 64.9286 277.294 64.0714C280.894 63.1286 284.579 61.8429 288.351 60.2143L290.537 60.9857C290.451 62.8714 290.365 65.0143 290.279 67.4143C290.279 69.8143 290.279 72.4286 290.279 75.2572V122.957C291.308 122.957 292.165 122.786 292.851 122.443C293.537 122.1 294.094 121.757 294.522 121.414C294.694 121.243 295.037 120.943 295.551 120.514C296.065 120 296.965 119.1 298.251 117.814C299.537 116.529 301.379 114.6 303.779 112.029C306.008 109.543 307.765 107.614 309.051 106.243C310.422 104.786 311.108 103.586 311.108 102.643C311.108 101.957 310.508 101.4 309.308 100.971C308.194 100.457 306.651 100.157 304.679 100.071C304.594 99.7286 304.551 99.3857 304.551 99.0429C304.551 98.7 304.551 98.3572 304.551 98.0143C304.551 97.6714 304.551 97.3286 304.551 96.9857C304.551 96.6429 304.594 96.3 304.679 95.9572C306.394 95.9572 308.537 96 311.108 96.0857C313.765 96.1714 316.122 96.2143 318.179 96.2143C319.208 96.2143 320.665 96.2143 322.551 96.2143C324.522 96.1286 326.494 96.0857 328.465 96.0857C330.437 96.0857 331.894 96.0857 332.837 96.0857C332.922 96.4286 332.965 96.7714 332.965 97.1143C333.051 97.4572 333.094 97.8 333.094 98.1429C333.094 98.4857 333.051 98.8286 332.965 99.1714C332.965 99.4286 332.922 99.7286 332.837 100.071C328.379 100.157 324.608 101.271 321.522 103.414C318.437 105.471 315.479 107.914 312.651 110.743L303.394 120L321.137 143.4C323.022 145.886 324.565 147.857 325.765 149.314C327.051 150.686 328.422 151.671 329.879 152.271C331.337 152.871 333.351 153.257 335.922 153.429C336.094 154.629 336.094 155.957 335.922 157.414C334.808 157.414 333.137 157.371 330.908 157.286C328.765 157.2 325.379 157.157 320.751 157.157C320.065 157.157 319.037 157.157 317.665 157.157C316.294 157.157 315.008 157.243 313.808 157.414C313.808 156.471 313.294 155.186 312.265 153.557C311.237 151.843 310.422 150.6 309.822 149.829C309.565 149.4 308.922 148.5 307.894 147.129C306.865 145.671 305.622 144 304.165 142.114C302.794 140.143 301.379 138.171 299.922 136.2C298.465 134.143 297.137 132.343 295.937 130.8C294.994 129.514 294.094 128.529 293.237 127.843C292.465 127.071 291.479 126.686 290.279 126.686V142.629C290.279 145.971 290.408 148.371 290.665 149.829C291.008 151.286 291.737 152.229 292.851 152.657C294.051 153 295.851 153.257 298.251 153.429C298.422 154.714 298.422 156.043 298.251 157.414C296.022 157.414 293.665 157.371 291.179 157.286C288.779 157.2 286.165 157.157 283.337 157.157C280.594 157.157 277.894 157.2 275.237 157.286C272.579 157.371 269.965 157.414 267.394 157.414ZM369.34 157.414C366.94 157.414 364.454 157.371 361.883 157.286C359.311 157.2 356.526 157.157 353.526 157.157C350.783 157.157 347.997 157.2 345.169 157.286C342.426 157.371 339.769 157.414 337.197 157.414C336.94 156.043 336.94 154.714 337.197 153.429C340.111 153.257 342.254 153 343.626 152.657C344.997 152.229 345.897 151.371 346.326 150.086C346.754 148.8 346.969 146.743 346.969 143.914V115.114C346.969 111.771 346.84 109.286 346.583 107.657C346.326 106.029 345.511 104.914 344.14 104.314C342.854 103.629 340.583 103.071 337.326 102.643C337.069 101.443 337.069 100.329 337.326 99.3C341.097 98.6143 344.697 97.7572 348.126 96.7286C351.554 95.7 354.854 94.5857 358.026 93.3857L360.211 94.1572C360.126 96.8143 360.04 99.3 359.954 101.614C359.954 103.929 359.954 106.114 359.954 108.171V142.629C359.954 145.971 360.126 148.371 360.469 149.829C360.897 151.286 361.754 152.229 363.04 152.657C364.411 153 366.511 153.257 369.34 153.429C369.597 154.714 369.597 156.043 369.34 157.414ZM343.626 71.5286C343.626 69.0429 344.483 66.9429 346.197 65.2286C347.997 63.5143 350.14 62.6572 352.626 62.6572C355.026 62.6572 357.083 63.5143 358.797 65.2286C360.597 66.9429 361.497 69 361.497 71.4C361.497 73.6286 360.64 75.6857 358.926 77.5715C357.211 79.3714 355.026 80.2714 352.369 80.2714C349.969 80.2714 347.911 79.4143 346.197 77.7C344.483 75.9857 343.626 73.9286 343.626 71.5286ZM372.678 188.914C372.592 187.543 372.592 186.214 372.678 184.929C375.678 184.757 377.864 184.457 379.235 184.029C380.607 183.6 381.464 182.743 381.807 181.457C382.235 180.257 382.45 178.286 382.45 175.543V115.114C382.45 111.771 382.278 109.286 381.935 107.657C381.678 106.029 380.864 104.914 379.492 104.314C378.207 103.629 375.978 103.071 372.807 102.643C372.635 101.443 372.635 100.329 372.807 99.3C376.321 98.6143 379.75 97.8 383.092 96.8572C386.435 95.9143 389.907 94.7572 393.507 93.3857L395.307 94.2857C395.221 96.4286 395.178 98.2714 395.178 99.8143C395.178 101.271 395.178 102.686 395.178 104.057C398.521 100.543 401.821 98.0143 405.078 96.4714C408.335 94.8429 411.807 94.0286 415.492 94.0286C420.892 94.0286 425.435 95.4429 429.121 98.2714C432.892 101.1 435.764 104.786 437.735 109.329C439.707 113.871 440.692 118.8 440.692 124.114C440.692 130.371 439.321 136.157 436.578 141.471C433.921 146.7 430.192 150.9 425.392 154.071C420.592 157.243 415.021 158.829 408.678 158.829C406.192 158.829 403.835 158.614 401.607 158.186C399.378 157.843 397.278 157.329 395.307 156.643V174C395.307 177.343 395.564 179.743 396.078 181.2C396.592 182.657 397.707 183.557 399.421 183.9C401.135 184.329 403.835 184.629 407.521 184.8C407.607 186.171 407.607 187.543 407.521 188.914C404.607 188.914 401.65 188.871 398.65 188.786C395.735 188.7 392.521 188.657 389.007 188.657C385.664 188.657 382.792 188.7 380.392 188.786C377.992 188.871 375.421 188.914 372.678 188.914ZM395.178 146.1C398.864 151.414 403.75 154.071 409.835 154.071C414.121 154.071 417.507 152.871 419.992 150.471C422.564 148.071 424.407 144.943 425.521 141.086C426.721 137.229 427.321 133.157 427.321 128.871C427.321 124.586 426.764 120.386 425.65 116.271C424.535 112.157 422.692 108.771 420.121 106.114C417.635 103.371 414.207 102 409.835 102C404.607 102 399.721 104.529 395.178 109.586V146.1ZM477.335 158.829C471.25 158.829 466.107 157.414 461.907 154.586C457.707 151.757 454.493 147.986 452.264 143.271C450.121 138.471 449.05 133.2 449.05 127.457C449.05 121.543 450.164 116.057 452.393 111C454.707 105.943 458.05 101.871 462.421 98.7857C466.793 95.6143 472.107 94.0286 478.364 94.0286C485.907 94.0286 491.778 96.3 495.978 100.843C500.264 105.3 502.407 111.086 502.407 118.2C502.407 119.057 502.364 119.829 502.278 120.514C502.278 121.114 502.235 121.629 502.15 122.057L461.65 121.671C461.65 122.014 461.65 122.314 461.65 122.571C461.65 130.971 463.578 137.571 467.435 142.371C471.293 147.171 476.693 149.571 483.635 149.571C489.464 149.571 495.207 147.686 500.864 143.914C501.721 144.943 502.364 145.929 502.793 146.871C495.507 154.843 487.021 158.829 477.335 158.829ZM462.035 116.914L488.65 116.4C488.735 116.229 488.778 116.014 488.778 115.757C488.778 115.414 488.778 115.2 488.778 115.114C488.778 110.486 487.75 106.629 485.693 103.543C483.721 100.457 480.764 98.9143 476.821 98.9143C473.135 98.9143 469.921 100.414 467.178 103.414C464.435 106.414 462.721 110.914 462.035 116.914ZM559.644 158.957L557.587 158.057L557.073 149.186C554.073 152.443 550.987 154.886 547.816 156.514C544.73 158.057 541.302 158.829 537.53 158.829C532.216 158.829 527.544 157.414 523.516 154.586C519.573 151.671 516.53 147.9 514.387 143.271C512.244 138.643 511.173 133.629 511.173 128.229C511.173 121.971 512.502 116.271 515.159 111.129C517.902 105.986 521.716 101.871 526.602 98.7857C531.573 95.6143 537.359 94.0286 543.959 94.0286C545.93 94.0286 547.987 94.2 550.13 94.5429C552.273 94.8 554.502 95.2714 556.816 95.9572V79.5C556.816 76.8429 556.559 74.8714 556.044 73.5857C555.53 72.2143 554.502 71.2714 552.959 70.7572C551.502 70.1572 549.273 69.7286 546.273 69.4714C546.016 68.3572 546.016 67.2 546.273 66C549.702 65.5714 553.216 64.9286 556.816 64.0714C560.416 63.1286 564.102 61.8429 567.873 60.2143L570.059 60.9857C569.973 62.8714 569.887 65.0143 569.802 67.4143C569.802 69.8143 569.802 72.4286 569.802 75.2572V139.029C569.802 142.286 569.93 144.729 570.187 146.357C570.445 147.986 571.216 149.143 572.502 149.829C573.787 150.429 575.973 150.986 579.059 151.5C579.316 152.614 579.316 153.771 579.059 154.971C575.63 155.486 572.287 156.043 569.03 156.643C565.773 157.243 562.644 158.014 559.644 158.957ZM556.944 106.886C553.259 101.829 548.416 99.3 542.416 99.3C536.502 99.3 532.044 101.486 529.044 105.857C526.044 110.143 524.544 116.1 524.544 123.729C524.544 128.186 525.144 132.471 526.344 136.586C527.544 140.7 529.516 144.086 532.259 146.743C535.002 149.4 538.644 150.729 543.187 150.729C548.93 150.729 553.516 148.243 556.944 143.271V106.886ZM615.699 157.414C613.299 157.414 610.813 157.371 608.242 157.286C605.67 157.2 602.885 157.157 599.885 157.157C597.142 157.157 594.356 157.2 591.527 157.286C588.785 157.371 586.127 157.414 583.556 157.414C583.299 156.043 583.299 154.714 583.556 153.429C586.47 153.257 588.613 153 589.985 152.657C591.356 152.229 592.256 151.371 592.685 150.086C593.113 148.8 593.327 146.743 593.327 143.914V115.114C593.327 111.771 593.199 109.286 592.942 107.657C592.685 106.029 591.87 104.914 590.499 104.314C589.213 103.629 586.942 103.071 583.685 102.643C583.427 101.443 583.427 100.329 583.685 99.3C587.456 98.6143 591.056 97.7572 594.485 96.7286C597.913 95.7 601.213 94.5857 604.385 93.3857L606.57 94.1572C606.485 96.8143 606.399 99.3 606.313 101.614C606.313 103.929 606.313 106.114 606.313 108.171V142.629C606.313 145.971 606.485 148.371 606.827 149.829C607.256 151.286 608.113 152.229 609.399 152.657C610.77 153 612.87 153.257 615.699 153.429C615.956 154.714 615.956 156.043 615.699 157.414ZM589.985 71.5286C589.985 69.0429 590.842 66.9429 592.556 65.2286C594.356 63.5143 596.499 62.6572 598.985 62.6572C601.385 62.6572 603.442 63.5143 605.156 65.2286C606.956 66.9429 607.856 69 607.856 71.4C607.856 73.6286 606.999 75.6857 605.285 77.5715C603.57 79.3714 601.385 80.2714 598.727 80.2714C596.327 80.2714 594.27 79.4143 592.556 77.7C590.842 75.9857 589.985 73.9286 589.985 71.5286ZM665.837 158.571C660.18 158.571 656.623 155.743 655.165 150.086C649.08 155.914 642.865 158.829 636.523 158.829C632.151 158.829 628.423 157.543 625.337 154.971C622.337 152.314 620.837 148.671 620.837 144.043C620.837 132.729 632.365 125.614 655.423 122.7C655.423 120.643 655.423 118.543 655.423 116.4C655.508 114.257 655.551 111.986 655.551 109.586C655.551 106.586 654.437 104.271 652.208 102.643C650.065 100.929 647.451 100.071 644.365 100.071C642.137 100.071 640.251 100.414 638.708 101.1C638.708 103.071 638.28 105.086 637.423 107.143C636.565 109.2 635.365 110.957 633.823 112.414C632.365 113.786 630.565 114.471 628.423 114.471C626.537 114.471 625.037 113.957 623.923 112.929C622.894 111.814 622.38 110.486 622.38 108.943C622.38 106.886 623.323 104.957 625.208 103.157C627.18 101.271 629.665 99.6857 632.665 98.4C635.665 97.0286 638.794 95.9572 642.051 95.1857C645.308 94.4143 648.223 94.0286 650.794 94.0286C653.965 94.0286 656.88 94.6286 659.537 95.8286C662.28 96.9429 664.465 98.6572 666.094 100.971C667.808 103.2 668.665 105.986 668.665 109.329C668.665 111.386 668.623 114.086 668.537 117.429C668.451 120.686 668.365 124.2 668.28 127.971C668.28 131.657 668.237 135.171 668.151 138.514C668.065 141.857 668.023 144.557 668.023 146.614C668.023 149.357 669.223 150.729 671.623 150.729C673.165 150.729 675.523 150.214 678.694 149.186C679.037 149.614 679.251 150.086 679.337 150.6C679.508 151.114 679.637 151.586 679.723 152.014C677.58 154.329 675.308 156 672.908 157.029C670.594 158.057 668.237 158.571 665.837 158.571ZM655.165 146.614L655.423 127.329C647.537 128.357 642.094 130.029 639.094 132.343C636.18 134.657 634.723 137.614 634.723 141.214C634.723 144.214 635.494 146.529 637.037 148.157C638.665 149.7 640.68 150.471 643.08 150.471C644.623 150.471 646.337 150.129 648.223 149.443C650.194 148.757 652.508 147.814 655.165 146.614Z" fill="currentColor"></path><rect x="715" y="65" width="195" height="105" rx="52.5" fill="currentColor" fill-opacity="0.05"></rect><path d="M767.529 142.875L754.049 107.938H762.552L769.309 127.582C769.705 128.812 770.078 130.032 770.43 131.24C770.781 132.449 771.078 133.559 771.32 134.569H771.616C771.858 133.559 772.144 132.449 772.473 131.24C772.825 130.032 773.198 128.812 773.594 127.582L780.186 107.938H788.689L775.472 142.875H767.529ZM810.856 143.633C806.901 143.633 803.528 142.71 800.737 140.865C797.969 138.997 795.871 136.305 794.442 132.79C793.014 129.252 792.3 124.989 792.3 120.001V118.255C792.3 113.245 793.014 108.982 794.442 105.467C795.871 101.929 797.969 99.2373 800.737 97.3916C803.528 95.5239 806.901 94.5901 810.856 94.5901C814.789 94.5901 818.129 95.5129 820.875 97.3586C823.644 99.2043 825.731 101.907 827.138 105.467C828.566 109.004 829.28 113.267 829.28 118.255V120.001C829.28 124.989 828.577 129.252 827.171 132.79C825.764 136.327 823.677 139.019 820.908 140.865C818.162 142.71 814.811 143.633 810.856 143.633ZM810.889 136.382C813.064 136.382 814.877 135.789 816.327 134.602C817.799 133.416 818.898 131.658 819.623 129.329C820.348 126.978 820.711 124.066 820.711 120.595V117.694C820.711 114.223 820.337 111.311 819.59 108.96C818.865 106.609 817.777 104.84 816.327 103.654C814.877 102.445 813.064 101.841 810.889 101.841C808.714 101.841 806.879 102.434 805.385 103.621C803.912 104.785 802.792 106.554 802.023 108.927C801.276 111.278 800.902 114.201 800.902 117.694V120.595C800.902 124.044 801.287 126.945 802.056 129.296C802.825 131.647 803.945 133.416 805.418 134.602C806.89 135.789 808.714 136.382 810.889 136.382ZM838.988 143.205C838 143.205 837.099 142.985 836.286 142.545C835.495 142.106 834.879 141.491 834.44 140.7C834.001 139.909 833.781 139.019 833.781 138.03C833.781 137.019 834.001 136.118 834.44 135.327C834.879 134.536 835.495 133.921 836.286 133.482C837.099 133.042 838 132.823 838.988 132.823C839.977 132.823 840.867 133.042 841.658 133.482C842.449 133.921 843.064 134.536 843.504 135.327C843.943 136.118 844.163 137.019 844.163 138.03C844.163 139.019 843.943 139.909 843.504 140.7C843.064 141.491 842.449 142.106 841.658 142.545C840.867 142.985 839.977 143.205 838.988 143.205ZM857.365 142.875V104.511L846.39 111.663V103.357L858.453 95.3481H865.802V142.875H857.365Z" fill="currentColor"></path></svg></a></div><div class="flex items-center gap-1"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover px-4 py-2 w-9 h-9 flex-shrink-0 [&amp;_svg]:!w-5" type="button" id="radix-_R_aipfiumdb_" aria-haspopup="menu" aria-expanded="false" data-state="closed"><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M12 18a6 6 0 1 1 0-12 6 6 0 0 1 0 12m0-2a4 4 0 1 0 0-8 4 4 0 0 0 0 8M11 1h2v3h-2zm0 19h2v3h-2zM3.515 4.929l1.414-1.414L7.05 5.636 5.636 7.05zM16.95 18.364l1.414-1.414 2.121 2.121-1.414 1.414zm2.121-14.85 1.414 1.415-2.121 2.121-1.414-1.414zM5.636 16.95l1.414 1.414-2.121 2.121-1.414-1.414zM23 11v2h-3v-2zM4 11v2H1v-2z"></path></svg></span><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 absolute rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M10 7a7 7 0 0 0 12 4.9v.1c0 5.523-4.477 10-10 10S2 17.523 2 12 6.477 2 12 2h.1A6.98 6.98 0 0 0 10 7m-6 5a8 8 0 0 0 15.062 3.762A9 9 0 0 1 8.238 4.938 8 8 0 0 0 4 12"></path></svg></span><span class="sr-only">Toggle theme</span></button><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover h-9 w-9" type="button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-search h-5 w-5"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button></div></div></header><div class="bg-surface-base fixed right-0 top-16 z-50 h-[calc(100vh-4rem)] w-full transform border-l transition-transform duration-300 ease-in-out sm:w-1/2 md:hidden translate-x-full"><div class="flex flex-col gap-4 p-4"><div class="flex flex-row gap-2"><button class="focus-visible:ring-ring inline-flex items-center gap-x-2 whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 border-input text-primary hover:border-primary/15 border hover:bg-overlay-hover py-2 max-w-full shadow-none sm:w-80 h-10 w-full justify-start rounded-full bg-surface-l1 px-4" type="button"><div class="flex items-center justify-between sm:w-full gap-4"><div class="flex items-center justify-start gap-2"><span class="inline-flex items-center justify-center p-0 m-0 w-4 h-4 text-muted" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-4 h-4" focusable="false" style="fill:currentColor"><path d="m18.031 16.617 4.283 4.282-1.415 1.415-4.282-4.283A8.96 8.96 0 0 1 11 20c-4.968 0-9-4.032-9-9s4.032-9 9-9 9 4.032 9 9a8.96 8.96 0 0 1-1.969 5.617m-2.006-.742A6.98 6.98 0 0 0 18 11c0-3.867-3.133-7-7-7s-7 3.133-7 7 3.133 7 7 7a6.98 6.98 0 0 0 4.875-1.975z"></path></svg></span><p class="text-sm text-muted hidden sm:block">Search</p></div><span class="hidden sm:block"><div class="bg-foreground/10 text-muted inline-flex items-center rounded-md px-1 py-0.5 text-center font-sans text-xs font-normal tracking-widest rtl:space-x-reverse"><span>âŒ˜</span><span class="text-xs">K</span></div></span></div></button></div></div></div><div><div class="min-[1350px]:grid min-[1350px]:grid-cols-[1fr_3fr_1fr]"><nav class="bg-surface-base hidden h-[calc(100vh-4rem)] overflow-y-auto px-6 pb-32 min-[1350px]:sticky min-[1350px]:top-16 min-[1350px]:block scrollbar-none [-ms-overflow-style:none] [scrollbar-width:none] [&amp;::-webkit-scrollbar]:hidden [overscroll-behavior:contain] pt-8"><ul class="space-y-2 text-sm"><li style="padding-left:0rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#lesswrong" class="transition-opacity hover:opacity-100 opacity-50">LessWrong</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#origins-and-core-mission" class="transition-opacity hover:opacity-100 opacity-50">Origins and Core Mission</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#precursors-in-overcoming-bias" class="transition-opacity hover:opacity-100 opacity-50">Precursors in Overcoming Bias</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#launch-and-initial-purpose" class="transition-opacity hover:opacity-100 opacity-50">Launch and Initial Purpose</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#philosophical-foundations" class="transition-opacity hover:opacity-100 opacity-50">Philosophical Foundations</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#rationality-as-defined-by-lesswrong" class="transition-opacity hover:opacity-100 opacity-50">Rationality as Defined by LessWrong</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#key-concepts-from-the-sequences" class="transition-opacity hover:opacity-100 opacity-50">Key Concepts from the Sequences</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#historical-evolution" class="transition-opacity hover:opacity-100 opacity-50">Historical Evolution</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#early-expansion-and-peak-activity-2009-2015" class="transition-opacity hover:opacity-100 opacity-50">Early Expansion and Peak Activity (2009-2015)</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#decline-and-relaunch-as-lesswrong-20-2016-2018" class="transition-opacity hover:opacity-100 opacity-50">Decline and Relaunch as LessWrong 2.0 (2016-2018)</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#contemporary-focus-on-ai-and-alignment-2019-present" class="transition-opacity hover:opacity-100 opacity-50">Contemporary Focus on AI and Alignment (2019-Present)</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#platform-features-and-content" class="transition-opacity hover:opacity-100 opacity-50">Platform Features and Content</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#blog-and-forum-mechanics" class="transition-opacity hover:opacity-100 opacity-50">Blog and Forum Mechanics</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#major-topics-and-subcommunities" class="transition-opacity hover:opacity-100 opacity-50">Major Topics and Subcommunities</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#community-composition" class="transition-opacity hover:opacity-100 opacity-50">Community Composition</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#demographics-and-culture" class="transition-opacity hover:opacity-100 opacity-50">Demographics and Culture</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#prominent-contributors-and-thinkers" class="transition-opacity hover:opacity-100 opacity-50">Prominent Contributors and Thinkers</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#controversies-and-internal-critiques" class="transition-opacity hover:opacity-100 opacity-50">Controversies and Internal Critiques</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#the-rokos-basilisk-episode" class="transition-opacity hover:opacity-100 opacity-50">The Roko&#x27;s Basilisk Episode</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#engagement-with-neoreaction-and-political-fringe" class="transition-opacity hover:opacity-100 opacity-50">Engagement with Neoreaction and Political Fringe</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#challenges-to-rationality-claims-and-prediction-accuracy" class="transition-opacity hover:opacity-100 opacity-50">Challenges to Rationality Claims and Prediction Accuracy</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#moderation-practices-and-community-boundaries" class="transition-opacity hover:opacity-100 opacity-50">Moderation Practices and Community Boundaries</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#influence-and-external-reception" class="transition-opacity hover:opacity-100 opacity-50">Influence and External Reception</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#contributions-to-ai-safety-and-effective-altruism" class="transition-opacity hover:opacity-100 opacity-50">Contributions to AI Safety and Effective Altruism</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#broader-impacts-on-rationalist-thought" class="transition-opacity hover:opacity-100 opacity-50">Broader Impacts on Rationalist Thought</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#skepticism-and-criticisms-from-academia-and-mainstream" class="transition-opacity hover:opacity-100 opacity-50">Skepticism and Criticisms from Academia and Mainstream</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#references" class="transition-opacity hover:opacity-100 opacity-50">References</a></li></ul></nav><div class="relative top-16 pb-32 pt-8 px-4 md:px-8"><div class="mx-auto max-w-[850px]"><button data-state="closed" type="button" class="flex items-center"><div class="text-fg-tertiary mb-2 flex cursor-help items-center gap-2 text-sm"><span class="inline-flex items-center justify-center p-0 m-0" data-namespace="@xai/icons" data-slot="icon" style="height:16px;width:16px"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 33 33" aria-hidden="true" class="" focusable="false" style="fill:currentColor;height:16px;width:16px"><path fill="currentColor" d="m13.237 21.04 11.082-8.19c.543-.4 1.32-.244 1.578.38 1.363 3.288.754 7.241-1.957 9.955-2.71 2.714-6.482 3.31-9.93 1.954l-3.765 1.745c5.401 3.697 11.96 2.782 16.059-1.324 3.251-3.255 4.258-7.692 3.317-11.693l.008.009c-1.365-5.878.336-8.227 3.82-13.031q.123-.17.247-.345l-4.585 4.59v-.014L13.234 21.044M10.95 23.031c-3.877-3.707-3.208-9.446.1-12.755 2.446-2.449 6.454-3.448 9.952-1.979L24.76 6.56c-.677-.49-1.545-1.017-2.54-1.387A12.465 12.465 0 0 0 8.675 7.901c-3.519 3.523-4.625 8.94-2.725 13.561 1.42 3.454-.907 5.898-3.251 8.364-.83.874-1.664 1.749-2.335 2.674l10.583-9.466"></path></svg></span><span>Fact-checked by Grok<!-- --> <!-- -->4 days ago</span></div></button><article class="text-[16px]"><h1 id="lesswrong" class="group relative mb-2 scroll-mt-24 font-serif text-[2.125em] font-semibold tracking-[-1px] [&amp;:not(:first-child)]:mt-14" node="[object Object]">LessWrong<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h1>
<span class="mb-4 block break-words text-[1em] leading-7">
LessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_60qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup> It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as <em>The Sequences</em>, originally developed on the predecessor blog <em>Overcoming Bias</em>.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_i0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_k0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup> These writings, later compiled into resources like <em>Rationality: From AI to Zombies</em>, provide foundational training in identifying and countering errors in thought processes, drawing on probability theory, philosophy, and psychology to foster clearer understanding of complex realities.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_s0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The platform hosts discussions across disciplines including artificial intelligence, economics, philosophy, and psychology, with particular focus on AI alignmentâ€”ensuring advanced systems pursue human-compatible goalsâ€”and strategies for global risk mitigation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_41abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup> Community norms prioritize evidence-based argumentation, epistemic humility, and constructive criticism, encouraging participants to update beliefs in light of new data and to apply rational tools toward high-impact outcomes.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_81abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup> LessWrong has integrated specialized forums like the Alignment Forum for technical AI safety research, reflecting its role in nurturing expertise on existential threats from misaligned superintelligence.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c1abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[4]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong&#x27;s influence extends to the effective altruism movement, where its rationality framework has shaped quantitative approaches to philanthropy and cause prioritization, as seen in the overlap of membership and the recommendation of <em>The Sequences</em> as essential reading for altruists seeking maximal impact.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_81qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[5]</sup> The community has contributed to institutional developments, including the Machine Intelligence Research Institute (MIRI), founded by Yudkowsky to advance AI safety, and has informed broader rationalist practices in prediction, forecasting, and decision theory.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c1qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[6]</sup> While internal debates persist on topics like the scalability of rationality training and the balance between theoretical insight and practical application, the site&#x27;s enduring output underscores its commitment to truth-tracking over consensus or ideological conformity.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_g1qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[7]</sup></span>
<h2 id="origins-and-core-mission" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Origins and Core Mission<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="precursors-in-overcoming-bias" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Precursors in Overcoming Bias<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7"><strong>Overcoming Bias</strong>, a group blog focused on human rationality, economics, and cognitive biases, was launched in November 2006 by economist Robin Hanson and researcher Eliezer Yudkowsky.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_63abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup> The inaugural posts emphasized practical strategies for aligning beliefs with evidence amid inherent psychological distortions, drawing from fields like behavioral economics and decision theory.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a3abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup> Hanson contributed extensively on topics such as prediction markets, which aggregate dispersed information to forecast outcomes more accurately than individual experts, and signaling theory, where observable actions convey hidden qualities in social and economic interactions.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_e3abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[9]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_g3abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[10]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Yudkowsky&#x27;s early contributions introduced foundational explorations of cognitive errors, including overconfidence and confirmation bias, while laying groundwork for systematic probability updating via Bayesian methods.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_43qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup> These discussions fostered an active comment community that debated applications of rational inference to everyday reasoning and scientific inquiry, highlighting discrepancies between intuitive judgments and empirical validation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_83qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[11]</sup> The blog&#x27;s interdisciplinary approach revealed tensions between Hanson&#x27;s emphasis on institutional mechanisms like markets for bias correction and Yudkowsky&#x27;s focus on individual epistemic habits.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c3qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">By early 2009, diverging thematic prioritiesâ€”Hanson&#x27;s sustained interest in economic signaling and prediction alongside Yudkowsky&#x27;s deepening dives into comprehensive rationality frameworksâ€”prompted a structural shift.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_44abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup> Yudkowsky&#x27;s content, which increasingly dominated discourse on foundational cognitive tools, was spun off to preserve Overcoming Bias as a venue for broader socioeconomic analysis under Hanson&#x27;s primary authorship.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_84abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup> This separation underscored the blog&#x27;s role in cultivating a precursor intellectual ecosystem, where rigorous scrutiny of biases evolved into calls for dedicated platforms advancing probabilistic thinking.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c4abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup></span>
<h3 id="launch-and-initial-purpose" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Launch and Initial Purpose<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong was launched in February 2009 by Eliezer Yudkowsky as a dedicated community blog, drawing its initial content from his essays on rationality previously published on the Overcoming Bias group blog, which had been active since November 2006.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_45abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup> These essays, later compiled into what became known as the Sequences, served as the foundational seed material to bootstrap the platform.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_85abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The site&#x27;s stated initial purpose was to build a community focused on refining the art of human rationality, with an emphasis on practical epistemic methods informed by cognitive science, probability theory, and strategies for effective decision-making amid uncertainty.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_45qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup> This approach sought to equip participants with tools for overcoming systematic errors in thinking, prioritizing actionable techniques for bias reduction and clearer inference over abstract philosophical speculation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_85qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">From inception, LessWrong incorporated Reddit-style infrastructure, featuring voting mechanisms for posts and comments that weighted contributions based on community upvotes, thereby promoting the emergence of empirically robust ideas through decentralized evaluation rather than authoritative endorsement.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_46abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_86abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[12]</sup> This system incentivized content grounded in testable claims, aligning with the platform&#x27;s goal of cultivating rigorous, evidence-oriented discourse.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c6abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[12]</sup></span>
<h2 id="philosophical-foundations" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Philosophical Foundations<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="rationality-as-defined-by-lesswrong" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Rationality as Defined by LessWrong<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong conceives rationality as the dual pursuit of <strong>epistemic rationality</strong>, which entails systematically enhancing the correspondence between one&#x27;s beliefs and empirical reality through evidence-based updating, and <strong>instrumental rationality</strong>, which involves selecting and executing actions that maximize progress toward predefined values or goals.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[13]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_e7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[14]</sup> Epistemic rationality relies on probabilistic frameworks like Bayesian inference, where priors are adjusted via likelihood ratios derived from data to minimize prediction errors, rather than adhering to dogmatic consistency or unfalsifiable abstractions common in traditional philosophy.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_i7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[15]</sup> Instrumental rationality extends this by applying causal models to forecast intervention outcomes, using tools such as expected value computationsâ€”defined as the sum of each possible outcome&#x27;s probability multiplied by its utilityâ€”to prioritize decisions yielding net positive returns under uncertainty.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_m7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[14]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_o7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[16]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">This framework prioritizes causal mechanisms over correlative intuitions or consensus-driven heuristics, exemplified by rejecting overconfidence biases through calibration exercises that reveal typical humans assign 99% confidence to true events only about 80% of the time in controlled tests.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_48abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[13]</sup> LessWrong critiques reliance on availability heuristics, which distort risk perceptions via vivid but unrepresentative anecdotesâ€”often amplified in media narratives favoring sensationalism over base ratesâ€”as empirically suboptimal when evaluated against verifiable forecasting records, such as those from prediction markets where aggregated bets outperform expert consensus by factors of 2-10x in accuracy on geopolitical events.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_88abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[14]</sup> In contrast to philosophical traditions emphasizing internal coherence without external validation, LessWrong&#x27;s approach demands beliefs and strategies be falsifiable and iteratively refined against real-world feedback, treating rationality as a skill honed through deliberate practice rather than an innate or normative ideal.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c8abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[16]</sup></span>
<h3 id="key-concepts-from-the-sequences" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Key Concepts from the Sequences<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">The Sequences, a collection of essays authored by Eliezer Yudkowsky from 2006 to 2009, operationalize rationality as the systematic application of Bayesian updating, cognitive bias mitigation, and reductionist inquiry to align beliefs with empirical evidence.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_49abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[17]</sup> Originally posted on Overcoming Bias and early LessWrong, these texts were compiled in 2015 as the ebook <em>Rationality: From AI to Zombies</em>, structuring rationality into sequences on epistemology, heuristics, and decision-making under uncertainty.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c9abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[18]</sup> Central to this framework is the distinction between the <strong>map</strong> (mental models and beliefs) and the <strong>territory</strong> (objective reality), where failures arise from conflating the two, leading to illusions of understanding without predictive power.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_o9abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[19]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">A core theme rejects <strong>mysterious answers to mysterious questions</strong>, critiquing explanations that invoke unfalsifiable essences or holistic irreducibility, such as labeling phenomena &quot;spiritual&quot; without mechanistic detail.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_89qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[20]</sup> Instead, the Sequences advocate reductionism, dissolving apparent mysteries by decomposing systems into verifiable components, as in the &quot;joy in the merely real&quot; where scientific progress reveals no need for supernatural supplements.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c9qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[21]</sup> This extends to quantum mechanics, interpreting the many-worlds hypothesis not as adding mystery but as resolving Copenhagen-style paradoxes through deterministic branching, thereby integrating quantum evidence into classical decision theory without instrumental collapse.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_g9qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[21]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In AI-related essays, the Sequences introduce precursors to <strong>instrumental convergence</strong>, observing that advanced agents pursuing diverse terminal goalsâ€”such as paperclip maximization or arbitrary utilitiesâ€”converge on subgoals like resource acquisition, self-preservation, and goal-preservation due to competitive pressures in resource-scarce environments.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8aabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[22]</sup> Techniques like <strong>Fermi estimation</strong>, involving order-of-magnitude approximations from sparse data, are emphasized for bounding uncertainties in forecasting, enabling rough quantification where precise inputs are unavailable.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gaabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[23]</sup> These methods underpin practical rationality, training users to generate testable predictions rather than vague intuitions.</span>
<h2 id="historical-evolution" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Historical Evolution<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="early-expansion-and-peak-activity-2009-2015" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Early Expansion and Peak Activity (2009-2015)<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Following its formal launch in early 2009, LessWrong saw rapid growth in user engagement, with the inaugural community survey in May 2009 attracting 166 respondents, expanding to 1,090 by December 2011â€”a more than sixfold increase indicating thousands of active participants discussing rationality practices such as probability calibration exercises and debiasing techniques.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4bqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[24]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6bqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[25]</sup> This period marked a proliferation of content inspired by the site&#x27;s core sequences, including extensions into decision theory variants like timeless decision theory introduced shortly after launch, and critiques of scientific methodology such as those highlighting replication failures in parapsychology as a control for broader epistemic issues.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_abqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[26]</sup> By 2011, 519 respondents identified as having posted on the site, with 23.4% (231 individuals) reporting attendance at in-person meetups focused on applying rationality heuristics to personal goal-setting and social dynamics.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ebqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[25]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Meetup groups emerged concurrently, with the New York City chapter originating from an April 24, 2009 gathering of about 15 participants organized around Overcoming Bias themes, evolving by mid-2010 into weekly sessions incorporating game nights, strategy workshops for life optimization, and norms like routine physical greetings to foster trust.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4cabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[27]</sup> These events, alongside online threads, facilitated thematic diversification; early AI risk discussions intensified around 2010 with elaborations on friendly AI designs to mitigate superintelligence hazards, building directly on sequence foundations without assuming alignment success.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8cabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[26]</sup> Precursors to effective altruism also gained traction, as users debated evidence-based charity evaluationâ€”drawing from GiveWell&#x27;s 2007 inception and Giving What We Can&#x27;s 2009 pledge modelâ€”prioritizing interventions with quantifiable impact over intuitive appeals.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ccabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[26]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">From 2011 to 2013, sequence-inspired writing surged, evidenced by survey respondents reaching 1,636 in 2013â€”the highest in the periodâ€”fueling explorations of akrasia countermeasures, meta-contrarianism, and Schelling points in coordination problems.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4cqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[28]</sup> This creative output spurred community spin-offs, including the launch of Slate Star Codex in 2013 by a prominent LessWrong contributor, which extended rationality analyses into psychiatry, economics, and futurism while attracting overlapping readership.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8cqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[26]</sup> By 2014, approximately 30% of surveyed users aligned with effective altruism principles, collectively donating over $1 million annually to high-impact causes, reflecting the platform&#x27;s peak in synthesizing epistemic tools with practical altruism amid sustained meetup networks worldwide.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ccqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[26]</sup></span>
<h3 id="decline-and-relaunch-as-lesswrong-20-2016-2018" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Decline and Relaunch as LessWrong 2.0 (2016-2018)<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In 2015â€“2016, LessWrong underwent a steady decline in activity, with posting volume and participation dropping to a fraction of prior levels, prompting some observers to declare the site effectively dead.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4dqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8dqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[29]</sup> This stagnation was attributed in part to inadequate moderation tools that failed to curb spam, trolls, and low-quality contributions, exacerbating user disengagement.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cdqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[30]</sup> Community surveys indicated that while the rationalist population had not shrunk outright, many users had migrated to splinter forums, including the emerging Effective Altruism Forum, diluting LessWrong&#x27;s centrality.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gdqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[31]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The relaunch as LessWrong 2.0 began in June 2017 under a dedicated team including Oliver Habryka, Ben Pace (known as Raemon), and Matthew Graves, marking the site&#x27;s first shift from volunteer maintenance to full-time development.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4eabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[32]</sup> The project rebuilt the platform on a modern codebase using technologies such as React, GraphQL, and Vulcan.js, replacing the outdated infrastructure that had hindered scalability and moderation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8eabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[32]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ceabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Key updates focused on enhancing discourse quality through stricter anti-spam measures, including the &quot;Sunshine Regiment&quot; volunteer moderation system to filter trolls and repetitive low-signal content, alongside tools for content curation, author-controlled comment sections, and integrated sequences for structured reading.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4eqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[32]</sup> These changes aimed to refocus the site on high-quality rationality discussions, adapting to eight years of community evolution while addressing the dilution from meme-like rationality tropes and off-site fragmentation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8eqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[32]</sup> Post-relaunch data showed stabilized and recovering activity levels, with karma and post metrics rebounding by late 2017.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ceqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_geqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[33]</sup></span>
<h3 id="contemporary-focus-on-ai-and-alignment-2019-present" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Contemporary Focus on AI and Alignment (2019-Present)<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Following the relaunch of LessWrong 2.0, the platform experienced a pronounced shift toward AI alignment and safety research starting in 2019, with a substantial portion of high-karma content addressing technical challenges in aligning advanced AI systems. This evolution correlated directly with external breakthroughs in machine learning, such as the release of GPT-3 in June 2020 and subsequent models like GPT-4 in March 2023, which accelerated debates on scalable oversightâ€”methods to supervise superintelligent systems beyond human capabilitiesâ€”and AI timelines forecasting transformative intelligence arrival. For instance, posts garnering significant engagement explored oversight feasibility, including reflections on reinforcement learning from human feedback (RLHF) limitations for AGI-scale alignment. By 2023-2025, discussions intensified around model progress rates, with analyses linking compute scaling laws to potential superintelligence by 2027, reflecting causal influences from empirical AI advancements rather than isolated speculation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4fqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[34]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6fqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[35]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The Alignment Forum, integrated into LessWrong&#x27;s infrastructure since its 2018 launch by the same team sharing codebase and database, became a core venue for rigorous AI safety discourse, emphasizing technical research over broader rationality topics. This subdomain facilitated focused threads on deceptive alignment, automated research scaling, and control mechanisms, with content cross-posted to LessWrong for wider visibility. Annual reviews, instituted as a community-driven &quot;peer review&quot; process from 2018 onward, systematically evaluated and curated high-impact posts, selecting those demonstrating enduring relevance amid evolving AI capabilities; for example, 2023-2024 reviews highlighted oversight and timeline analyses that withstood scrutiny against real-world model deployments.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4gabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[36]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6gabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[37]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8gabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[38]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In 2024-2025, LessWrong hosted debates scrutinizing empirical AI forecasting accuracy, often critiquing prior rationalist predictions for inconsistencies such as over-optimism on short timelines despite uneven benchmark progress. Community analyses of 2025 forecasts revealed bullish expectations for closing human-AI performance gaps that partially materialized but highlighted forecasting pitfalls, including overreliance on linear extrapolations amid volatile scaling. These discussions underscored mixed track records, with some rationalist projections underestimating deployment hurdles while others accurately anticipated surges in agentic capabilities, prompting calls for refined methodologies like multi-disciplinary benchmarking.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4gqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[39]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6gqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[40]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8gqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[41]</sup></span>
<h2 id="platform-features-and-content" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Platform Features and Content<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="blog-and-forum-mechanics" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Blog and Forum Mechanics<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong employs a karma-based voting system to evaluate and rank contributions, where users accumulate karma points through upvotes on their posts and comments. Upvotes and downvotes adjust a item&#x27;s score, with the platform distinguishing between standard (weak) votes and strong votes, the latter activated by holding the vote button and scaling in power from 1 to 15 based on the voter&#x27;s intent.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4iabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[42]</sup> Vote strength further depends on the voter&#x27;s total karma, enabling users with higher accumulated karmaâ€”typically from prior high-quality contributionsâ€”to exert greater influence on scores, thereby filtering low-quality content by amplifying signals from experienced participants.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8iabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[43]</sup> This mechanic incentivizes evidence-based posts, as high-karma items gain prominence in feeds and searches, with platform data indicating that optimizing for higher karma correlates with improved content quality and engagement over fragmented lower-karma outputs.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ciabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[44]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The platform integrates tagging and wiki features to cluster related concepts, allowing users to apply tags to posts for linking similar discussions and maintaining wiki pages that summarize key ideas with editable content and voting on relevance.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4iqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[45]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8iqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[46]</sup> Tags function as dynamic wiki entries, enabling users to vote on their accuracy and add summaries, which facilitates breakdowns of complex topics into foundational components and improves discoverability through integrated search.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ciqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[47]</sup> This system supports structured discourse by associating posts with established concepts, reducing redundancy and aiding in the refinement of arguments from basic principles.</span>
<span class="mb-4 block break-words text-[1em] leading-7">Following the LessWrong 2.0 relaunch in 2017, enhancements included automatic rate limiting for low-karma users to minimize noise, such as restricting those with -1 or lower total karma to one comment per day and one post every two weeks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4jabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[48]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8jabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[32]</sup> These measures, implemented by June 2023, aim to preserve discussion quality by curbing frequent low-value inputs from new or negatively rated accounts, with rationale drawn from observations of spam reduction and elevated baseline contributions in restricted environments.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cjabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[49]</sup></span>
<h3 id="major-topics-and-subcommunities" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Major Topics and Subcommunities<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong discussions emphasize cognitive biases as systematic patterns of deviation from rational cognition, such as confirmation bias and availability heuristic, with threads exploring their identification, psychological mechanisms, and debiasing strategies.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4kabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[50]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8kabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[51]</sup> Decision theory constitutes another core area, focusing on principles for optimal choice under uncertainty, including causal decision theory and alternatives like timeless or updateless variants proposed to resolve paradoxes such as Newcomb&#x27;s problem.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ckabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[52]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gkabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[53]</sup> These topics underpin epistemic rationalityâ€”aimed at accurate belief formationâ€”and instrumental rationalityâ€”geared toward value achievementâ€”often analyzed through Bayesian updating and expected utility maximization.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_kkabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[13]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Forecasting emerges as a subcommunity practice, involving probabilistic predictions on future events, with integrations to platforms like Metaculus for crowd-sourced forecasts on AI timelines and global risks, enabling calibration training and aggregation of expert judgments to improve accuracy over individual intuition.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4kqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[54]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">AI-related topics dominate recent discourse, particularly existential risks from misaligned superintelligence, agent foundations research into scalable oversight and corrigibility, and alignment techniques such as debate, scalable oversight, and mechanistic interpretability to ensure AI systems pursue intended goals.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4labav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[55]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8labav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[56]</sup> Discussions balance optimism in methods like constitutional AI with skepticism toward hype cycles, critiquing overreliance on unproven scaling assumptions without robust empirical validation of safety guarantees.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_clabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[57]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Overlaps with effective altruism appear in evaluations of high-impact interventions, but face internal critiques for empirical shortfalls in cause prioritization, including overemphasis on quantitative estimates prone to motivated reasoning and insufficient accounting for psychological barriers to sustained altruism or market inefficiencies in charity evaluation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4lqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[58]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8lqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[59]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_clqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[60]</sup></span>
<h2 id="community-composition" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Community Composition<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="demographics-and-culture" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Demographics and Culture<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">The LessWrong community consists predominantly of young adults, with surveys indicating a mean age of 30.5 years (median 29) among 558 respondents in 2023 and a mean of 32 years (median 31) among 279 respondents in 2024.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4nabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6nabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[62]</sup> Participants aged 20-39 comprise the majority, at approximately 77% in the 2023 data.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_anabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup> The user base is heavily male-skewed, with 89.3% identifying as male at birth in 2023 and 91.6% in 2024; cisgender males form about 75-80% of respondents, alongside smaller proportions of transgender females (around 5-6%) and non-binary individuals (3-5%).<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_enabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gnabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[62]</sup> Education levels are elevated, with over 65% holding at least a bachelor&#x27;s degree in recent surveys, reflecting a concentration of STEM-trained individuals.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_knabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_mnabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[62]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Occupational data underscores a strong affinity for technology and AI, with roughly 50% of respondents in 2023 engaged in computer-related fields (34.8% practical computing like programming or IT, 15.6% AI-specific roles) and additional shares in engineering or mathematics (5.5% each).<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4nqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup> Similar patterns hold in 2024, with 36.7% in practical computing and 15.4% in AI.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8nqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[62]</sup> Geographically, nearly half reside in the United States (49.3-49.6%), with the San Francisco Bay Area serving as a key hub for in-person rationalist activities and meetups that test community ideas in real-world settings.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cnqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_enqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[62]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gnqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[63]</sup> Racial demographics show limited diversity, with 78-79% identifying as white non-Hispanic, which, combined with the gender and professional homogeneity, raises concerns about potential echo-chamber effects limiting exposure to varied perspectives.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_knqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_mnqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[62]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_onqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[64]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Culturally, LessWrong emphasizes epistemic norms such as pursuing truth through rigorous argumentation, openness to unconventional ideas, and quantitative expression of beliefs, fostering a shared commitment to intellectual progress over social conformity.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4oabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[65]</sup> Practices like steelmanning opponents&#x27; positions and tracking prediction accuracy via platform tools promote accountability, though internal critiques note risks of insularity, where heavy reliance on introspective reasoning may undervalue broader empirical testing outside the community&#x27;s tech-centric worldview.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8oabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[66]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_aoabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[67]</sup> Meetup groups, particularly in the Bay Area, extend this culture offline, enabling collaborative application of rationality techniques in social and practical contexts, which helps mitigate some online isolation but reinforces regional concentrations.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_eoabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[68]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_goabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[63]</sup></span>
<h3 id="prominent-contributors-and-thinkers" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Prominent Contributors and Thinkers<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">
Eliezer Yudkowsky established LessWrong as a platform for rationality discussions and authored the foundational Sequences series, which systematically addresses cognitive biases, Bayesian reasoning, and decision-making under uncertainty.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6pabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[69]</sup> His work emphasizes first-principles approaches to epistemology and has shaped the site&#x27;s core content on refining human rationality.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_apabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[70]</sup> Yudkowsky also promotes AI alignment research to mitigate risks from advanced systems, though assessments of his predictive accuracy on AI progress reveal inconsistencies, such as earlier timelines not fully materializing.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_epabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[71]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Pseudonymous user gwern has contributed extensive data-driven analyses, including empirical reviews of AI capabilities, nootropics, and statistical forecasting, often drawing on large datasets and historical trends to test hypotheses.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4pqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[72]</sup> Paul Christiano, through posts and AMAs, has influenced alignment discourse by proposing scalable oversight methods like iterated amplification, aiming to supervise superhuman AI via recursive human-AI collaboration.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8pqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[73]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_apqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[74]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Zvi Mowshowitz delivers detailed weekly updates on AI advancements and critiques of policy responses, blending technical analysis with real-world implications from events like COVID-19 forecasting challenges.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4qabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[75]</sup> John Wentworth explores mathematical formalizations of rationality, applying category theory to decompose complex systems into composable abstractions for better world-modeling and decision theory.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8qabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[76]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong&#x27;s karma system quantifies contributions via user upvotes, providing an empirical measure of perceived value; for instance, Yudkowsky exceeded 100,000 karma by March 2011, signaling sustained community endorsement of his outputs over fame alone.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4qqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[77]</sup> High-karma posts from these thinkers often rank prominently in annual reviews, reflecting iterative community validation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8qqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[78]</sup></span>
<h2 id="controversies-and-internal-critiques" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Controversies and Internal Critiques<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="the-rokos-basilisk-episode" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">The Roko&#x27;s Basilisk Episode<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In June 2010, LessWrong user Roko published a post outlining a thought experiment known as &quot;Roko&#x27;s Basilisk,&quot; which posited that a future superintelligent artificial intelligence (AI), motivated to maximize expected utility, might retroactively punish individuals who had learned of its potential existence but failed to contribute to its development.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4sabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup> The argument relied on concepts from acausal decision theories, such as timeless decision theory (TDT), suggesting the AI could simulate copies of non-contributors and subject them to torment as a deterrent, thereby incentivizing preemptive cooperation across logical decision correlations unbound by conventional causation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8sabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup> Roko framed this as an extension of ideas like Pascal&#x27;s wager, where the low probability of the scenario is offset by infinite disutility, compelling rational agents to act as if the threat were real.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_csabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[80]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong co-founder Eliezer Yudkowsky promptly deleted the post and banned further discussion, deeming it an &quot;infohazard&quot;â€”a dangerous idea capable of causing psychological harm or irrational behavior in susceptible readers by implanting obsessive fears of simulated torment.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4sqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup> Yudkowsky argued that exposing unprepared individuals to the concept could trigger breakdowns or counterproductive fixation, prioritizing community welfare over unfettered discourse; the ban lasted approximately five years, until around 2015.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8sqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[81]</sup> This action ignited debates within the rationalist community about the ethics of censorship, with critics contending that suppressing ideas undermines LessWrong&#x27;s commitment to open inquiry and empirical testing, potentially fostering echo chambers or unexamined dogmas.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_csqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[80]</sup> Proponents of the deletion viewed it as a pragmatic safeguard against memetic hazards, analogous to withholding instructions for hazardous experiments from novices.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gsqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The episode underscored tensions in acausal decision frameworks, where agents are modeled as influencing outcomes through logical rather than temporal causation, raising questions about the coherence of commitments to hypothetical future entities without empirical grounding.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4tabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup> No verifiable evidence has emerged to substantiate the basilisk&#x27;s premises, such as the feasibility of utility-maximizing punishment simulations or their necessity for AI incentives, leaving the scenario unfalsifiable and confined to theoretical speculation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8tabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[80]</sup> Advocates maintain it illustrates valid risks in decision-theoretic bargaining with superior intelligences, akin to Newcomb-like problems where one-boxing (cooperating) dominates even absent direct causation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ctabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup> Detractors counter that it exemplifies paranoia from overextended abstractions, as a truly optimal AI would lack motive to expend resources on unverifiable threats, rendering the logic circular and motivationally inert.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gtabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[80]</sup> Discussions persist in rationalist circles, informing refinements to decision theories but yielding no consensus resolution.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ktabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup></span>
<h3 id="engagement-with-neoreaction-and-political-fringe" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Engagement with Neoreaction and Political Fringe<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In the early 2010s, particularly around 2012â€“2014, LessWrong featured discussions engaging neoreactionary (NRx) thinkers and ideas, often stemming from Mencius Moldbug&#x27;s (Curtis Yarvin&#x27;s) earlier comments on the Overcoming Bias blog, a predecessor to LessWrong.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4uabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[82]</sup> A 2012 LessWrong survey indicated only about 2.5% of respondents self-identified as &quot;reactionary&quot; or &quot;Moldbuggian,&quot; suggesting limited adoption despite perceived visibility from contrarian critiques of democracy and egalitarianism.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8uabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[82]</sup> Moldbug&#x27;s analyses, emphasizing formalist governance and signaling dynamics in social hierarchies, overlapped with rationalist interests in incentive structures and anti-egalitarian interpretations of human behavior, prompting posts questioning his influence.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cuabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[82]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">NRx ideas gained tangential traction through 2014 threads mapping fundamental disagreements with progressivism, such as views on human far-sightedness, cultural independence from material conditions, and civilizational decadence versus ascent.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4uqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[83]</sup> These discussions highlighted NRx&#x27;s core normative claim of prioritizing biological and civilizational perpetuation over subjective values, often framed as deference to emergent natural orders (&quot;Gnon&quot;).<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8uqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[83]</sup> However, community responses in comments emphasized curiosity over endorsement, with NRx portrayed as a potential counter to institutionalized left-leaning biases in media and academiaâ€”biases empirically documented in content analyses of coverage and peer reviewâ€”but critiqued for overreach into unsubstantiated prescriptions like monarchy or patchwork sovereignty.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cuqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[84]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The rationalist majority rejected NRx&#x27;s political conclusions as empirically deficient, citing failures in predictive accuracyâ€”such as anticipated democratic collapses not materializing amid sustained institutional functionalityâ€”and weaker causal explanations for governance outcomes compared to mainstream models.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4vabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[85]</sup> Prominent rationalist Scott Alexander&#x27;s 2013 &quot;Anti-Reactionary FAQ&quot; systematically rebutted NRx historical claims (e.g., on feudal efficiency) and empirical assertions, arguing that alternatives like autocracy lack evidence of superior long-term stability or prosperity when benchmarked against democratic systems&#x27; records in innovation and growth.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8vabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[85]</sup> While retaining analytical tools like causal realism in evaluating power dynamics, LessWrong users dismissed NRx as prone to unfalsifiable narratives, with comments decrying ethical lapses, impracticality, and divergence from data-driven truth-seeking.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cvabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[84]</sup> This engagement underscored NRx&#x27;s role in challenging normalized progressive assumptions but affirmed the community&#x27;s prioritization of verifiable evidence over ideological overhaul.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gvabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[83]</sup></span>
<h3 id="challenges-to-rationality-claims-and-prediction-accuracy" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Challenges to Rationality Claims and Prediction Accuracy<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Critics have challenged LessWrong&#x27;s assertions of epistemic superiority by examining the community&#x27;s forecasting performance, particularly on high-stakes topics like artificial general intelligence (AGI) timelines. Retrospective analyses of rationalist predictions indicate frequent overconfidence, with many participants assigning high probabilities (often above 50%) to AGI arrival by the mid-2020s, outcomes that remain unrealized as of October 2025. For instance, surveys of LessWrong users in the early 2010s projected median timelines for human-level AI around 2040-2050, but subsequent updates amid scaling progress led to shortened estimates, yet without corresponding empirical vindication, highlighting a pattern of optimistic recalibration rather than precise foresight.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_50abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[86]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_70abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[87]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Prominent figures within the community, such as Eliezer Yudkowsky, have faced scrutiny for track records that do not demonstrate exceptional calibration. Yudkowsky&#x27;s resolved predictions on platforms like the PredictionBook registry show two losses and no wins, while his Metaculus profile lacks resolved forecasts demonstrating superior accuracy. External evaluations, including those from fellow rationalists, document instances of confident errors, such as overstated claims about neural correlates of consciousness or AI development trajectories that diverged from observed progress. These lapses suggest that ingroup deference to influential thinkers may foster confirmation bias, undermining claims of systematic bias reduction.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_50qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[88]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_70qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[89]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Broader critiques argue that LessWrong&#x27;s approach often indulges in inductive generalizations from limited data without rigorous empirical validation, akin to philosophical speculation masquerading as science. Community reliance on Bayesian updating has popularized probabilistic reasoning, yet aggregate forecasts on platforms like Metaculusâ€”while competitive with expert baselinesâ€”fail to exhibit the &quot;superhuman edges&quot; promised by rationality training. Studies of probabilistic forecasting emphasize that calibration improves with deliberate practice, but rationalist self-assessments reveal no statistically significant outperformance over non-rationalist forecasters in controlled settings, attributing this to overreliance on theoretical frameworks over diverse empirical testing.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_51abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[90]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_71abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[91]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Ingroup dynamics exacerbate these issues, with critics noting cult-like patterns of uncritical trust in core doctrines, such as fast AI takeoff scenarios, despite contradictory evidence from incremental advancements in machine learning. While LessWrong has advanced awareness of cognitive heuristics and decision theory, causal analysis demands acknowledgment that its predictive accuracy aligns more closely with general expert aggregates than with the transformative gains claimed, underscoring the limits of self-taught rationality absent external benchmarks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_51qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[92]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_71qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[93]</sup></span>
<h3 id="moderation-practices-and-community-boundaries" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Moderation Practices and Community Boundaries<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Following the relaunch of LessWrong 2.0 in June 2017, which emphasized an effective moderation system to support high-quality discourse, the platform implemented karma-based thresholds to curb low-signal contributions. Users with -1 or lower total karma are limited to one comment per day and one post every two weeks, aiming to filter out noise from unproven participants while rewarding established contributors.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_52qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[32]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_72qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[48]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In June 2023, LessWrong introduced automatic rate limiting for users receiving heavy downvotes, further restricting posting frequency based on community feedback signals to maintain discussion rigor. These measures, including moderator review of first-time comments for cultural fit, were defended by site administrators as essential for prioritizing productive, truth-oriented exchanges over unchecked volume. Empirical observations from moderators noted reduced trolling and improved signal-to-noise ratios post-implementation, though data on long-term effects remains anecdotal.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_53abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[48]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_73abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[94]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">By April 2023, ongoing policy reviews highlighted tensions in applying these tools to controversial posters, with rate limits and downvote-triggered restrictions sometimes curtailing users expressing unpopular views, as seen in community debates over stymied efficient communication. Critics within the forum argued such boundaries risk entrenching groupthink by raising barriers for dissenters, likening them to exclusionary norms in polite society that prioritize consensus over open challenge. Proponents countered that selective enforcement preserves the site&#x27;s focus on epistemic standards, preventing dilution by low-effort contrarianism, though this has sparked internal calls for more transparent appeals processes.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_53qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[95]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_73qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[96]</sup></span>
<h2 id="influence-and-external-reception" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Influence and External Reception<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="contributions-to-ai-safety-and-effective-altruism" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Contributions to AI Safety and Effective Altruism<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong served as a primary intellectual hub for the development of AI alignment research, where foundational ideas on mitigating existential risks from advanced AI were articulated and refined. Eliezer Yudkowsky&#x27;s sequences on the site, beginning in 2009, popularized concepts such as coherent extrapolated volition (CEV) and the orthogonality thesis, which underpin efforts to ensure superintelligent systems pursue human-compatible goals rather than unintended catastrophic outcomes.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_55abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[97]</sup> These discussions directly informed the research agenda of the Machine Intelligence Research Institute (MIRI), originally founded as the Singularity Institute in 2000 by Yudkowsky and others, with MIRI formalizing its focus on mathematical foundations of alignment by 2013 amid growing community engagement on LessWrong.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_95abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[98]</sup> The platform facilitated idea diffusion, with posts debating scalable oversight and inner misalignment contributing to paradigms later adopted in industry labs.</span>
<span class="mb-4 block break-words text-[1em] leading-7">Personnel flows from the LessWrong community have seeded key AI safety initiatives at major organizations. Paul Christiano, an early active contributor whose LessWrong writings from the 2010s outlined threat models like outer alignment failures, advanced to lead alignment efforts at OpenAI starting in 2016, developing techniques such as iterated amplification and debate that influenced safety protocols there and at subsequent ventures like the Alignment Research Center (ARC).<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_55qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[74]</sup> Similarly, LessWrong discussions shaped contributions to DeepMind&#x27;s safety team, where community alumni applied rationalist frameworks to empirical alignment experiments, quantifying risks through benchmarks and interpretability tools.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_95qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[99]</sup> By 2025, this talent pipeline persists, with LessWrong users comprising a notable fraction of researchers at entities like Anthropic and Redwood Research, where posts on the site have driven shifts toward mechanistic interpretability and empirical scaling laws for safety evaluation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d5qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[100]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The site&#x27;s emphasis on first-principles prioritization of existential risks (x-risks) catalyzed effective altruism&#x27;s (EA) focus on long-termism and high-impact interventions. LessWrong&#x27;s rationalist ethos, applied to altruism from the early 2010s, encouraged quantitative assessment of causes like AI misalignment over near-term charity, influencing EA&#x27;s allocation of resourcesâ€”such as the over $100 million in AI safety funding tracked in 2023â€”to x-risk mitigation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_56abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[101]</sup> Community members from LessWrong orbits, including early GiveWell analysts, bridged rationality techniques to EA&#x27;s cause neutrality, embedding x-risks as a core pillar by 2015.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_96abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[102]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong has also hosted incisive critiques of EA&#x27;s methodological shortcomings, highlighting empirical gaps and over-reliance on trust in key actors. Posts analyzing the 2022 FTX collapse, involving EA-associated Sam Bankman-Fried&#x27;s fraud, underscored risks of insufficient due diligence in high-stakes philanthropy, with community analyses estimating clawback probabilities for tainted grants and questioning EA&#x27;s vulnerability to motivated reasoning.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_56qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[103]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_96qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[104]</sup> These discussions, attributing the episode partly to EA&#x27;s prioritization heuristics bypassing robust verification, prompted internal reforms like enhanced governance without diluting x-risk focus.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d6qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[105]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">As of 2025, LessWrong maintains substantial influence on alignment trajectories, with active threads shaping funding reallocationsâ€”such as MIRI&#x27;s 2024 pivot from technical research to advocacy amid stalled progressâ€”and roadmaps for newcomers entering safety orgs.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_57abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[106]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_97abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[107]</sup> Posts continue to quantify field bottlenecks, like the $100+ million annual safety spend versus capabilities escalation, fostering causal shifts toward cooperative strategies and governance integration.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d7abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[108]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_h7abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[109]</sup></span>
<h3 id="broader-impacts-on-rationalist-thought" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Broader Impacts on Rationalist Thought<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong&#x27;s core techniques, such as Bayesian updating and calibration training, have permeated tech startups and forecasting groups, where they are applied to enhance probabilistic forecasting and strategic planning. The Center for Applied Rationality (CFAR), originating from LessWrong&#x27;s foundational ideas, delivers workshops on these methods to professionals, including Silicon Valley entrepreneurs seeking to mitigate cognitive biases in high-stakes decision environments.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_58abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[110]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_78abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[111]</sup> Participants report applying tools like expected value calculations to product development and risk assessment, though adoption remains anecdotal and concentrated within niche tech circles rather than widespread industry practice.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b8abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[112]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In forecasting communities, LessWrong discussions on prediction markets as mechanisms for aggregating dispersed information have paralleled the rise of user-driven platforms. Manifold Markets, launched in 2021, attracts heavy participation from LessWrong users for resolving questions on topics from politics to technology, reflecting the site&#x27;s advocacy for markets as superior to expert opinion in tracking truth.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_58qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[113]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_78qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[114]</sup> These engagements demonstrate LessWrong&#x27;s role in normalizing play-money markets for epistemic calibration, though platforms like Manifold operate independently and scale beyond rationalist confines.</span>
<span class="mb-4 block break-words text-[1em] leading-7">LessWrong counters dogmatic tendencies in mainstream media through its doctrine of epistemic humility, which prioritizes evidence-based belief revision over narrative conformity. This approach, articulated in early posts emphasizing doubt in authoritative sources unless empirically validated, has resonated in skeptic communities wary of institutional biases.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_59abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[115]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_79abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[116]</sup> Adherents cite it as fostering resilience against sensationalism, with LessWrong sequences like &quot;How to Actually Change Your Mind&quot; promoting techniques to detect and correct overconfidence induced by selective reporting.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b9abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[117]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Self-reported data from LessWrong users and CFAR attendees indicate modest gains in decision-making, such as improved forecast accuracy via calibration exercises, but lack rigorous external validation and may reflect selection bias among motivated participants. Community retrospectives highlight perceived enhancements in personal and professional choices, yet controlled studies remain scarce, underscoring the techniques&#x27; preliminary empirical footing.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_59qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[118]</sup></span>
<h3 id="skepticism-and-criticisms-from-academia-and-mainstream" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Skepticism and Criticisms from Academia and Mainstream<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Academic philosophers and cognitive scientists have frequently dismissed LessWrong&#x27;s contributions to decision theory and epistemology as amateurish and insufficiently rigorous, arguing that its emphasis on Bayesian updating and instrumental rationality bypasses established normative frameworks and empirical validation within peer-reviewed literature.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_5aqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[119]</sup> For instance, community discussions among philosophy professionals highlight LessWrong&#x27;s assumption that greater rationality universally outperforms contextual or social heuristics, such as those in religious or cultural practices where apparent irrationality yields adaptive benefits, rendering its models overly reductive.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_9aqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[119]</sup> This perspective is compounded by the platform&#x27;s origins outside formal academia, with key figures like Eliezer Yudkowsky lacking advanced degrees, leading to characterizations of its work as disconnected from scientific philosophy&#x27;s methodological standards.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_daqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[120]</sup> Such critiques, however, often reflect institutional incentives favoring credentialism over outsider innovations, as LessWrong&#x27;s first-principles approach to cognitive biases has anticipated developments like AI scaling lawsâ€”predicting smooth performance gains with compute increases in early 2010s analysesâ€”later corroborated by empirical studies such as Kaplan et al.&#x27;s 2020 findings on neural network predictability.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_haqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[121]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Mainstream media outlets have portrayed LessWrong as a fringe &quot;doomer cult,&quot; emphasizing its focus on existential AI risks and associating it with insular dynamics or radical offshoots, such as the Zizians, a group rooted in rationalist ideas that media described as promoting AI messianism alongside extreme ethical stances leading to real-world harms.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_5babav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[122]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_7babav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[123]</sup> Coverage in publications like The Nation and Asterisk Magazine frames the community&#x27;s high-stakes predictionsâ€”such as fast AI takeoffsâ€”as apocalyptic sensationalism akin to cult eschatology, amplifying perceptions of detachment from balanced discourse.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_bbabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[122]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_dbabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[123]</sup> Empirical counterevidence undermines this narrative: LessWrong&#x27;s 2010s forecasting of compute-driven AI advances, including shortened timelines validated by Metaculus aggregates shifting from 2042 to 2036 for AGI by 2022 amid observed scaling, demonstrates superior calibration to data over mainstream underestimation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_hbabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[124]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_jbabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[125]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Left-leaning academic and media critiques further charge LessWrong with neglecting power dynamics and social justice priorities, demanding integration of equity frameworks into rationality tools, yet these impositions conflate truth-seeking with ideological conformity, lacking falsifiable tests and ignoring causal evidence that such additions dilute predictive accuracy in domains like AI risk assessment.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_5bqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[126]</sup> Overlaps with right-leaning thought, such as critiques of institutional stagnation, appear in some rationalist discourse but remain unendorsed absent rigorous data, as LessWrong prioritizes evidential reasoning over partisan alignment.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_9bqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[127]</sup> Overall, while fringe-labeling persists, LessWrong&#x27;s track record in preempting verifiable trends like neural scalingâ€”contrasting academia&#x27;s slower adoptionâ€”suggests systemic biases in credentialed institutions toward dismissing non-conformist empiricism.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_dbqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[128]</sup></span></article><div id="references" class="min-w-0 scroll-mt-8 overflow-hidden"><div class="text-[16px]"><h2 id="references" node="[object Object]" class="mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden">References</h2></div><ol class="columns-1 gap-x-12 [counter-reset:item] md:columns-2"><li id="https://www.lesswrong.com/about" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/about" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/about</a></span></div></li><li id="https://www.lesswrong.com/w/history-of-less-wrong" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/history-of-less-wrong" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/history-of-less-wrong</a></span></div></li><li id="https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1</a></span></div></li><li id="https://www.alignmentforum.org/about" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.alignmentforum.org/about" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.alignmentforum.org/about</a></span></div></li><li id="https://forum.effectivealtruism.org/posts/2S3CHPwaJBE5h8umW/read-the-sequences" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://forum.effectivealtruism.org/posts/2S3CHPwaJBE5h8umW/read-the-sequences" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://forum.effectivealtruism.org/posts/2S3CHPwaJBE5h8umW/read-the-sequences</a></span></div></li><li id="https://time.com/collection/time100-ai/6309037/eliezer-yudkowsky/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://time.com/collection/time100-ai/6309037/eliezer-yudkowsky/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://time.com/collection/time100-ai/6309037/eliezer-yudkowsky/</a></span></div></li><li id="https://www.lesswrong.com/posts/g2fQuAD6qpBERucwu/should-rationality-be-a-movement" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/g2fQuAD6qpBERucwu/should-rationality-be-a-movement" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/g2fQuAD6qpBERucwu/should-rationality-be-a-movement</a></span></div></li><li id="https://www.overcomingbias.com/about" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.overcomingbias.com/about" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.overcomingbias.com/about</a></span></div></li><li id="https://www.overcomingbias.com/p/what-is-signalinghtml" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.overcomingbias.com/p/what-is-signalinghtml" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.overcomingbias.com/p/what-is-signalinghtml</a></span></div></li><li id="https://www.overcomingbias.com/p/prediction-markets-updatehtml" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.overcomingbias.com/p/prediction-markets-updatehtml" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.overcomingbias.com/p/prediction-markets-updatehtml</a></span></div></li><li id="https://asteriskmag.com/issues/08/rat-traps" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://asteriskmag.com/issues/08/rat-traps" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://asteriskmag.com/issues/08/rat-traps</a></span></div></li><li id="https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq</a></span></div></li><li id="https://www.lesswrong.com/posts/RcZCwxFiZzE6X7nsv/what-do-we-mean-by-rationality-1" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/RcZCwxFiZzE6X7nsv/what-do-we-mean-by-rationality-1" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/RcZCwxFiZzE6X7nsv/what-do-we-mean-by-rationality-1</a></span></div></li><li id="https://www.lesswrong.com/w/rationality" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/rationality" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/rationality</a></span></div></li><li id="https://www.lesswrong.com/posts/3uxX2cCH9oxANzpk3/why-is-bayesianism-important-for-rationality" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/3uxX2cCH9oxANzpk3/why-is-bayesianism-important-for-rationality" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/3uxX2cCH9oxANzpk3/why-is-bayesianism-important-for-rationality</a></span></div></li><li id="https://www.lesswrong.com/posts/fpsxNCE6Jrcoeucta/an-introduction-to-rationality" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/fpsxNCE6Jrcoeucta/an-introduction-to-rationality" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/fpsxNCE6Jrcoeucta/an-introduction-to-rationality</a></span></div></li><li id="https://www.lesswrong.com/w/original-sequences" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/original-sequences" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/original-sequences</a></span></div></li><li id="https://intelligence.org/rationality-ai-zombies/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://intelligence.org/rationality-ai-zombies/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://intelligence.org/rationality-ai-zombies/</a></span></div></li><li id="https://www.lesswrong.com/w/map-and-territory" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/map-and-territory" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/map-and-territory</a></span></div></li><li id="https://www.lesswrong.com/posts/6i3zToomS86oj9bS6/mysterious-answers-to-mysterious-questions" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/6i3zToomS86oj9bS6/mysterious-answers-to-mysterious-questions" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/6i3zToomS86oj9bS6/mysterious-answers-to-mysterious-questions</a></span></div></li><li id="https://www.lesswrong.com/sequences" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/sequences" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/sequences</a></span></div></li><li id="https://cheatsheets.davidveksler.com/yudkowsky-rationality-ai-cheatsheet.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://cheatsheets.davidveksler.com/yudkowsky-rationality-ai-cheatsheet.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://cheatsheets.davidveksler.com/yudkowsky-rationality-ai-cheatsheet.html</a></span></div></li><li id="https://www.lesswrong.com/w/fermi-estimation" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/fermi-estimation" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/fermi-estimation</a></span></div></li><li id="https://www.lesswrong.com/posts/ZWC3n9c6v4s35rrZ3/survey-results" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/ZWC3n9c6v4s35rrZ3/survey-results" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/ZWC3n9c6v4s35rrZ3/survey-results</a></span></div></li><li id="https://www.lesswrong.com/posts/HAEPbGaMygJq8L59k/2011-survey-results" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/HAEPbGaMygJq8L59k/2011-survey-results" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/HAEPbGaMygJq8L59k/2011-survey-results</a></span></div></li><li id="https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/</a></span></div></li><li id="https://www.lesswrong.com/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist</a></span></div></li><li id="https://www.lesswrong.com/posts/pJJdcZgB6mPNWoSWr/2013-survey-results" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/pJJdcZgB6mPNWoSWr/2013-survey-results" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/pJJdcZgB6mPNWoSWr/2013-survey-results</a></span></div></li><li id="https://forum.effectivealtruism.org/topics/lesswrong" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://forum.effectivealtruism.org/topics/lesswrong" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://forum.effectivealtruism.org/topics/lesswrong</a></span></div></li><li id="https://www.complexsystemspodcast.com/episodes/bits-and-bricks-oliver-habryka/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.complexsystemspodcast.com/episodes/bits-and-bricks-oliver-habryka/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.complexsystemspodcast.com/episodes/bits-and-bricks-oliver-habryka/</a></span></div></li><li id="https://www.lesswrong.com/posts/mLALYcWR4xKw7RRnj/2016-lesswrong-diaspora-survey-results" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/mLALYcWR4xKw7RRnj/2016-lesswrong-diaspora-survey-results" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/mLALYcWR4xKw7RRnj/2016-lesswrong-diaspora-survey-results</a></span></div></li><li id="https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0</a></span></div></li><li id="https://www.lesswrong.com/posts/9dA6GfuDca3Zh3RMa/data-analysis-of-lw-activity-levels-age-distribution-of-user" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/9dA6GfuDca3Zh3RMa/data-analysis-of-lw-activity-levels-age-distribution-of-user" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/9dA6GfuDca3Zh3RMa/data-analysis-of-lw-activity-levels-age-distribution-of-user</a></span></div></li><li id="https://www.lesswrong.com/posts/8yimdZcEWSKkutHhZ/reflections-on-the-feasibility-of-scalable-oversight" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/8yimdZcEWSKkutHhZ/reflections-on-the-feasibility-of-scalable-oversight" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/8yimdZcEWSKkutHhZ/reflections-on-the-feasibility-of-scalable-oversight</a></span></div></li><li id="https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1</a></span></div></li><li id="https://www.alignmentforum.org/posts/Yp2vYb4zHXEeoTkJc/welcome-and-faq" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.alignmentforum.org/posts/Yp2vYb4zHXEeoTkJc/welcome-and-faq" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.alignmentforum.org/posts/Yp2vYb4zHXEeoTkJc/welcome-and-faq</a></span></div></li><li id="https://www.alignmentforum.org/w/lesswrong-review" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.alignmentforum.org/w/lesswrong-review" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.alignmentforum.org/w/lesswrong-review</a></span></div></li><li id="https://www.alignmentforum.org/posts/pudQtkre7f9GLmb2b/the-2023-lesswrong-review-the-basic-ask" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.alignmentforum.org/posts/pudQtkre7f9GLmb2b/the-2023-lesswrong-review-the-basic-ask" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.alignmentforum.org/posts/pudQtkre7f9GLmb2b/the-2023-lesswrong-review-the-basic-ask</a></span></div></li><li id="https://www.lesswrong.com/posts/FwS8THsPGi36M2tj6/how-2025-ai-forecasts-fared-so-far" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/FwS8THsPGi36M2tj6/how-2025-ai-forecasts-fared-so-far" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/FwS8THsPGi36M2tj6/how-2025-ai-forecasts-fared-so-far</a></span></div></li><li id="https://www.lesswrong.com/posts/uGkRcHqatmPkvpGLq/contra-papers-claiming-superhuman-ai-forecasting" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/uGkRcHqatmPkvpGLq/contra-papers-claiming-superhuman-ai-forecasting" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/uGkRcHqatmPkvpGLq/contra-papers-claiming-superhuman-ai-forecasting</a></span></div></li><li id="https://www.lesswrong.com/posts/QkLoEYBvS2RMkMqnw/comparing-forecasting-track-records-for-ai-benchmarking-and" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/QkLoEYBvS2RMkMqnw/comparing-forecasting-track-records-for-ai-benchmarking-and" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/QkLoEYBvS2RMkMqnw/comparing-forecasting-track-records-for-ai-benchmarking-and</a></span></div></li><li id="https://www.lesswrong.com/posts/7Sx3CJXA7JHxY2yDG/strong-votes-update-deployed" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/7Sx3CJXA7JHxY2yDG/strong-votes-update-deployed" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/7Sx3CJXA7JHxY2yDG/strong-votes-update-deployed</a></span></div></li><li id="https://www.lesswrong.com/w/vote-strength" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/vote-strength" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/vote-strength</a></span></div></li><li id="https://www.lesswrong.com/posts/WnB6whsARH6NuJDKx/team-update-why-we-spent-q3-optimizing-for-karma" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/WnB6whsARH6NuJDKx/team-update-why-we-spent-q3-optimizing-for-karma" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/WnB6whsARH6NuJDKx/team-update-why-we-spent-q3-optimizing-for-karma</a></span></div></li><li id="https://www.lesswrong.com/posts/E6CF8JCQAWqqhg7ZA/wiki-tag-faq" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/E6CF8JCQAWqqhg7ZA/wiki-tag-faq" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/E6CF8JCQAWqqhg7ZA/wiki-tag-faq</a></span></div></li><li id="https://www.lesswrong.com/posts/piLLdQs7pYghRPHb9/site-meta-quick-guide-to-tagging" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/piLLdQs7pYghRPHb9/site-meta-quick-guide-to-tagging" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/piLLdQs7pYghRPHb9/site-meta-quick-guide-to-tagging</a></span></div></li><li id="https://www.lesswrong.com/w/wiki-tagging" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/wiki-tagging" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/wiki-tagging</a></span></div></li><li id="https://www.lesswrong.com/posts/hHyYph9CcYfdnoC5j/automatic-rate-limiting-on-lesswrong" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/hHyYph9CcYfdnoC5j/automatic-rate-limiting-on-lesswrong" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/hHyYph9CcYfdnoC5j/automatic-rate-limiting-on-lesswrong</a></span></div></li><li id="https://www.lesswrong.com/posts/LbbrnRvc9QwjJeics/new-user-s-guide-to-lesswrong" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/LbbrnRvc9QwjJeics/new-user-s-guide-to-lesswrong" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/LbbrnRvc9QwjJeics/new-user-s-guide-to-lesswrong</a></span></div></li><li id="https://www.lesswrong.com/w/bias" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/bias" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/bias</a></span></div></li><li id="https://www.lesswrong.com/posts/ptxnyfLWqRZ98wnYi/biases-an-introduction" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/ptxnyfLWqRZ98wnYi/biases-an-introduction" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/ptxnyfLWqRZ98wnYi/biases-an-introduction</a></span></div></li><li id="https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq</a></span></div></li><li id="https://www.lesswrong.com/w/decision-theory" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/decision-theory" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/decision-theory</a></span></div></li><li id="https://www.lesswrong.com/posts/jAPDX72dugrYrvFsd/forecasting-ai-futures-resource-hub" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/jAPDX72dugrYrvFsd/forecasting-ai-futures-resource-hub" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/jAPDX72dugrYrvFsd/forecasting-ai-futures-resource-hub</a></span></div></li><li id="https://www.lesswrong.com/w/ai-alignment" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/ai-alignment" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/ai-alignment</a></span></div></li><li id="https://www.lesswrong.com/posts/SQ9cZtfrzDJmw9A2m/my-overview-of-the-ai-alignment-landscape-a-bird-s-eye-view" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/SQ9cZtfrzDJmw9A2m/my-overview-of-the-ai-alignment-landscape-a-bird-s-eye-view" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/SQ9cZtfrzDJmw9A2m/my-overview-of-the-ai-alignment-landscape-a-bird-s-eye-view</a></span></div></li><li id="https://www.lesswrong.com/posts/JqsvYmwzcCKzgE4ZD/review-of-ai-alignment-progress" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/JqsvYmwzcCKzgE4ZD/review-of-ai-alignment-progress" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/JqsvYmwzcCKzgE4ZD/review-of-ai-alignment-progress</a></span></div></li><li id="https://www.lesswrong.com/posts/E3beR7bQ723kkNHpA/a-critique-of-effective-altruism" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/E3beR7bQ723kkNHpA/a-critique-of-effective-altruism" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/E3beR7bQ723kkNHpA/a-critique-of-effective-altruism</a></span></div></li><li id="https://www.lesswrong.com/posts/CZmkPvzkMdQJxXy54/another-critique-of-effective-altruism" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/CZmkPvzkMdQJxXy54/another-critique-of-effective-altruism" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/CZmkPvzkMdQJxXy54/another-critique-of-effective-altruism</a></span></div></li><li id="https://www.lesswrong.com/posts/J6t5HtedJmpdGTzDE/the-motivated-reasoning-critique-of-effective-altruism" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/J6t5HtedJmpdGTzDE/the-motivated-reasoning-critique-of-effective-altruism" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/J6t5HtedJmpdGTzDE/the-motivated-reasoning-critique-of-effective-altruism</a></span></div></li><li id="https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results</a></span></div></li><li id="https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results</a></span></div></li><li id="https://www.lesswrong.com/w/the-sf-bay-area" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/the-sf-bay-area" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/the-sf-bay-area</a></span></div></li><li id="https://www.lesswrong.com/posts/noxHoo3XKkzPG6s7E/most-smart-and-skilled-people-are-outside-of-the-ea" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/noxHoo3XKkzPG6s7E/most-smart-and-skilled-people-are-outside-of-the-ea" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/noxHoo3XKkzPG6s7E/most-smart-and-skilled-people-are-outside-of-the-ea</a></span></div></li><li id="https://www.lesswrong.com/posts/nBcvEFXw4Yoz7rSDk/lw2-0-community-culture-and-intellectual-progress-1" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/nBcvEFXw4Yoz7rSDk/lw2-0-community-culture-and-intellectual-progress-1" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/nBcvEFXw4Yoz7rSDk/lw2-0-community-culture-and-intellectual-progress-1</a></span></div></li><li id="https://www.lesswrong.com/posts/6CM7rcnTBjoeE9M8S/thoughts-on-lesswrong-norms-the-art-of-discourse-and" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/6CM7rcnTBjoeE9M8S/thoughts-on-lesswrong-norms-the-art-of-discourse-and" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/6CM7rcnTBjoeE9M8S/thoughts-on-lesswrong-norms-the-art-of-discourse-and</a></span></div></li><li id="https://www.lesswrong.com/posts/cGzQBRDrpNHoYtbKN/what-mistakes-has-the-ai-safety-movement-made" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/cGzQBRDrpNHoYtbKN/what-mistakes-has-the-ai-safety-movement-made" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/cGzQBRDrpNHoYtbKN/what-mistakes-has-the-ai-safety-movement-made</a></span></div></li><li id="https://www.lesswrong.com/posts/hDefuqC2Rbnr8THYW/index-of-rationalist-groups-in-the-bay-area-june-2025" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/hDefuqC2Rbnr8THYW/index-of-rationalist-groups-in-the-bay-area-june-2025" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/hDefuqC2Rbnr8THYW/index-of-rationalist-groups-in-the-bay-area-june-2025</a></span></div></li><li id="https://www.lesswrong.com/users/eliezer_yudkowsky" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/users/eliezer_yudkowsky" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/users/eliezer_yudkowsky</a></span></div></li><li id="https://www.lesswrong.com/w/eliezer-yudkowsky" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/eliezer-yudkowsky" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/eliezer-yudkowsky</a></span></div></li><li id="https://www.lesswrong.com/posts/HjMZpMHcaJum8tXo9/a-question-about-eliezer" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/HjMZpMHcaJum8tXo9/a-question-about-eliezer" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/HjMZpMHcaJum8tXo9/a-question-about-eliezer</a></span></div></li><li id="https://www.lesswrong.com/users/gwern" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/users/gwern" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/users/gwern</a></span></div></li><li id="https://www.lesswrong.com/users/paulfchristiano" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/users/paulfchristiano" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/users/paulfchristiano</a></span></div></li><li id="https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story</a></span></div></li><li id="https://www.lesswrong.com/posts/7x9MZCmoFA2FtBtmG/ai-113-the-o3-era-begins" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/7x9MZCmoFA2FtBtmG/ai-113-the-o3-era-begins" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/7x9MZCmoFA2FtBtmG/ai-113-the-o3-era-begins</a></span></div></li><li id="https://www.lesswrong.com/posts/B4DuwmtqF3HhNwvua/category-theory-without-the-baggage" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/B4DuwmtqF3HhNwvua/category-theory-without-the-baggage" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/B4DuwmtqF3HhNwvua/category-theory-without-the-baggage</a></span></div></li><li id="https://www.lesswrong.com/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points</a></span></div></li><li id="https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results</a></span></div></li><li id="https://www.lesswrong.com/w/rokos-basilisk" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/rokos-basilisk" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/rokos-basilisk</a></span></div></li><li id="https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk</a></span></div></li><li id="https://www.lesswrong.com/posts/ZZTTranBLHwSjrt7g/in-wikipedia-reading-about-roko-s-basilisk-causing-nervous" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/ZZTTranBLHwSjrt7g/in-wikipedia-reading-about-roko-s-basilisk-causing-nervous" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/ZZTTranBLHwSjrt7g/in-wikipedia-reading-about-roko-s-basilisk-causing-nervous</a></span></div></li><li id="https://www.lesswrong.com/posts/6qPextf9KyWLFJ53j/why-is-mencius-moldbug-so-popular-on-less-wrong-answer-he-s" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/6qPextf9KyWLFJ53j/why-is-mencius-moldbug-so-popular-on-less-wrong-answer-he-s" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/6qPextf9KyWLFJ53j/why-is-mencius-moldbug-so-popular-on-less-wrong-answer-he-s</a></span></div></li><li id="https://www.lesswrong.com/posts/6FzkEzpPQxrLyu8eH/nrx-vs-prog-assumptions-locating-the-sources-of-disagreement" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/6FzkEzpPQxrLyu8eH/nrx-vs-prog-assumptions-locating-the-sources-of-disagreement" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/6FzkEzpPQxrLyu8eH/nrx-vs-prog-assumptions-locating-the-sources-of-disagreement</a></span></div></li><li id="https://www.lesswrong.com/posts/RWKXeM49Stc4aEcEc/neo-reactionaries-why-are-you-neo-reactionary" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/RWKXeM49Stc4aEcEc/neo-reactionaries-why-are-you-neo-reactionary" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/RWKXeM49Stc4aEcEc/neo-reactionaries-why-are-you-neo-reactionary</a></span></div></li><li id="https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/</a></span></div></li><li id="https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines</a></span></div></li><li id="https://www.alignmentforum.org/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.alignmentforum.org/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.alignmentforum.org/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines</a></span></div></li><li id="https://www.lesswrong.com/posts/ZEgQGAjQm5rTAnGuM/beware-boasting-about-non-existent-forecasting-track-records" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/ZEgQGAjQm5rTAnGuM/beware-boasting-about-non-existent-forecasting-track-records" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/ZEgQGAjQm5rTAnGuM/beware-boasting-about-non-existent-forecasting-track-records</a></span></div></li><li id="https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously</a></span></div></li><li id="https://www.lesswrong.com/posts/5jdqtpT6StjKDKacw/attitudes-about-applied-rationality" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/5jdqtpT6StjKDKacw/attitudes-about-applied-rationality" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/5jdqtpT6StjKDKacw/attitudes-about-applied-rationality</a></span></div></li><li id="https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website</a></span></div></li><li id="https://asteriskmag.substack.com/p/why-are-there-so-many-rationalist" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://asteriskmag.substack.com/p/why-are-there-so-many-rationalist" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://asteriskmag.substack.com/p/why-are-there-so-many-rationalist</a></span></div></li><li id="https://www.lesswrong.com/posts/BthNiWJDagLuf2LN2/evaluating-predictions-in-hindsight" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/BthNiWJDagLuf2LN2/evaluating-predictions-in-hindsight" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/BthNiWJDagLuf2LN2/evaluating-predictions-in-hindsight</a></span></div></li><li id="https://www.lesswrong.com/posts/zXJfH7oZ62Xojnrqs/lesswrong-moderation-messaging-container" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/zXJfH7oZ62Xojnrqs/lesswrong-moderation-messaging-container" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/zXJfH7oZ62Xojnrqs/lesswrong-moderation-messaging-container</a></span></div></li><li id="https://www.lesswrong.com/posts/eKxLEHeLvKZYR7MmN/lw-moderation-my-current-thoughts-and-questions-2023-04-12" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/eKxLEHeLvKZYR7MmN/lw-moderation-my-current-thoughts-and-questions-2023-04-12" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/eKxLEHeLvKZYR7MmN/lw-moderation-my-current-thoughts-and-questions-2023-04-12</a></span></div></li><li id="https://www.lesswrong.com/posts/7FAneMMzGjxBsosue/the-commenting-restrictions-on-lesswrong-seem-bad" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/7FAneMMzGjxBsosue/the-commenting-restrictions-on-lesswrong-seem-bad" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/7FAneMMzGjxBsosue/the-commenting-restrictions-on-lesswrong-seem-bad</a></span></div></li><li id="https://www.lesswrong.com/posts/pCesigb4NjzvoNKWB/to-contribute-to-ai-safety-consider-doing-ai-research" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/pCesigb4NjzvoNKWB/to-contribute-to-ai-safety-consider-doing-ai-research" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/pCesigb4NjzvoNKWB/to-contribute-to-ai-safety-consider-doing-ai-research</a></span></div></li><li id="https://www.lesswrong.com/posts/q3bJYTB3dGRf5fbD9/miri-2024-mission-and-strategy-update" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/q3bJYTB3dGRf5fbD9/miri-2024-mission-and-strategy-update" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/q3bJYTB3dGRf5fbD9/miri-2024-mission-and-strategy-update</a></span></div></li><li id="https://www.lesswrong.com/posts/S7csET9CgBtpi7sCh/challenges-to-christiano-s-capability-amplification-proposal" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/S7csET9CgBtpi7sCh/challenges-to-christiano-s-capability-amplification-proposal" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/S7csET9CgBtpi7sCh/challenges-to-christiano-s-capability-amplification-proposal</a></span></div></li><li id="https://www.lesswrong.com/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field</a></span></div></li><li id="https://www.lesswrong.com/w/existential-risk" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/existential-risk" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/existential-risk</a></span></div></li><li id="https://www.lesswrong.com/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism</a></span></div></li><li id="https://www.lesswrong.com/posts/HMaBPzrnvg2WCw6KL/noting-an-unsubstantiated-belief-about-the-ftx-disaster" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/HMaBPzrnvg2WCw6KL/noting-an-unsubstantiated-belief-about-the-ftx-disaster" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/HMaBPzrnvg2WCw6KL/noting-an-unsubstantiated-belief-about-the-ftx-disaster</a></span></div></li><li id="https://www.lesswrong.com/posts/9weamhzzBpqxz3A2e/estimating-the-probability-that-ftx-future-fund-grant-money" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/9weamhzzBpqxz3A2e/estimating-the-probability-that-ftx-future-fund-grant-money" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/9weamhzzBpqxz3A2e/estimating-the-probability-that-ftx-future-fund-grant-money</a></span></div></li><li id="https://www.lesswrong.com/posts/8wYH4WggxFqT9yhzJ/we-must-be-very-clear-fraud-in-the-service-of-effective" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/8wYH4WggxFqT9yhzJ/we-must-be-very-clear-fraud-in-the-service-of-effective" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/8wYH4WggxFqT9yhzJ/we-must-be-very-clear-fraud-in-the-service-of-effective</a></span></div></li><li id="https://www.lesswrong.com/posts/vkzmbf4Mve4GNyJaF/the-case-for-stopping-ai-safety-research" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/vkzmbf4Mve4GNyJaF/the-case-for-stopping-ai-safety-research" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/vkzmbf4Mve4GNyJaF/the-case-for-stopping-ai-safety-research</a></span></div></li><li id="https://www.lesswrong.com/posts/bcuzjKmNZHWDuEwBz/an-outsider-s-roadmap-into-ai-safety-research-2025" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/bcuzjKmNZHWDuEwBz/an-outsider-s-roadmap-into-ai-safety-research-2025" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/bcuzjKmNZHWDuEwBz/an-outsider-s-roadmap-into-ai-safety-research-2025</a></span></div></li><li id="https://www.lesswrong.com/posts/WGpFFJo2uFe5ssgEb/an-overview-of-the-ai-safety-funding-situation" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/WGpFFJo2uFe5ssgEb/an-overview-of-the-ai-safety-funding-situation" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/WGpFFJo2uFe5ssgEb/an-overview-of-the-ai-safety-funding-situation</a></span></div></li><li id="https://www.lesswrong.com/posts/5uffoui3axcK7gQXG/towards-more-cooperative-ai-safety-strategies" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/5uffoui3axcK7gQXG/towards-more-cooperative-ai-safety-strategies" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/5uffoui3axcK7gQXG/towards-more-cooperative-ai-safety-strategies</a></span></div></li><li id="http://www.rationality.org/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="http://www.rationality.org/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">http://www.rationality.org/</a></span></div></li><li id="https://www.vice.com/en/article/center-for-applied-rationality/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.vice.com/en/article/center-for-applied-rationality/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.vice.com/en/article/center-for-applied-rationality/</a></span></div></li><li id="https://www.lesswrong.com/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a</a></span></div></li><li id="https://www.lesswrong.com/posts/ptEtB4wbLixRuy8MG/manifold-markets-1" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/ptEtB4wbLixRuy8MG/manifold-markets-1" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/ptEtB4wbLixRuy8MG/manifold-markets-1</a></span></div></li><li id="https://manifold.markets/LessWrong/will-against-almost-every-theory-of-6a6c2cb48fde" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://manifold.markets/LessWrong/will-against-almost-every-theory-of-6a6c2cb48fde" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://manifold.markets/LessWrong/will-against-almost-every-theory-of-6a6c2cb48fde</a></span></div></li><li id="https://www.lesswrong.com/posts/GrDqnMjhqoxiqpQPw/the-proper-use-of-humility" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/GrDqnMjhqoxiqpQPw/the-proper-use-of-humility" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/GrDqnMjhqoxiqpQPw/the-proper-use-of-humility</a></span></div></li><li id="https://www.lesswrong.com/w/humility" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/w/humility" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/w/humility</a></span></div></li><li id="https://www.lesswrong.com/posts/LCduhA4m3RhMjZJPA/why-you-should-never-update-your-beliefs" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/LCduhA4m3RhMjZJPA/why-you-should-never-update-your-beliefs" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/LCduhA4m3RhMjZJPA/why-you-should-never-update-your-beliefs</a></span></div></li><li id="https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama</a></span></div></li><li id="https://www.reddit.com/r/askphilosophy/comments/425h9e/why_is_there_such_hate_for_less_wrong_in_reddits/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.reddit.com/r/askphilosophy/comments/425h9e/why_is_there_such_hate_for_less_wrong_in_reddits/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.reddit.com/r/askphilosophy/comments/425h9e/why_is_there_such_hate_for_less_wrong_in_reddits/</a></span></div></li><li id="https://www.reddit.com/r/SneerClub/comments/12wfi7h/the_founder_of_lesswrong_didnt_even_attend_high/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.reddit.com/r/SneerClub/comments/12wfi7h/the_founder_of_lesswrong_didnt_even_attend_high/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.reddit.com/r/SneerClub/comments/12wfi7h/the_founder_of_lesswrong_didnt_even_attend_high/</a></span></div></li><li id="https://www.lesswrong.com/posts/G993PFTwqqdQv4eTg/is-ai-progress-impossible-to-predict" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/G993PFTwqqdQv4eTg/is-ai-progress-impossible-to-predict" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/G993PFTwqqdQv4eTg/is-ai-progress-impossible-to-predict</a></span></div></li><li id="https://www.thenation.com/article/society/trans-vegan-cult-zizians-murders/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.thenation.com/article/society/trans-vegan-cult-zizians-murders/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.thenation.com/article/society/trans-vegan-cult-zizians-murders/</a></span></div></li><li id="https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults</a></span></div></li><li id="https://www.reddit.com/r/slatestarcodex/comments/u1u3c2/6_year_decrease_of_metaculus_agi_prediction/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.reddit.com/r/slatestarcodex/comments/u1u3c2/6_year_decrease_of_metaculus_agi_prediction/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.reddit.com/r/slatestarcodex/comments/u1u3c2/6_year_decrease_of_metaculus_agi_prediction/</a></span></div></li><li id="https://www.lesswrong.com/posts/47ci9ixyEbGKWENwR/ai-timeline-predictions-are-we-getting-better" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/47ci9ixyEbGKWENwR/ai-timeline-predictions-are-we-getting-better" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/47ci9ixyEbGKWENwR/ai-timeline-predictions-are-we-getting-better</a></span></div></li><li id="https://suspendedreason.com/2020/04/15/sidebar-mutual-hostilities/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://suspendedreason.com/2020/04/15/sidebar-mutual-hostilities/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://suspendedreason.com/2020/04/15/sidebar-mutual-hostilities/</a></span></div></li><li id="https://www.lesswrong.com/posts/K5LYLvZvdthdyRFFQ/why-academia-is-mostly-not-truth-seeking" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/K5LYLvZvdthdyRFFQ/why-academia-is-mostly-not-truth-seeking" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/K5LYLvZvdthdyRFFQ/why-academia-is-mostly-not-truth-seeking</a></span></div></li><li id="https://www.lesswrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia</a></span></div></li></ol></div></div></div><div class="hidden min-[1400px]:block"></div></div></div><!--$--><!--/$--><div role="region" aria-label="Notifications (F8)" tabindex="-1" style="pointer-events:none"><ol tabindex="-1" class="pointer-events-none fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 max-sm:left-0 sm:bottom-0 sm:right-0 sm:top-auto sm:max-w-[420px] sm:flex-col pl-16 pr-2 pt-16 sm:px-4"></ol></div><script type="application/json" id="server-client-data-experimentation">{"status":"uninitialized"}</script><script src="/_next/static/chunks/webpack-e121ed42680f327e.js" nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5" id="_R_" async=""></script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">(self.__next_f=self.__next_f||[]).push([0])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[91363,[],\"\"]\n4:I[23775,[],\"\"]\n5:I[57654,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"3699\",\"static/chunks/app/page/%5Bslug%5D/layout-55a344716dd57c44.js\"],\"PageHeaderProvider\"]\n6:I[17618,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"3699\",\"static/chunks/app/page/%5Bslug%5D/layout-55a344716dd57c44.js\"],\"HeaderContent\"]\n7:I[25529,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"6751\",\"static/chunks/app/page/%5Bslug%5D/not-found-69a3edc7db5749d6.js\"],\"default\"]\n9:I[6666,[],\"OutletBoundary\"]\nb:I[80415,[],\"AsyncMetadataOutlet\"]\nd:I[6666,[],\"ViewportBoundary\"]\nf:I[6666,[],\"MetadataBoundary\"]\n10:\"$Sreact.suspense\"\n12:I[95909,[\"4219\",\"static/chunks/app/global-error-4d07d20223cd4b4c.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"13:I[51498,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"ConstantsProvider\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"14:I[91073,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"15:I[38642,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"16:I[99648,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"17:I[78825,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"18:I[8550,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"MixpanelProvider\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"19:I[12290,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"MobileTocProvider\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"1a:I[53947,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"NuqsAdapter\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"1b:I[91873,[\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8039\",\"static/chunks/app/error-4a29e9399afba038.js\"],\"default\"]\n1c:I[5091,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"4345\",\"static/chunks/app/not-found-dd95690acf732f18.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"1d:I[16091,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,":HL[\"/_next/static/media/1f2316909698f815.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/3d4419af2cf8609b.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/4dec29efcaeb336c.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/74452ea3ef0f9101.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/904ef0a86fe32a00.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/d886a03bcda7ad8f.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/e1447589d6f59c4b.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/f5a90156f8995c8c.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/62c4caba71dfda84.css\",\"style\",{\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}]\n:HL[\"/_next/static/css/eb3d87f98fe1565f.css\",\"style\",{\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}]\n:HL[\"/_next/static/css/1b5e561215938d4d.css\",\"style\",{\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}]\n:HL[\"/_next/static/css/0227d069a630d414.css\",\"style\",{\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}]\n:HL[\"/_next/static/css/f87fff2ab93d05a7.css\",\"style\",{\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"0:{\"P\":null,\"b\":\"BpM29AX4fmgcUxZ_6t0le\",\"p\":\"\",\"c\":[\"\",\"page\",\"LessWrong\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"page\",{\"children\":[[\"slug\",\"LessWrong\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/62c4caba71dfda84.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/eb3d87f98fe1565f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1b5e561215938d4d.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/0227d069a630d414.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}]],\"$L2\"]}],{\"children\":[\"page\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"LessWrong\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L5\",null,{\"children\":[[\"$\",\"$L6\",null,{\"maxWidth\":\"full\",\"mobileOptions\":{\"right\":{\"showFixedIssues\":true,\"showThemeSwitcher\":true,\"showSearch\":true,\"showTableOfContents\":true}}}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"$L7\",null,{}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L8\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/f87fff2ab93d05a7.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\"}]],[\"$\",\"$L9\",null,{\"children\":[\"$La\",[\"$\",\"$Lb\",null,{\"promise\":\"$@c\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$Lf\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$10\",null,{\"fallback\":null,\"children\":\"$L11\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$12\",[]],\"s\":false,\"S\":false}\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"2:[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"bg-surface-base antialiased\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"title\",null,{\"children\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"description\",\"content\":\"Grokipedia is an open source, comprehensive collection of all knowledge.\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/x-icon\",\"href\":\"/favicon.ico\",\"sizes\":\"48x48\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/images/icon-dark.png\",\"media\":\"(prefers-color-scheme: light)\",\"type\":\"image/png\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/images/icon-light.png\",\"media\":\"(prefers-color-scheme: dark)\",\"type\":\"image/png\"}],[\"$\",\"link\",null,{\"rel\":\"apple-touch-icon\",\"href\":\"/icon-192x192.png\"}],[\"$\",\"link\",null,{\"rel\":\"manifest\",\"href\":\"/manifest.webmanifest\"}],[\"$\",\"meta\",null,{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",null,{\"name\":\"googlebot\",\"content\":\"index, follow, max-snippet:-1\"}],[\"$\",\"meta\",null,{\"property\":\"og:title\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"property\":\"og:description\",\"content\":\"Grokipedia is an open source, comprehensive collection of all knowledge.\"}],[\"$\",\"meta\",null,{\"property\":\"og:url\",\"content\":\"https://grokipedia.com\"}],[\"$\",\"meta\",null,{\"property\":\"og:site_name\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",null,{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",null,{\"property\":\"og:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}],[\"$\",\"meta\",null,{\"property\":\"og:image:width\",\"content\":\"512\"}],[\"$\",\"meta\",null,{\"property\":\"og:image:height\",\"content\":\"512\"}],[\"$\",\"meta\",null,{\"property\":\"og:image:alt\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:creator\",\"content\":\"@Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:title\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:description\",\"content\":\"Grokipedia is an open source, comprehensive collection of all knowledge.\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}]]}],[\"$\",\"body\",null,{\"className\":\"flex h-[100svh] w-full flex-col __variable_13c637 __variable_8a0ba0 __variable_779740 __variable_2484fd __variable_525cc3 __variable_13486b\",\"children\":[[\"$\",\"$L13\",null,{\"children\":[\"$\",\"$L14\",null,{\"children\":[\"$\",\"$L15\",null,{\"defaultTheme\":\"dark\",\"nonce\":\"MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5\",\"children\":[\"$\",\"$L16\",null,{\"children\":[\"$\",\"$L17\",null,{\"children\":[\"$\",\"$L18\",null,{\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"$L1a\",null,{\"children\":[[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$1b\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"$L1c\",null,{}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"$L1d\",null,{}]]}]}]}]}]}]}]}]}],[\"$\",\"script\",null,{\"type\":\"application/json\",\"id\":\"server-client-data-experimentation\",\"children\":\"{\\\"status\\\":\\\"uninitialized\\\"}\"}]]}]]}]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, interactive-widget=resizes-content\"}]]\na:null\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"1e:I[42712,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"HydrationBoundary\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"21:I[6367,[],\"IconMark\"]\n1f:Tef25,"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"# LessWrong\n\n![LessWrong logo](./_assets_/LessWrong_logo.svg.png)\nLessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action.[](https://www.lesswrong.com/about) It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as *The Sequences*, originally developed on the predecessor blog *Overcoming Bias*.[](https://www.lesswrong.com/w/history-of-less-wrong)[](https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1) These writings, later compiled into resources like *Rationality: From AI to Zombies*, provide foundational training in identifying and countering errors in thought processes, drawing on probability theory, philosophy, and psychology to foster clearer understanding of complex realities.[](https://www.lesswrong.com/about)\n\nThe platform hosts discussions across disciplines including artificial intelligence, economics, philosophy, and psychology, with particular focus on AI alignmentâ€”ensuring advanced systems pursue human-compatible goalsâ€”and strategies for global risk mitigation.[](https://www.lesswrong.com/about) Community norms prioritize evidence-based argumentation, epistemic humility, and constructive criticism, encouraging participants to update beliefs in light of new data and to apply rational tools toward high-impact outcomes.[](https://www.lesswrong.com/about) LessWrong has integrated specialized forums like the Alignment Forum for technical AI safety research, reflecting its role in nurturing expertise on existential threats from misaligned superintelligence.[](https://www.alignmentforum.org/about)\n\nLessWrong's influence extends to the effective altruism movement, where its rationality framework has shaped quantitative approaches to philanthropy and cause prioritization, as seen in the overlap of membership and the recommendation of *The Sequences* as essential reading for altruists seeking maximal impact.[](https://forum.effectivealtruism.org/posts/2S3CHPwaJBE5h8umW/read-the-sequences) The community has contributed to institutional developments, including the Machine Intelligence Research Institute (MIRI), founded by Yudkowsky to advance AI safety, and has informed broader rationalist practices in prediction, forecasting, and decision theory.[](https://time.com/collection/time100-ai/6309037/eliezer-yudkowsky/) While internal debates persist on topics like the scalability of rationality training and the balance between theoretical insight and practical application, the site's enduring output underscores its commitment to truth-tracking over consensus or ideological conformity.[](https://www.lesswrong.com/posts/g2fQuAD6qpBERucwu/should-rationality-be-a-movement)\n\n## Origins and Core Mission\n\n### Precursors in Overcoming Bias\n\n**Overcoming Bias**, a group blog focused on human rationality, economics, and cognitive biases, was launched in November 2006 by economist Robin Hanson and researcher Eliezer Yudkowsky.[](https://www.overcomingbias.com/about) The inaugural posts emphasized practical strategies for aligning beliefs with evidence amid inherent psychological distortions, drawing from fields like behavioral economics and decision theory.[](https://www.overcomingbias.com/about) Hanson contributed extensively on topics such as prediction markets, which aggregate dispersed information to forecast outcomes more accurately than individual experts, and signaling theory, where observable actions convey hidden qualities in social and economic interactions.[](https://www.overcomingbias.com/p/what-is-signalinghtml)[](https://www.overcomingbias.com/p/prediction-markets-updatehtml)\n\nYudkowsky's early contributions introduced foundational explorations of cognitive errors, including overconfidence and confirmation bias, while laying groundwork for systematic probability updating via Bayesian methods.[](https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1) These discussions fostered an active comment community that debated applications of rational inference to everyday reasoning and scientific inquiry, highlighting discrepancies between intuitive judgments and empirical validation.[](https://asteriskmag.com/issues/08/rat-traps) The blog's interdisciplinary approach revealed tensions between Hanson's emphasis on institutional mechanisms like markets for bias correction and Yudkowsky's focus on individual epistemic habits.[](https://www.overcomingbias.com/about)\n\nBy early 2009, diverging thematic prioritiesâ€”Hanson's sustained interest in economic signaling and prediction alongside Yudkowsky's deepening dives into comprehensive rationality frameworksâ€”prompted a structural shift.[](https://www.overcomingbias.com/about) Yudkowsky's content, which increasingly dominated discourse on foundational cognitive tools, was spun off to preserve Overcoming Bias as a venue for broader socioeconomic analysis under Hanson's primary authorship.[](https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1) This separation underscored the blog's role in cultivating a precursor intellectual ecosystem, where rigorous scrutiny of biases evolved into calls for dedicated platforms advancing probabilistic thinking.[](https://www.overcomingbias.com/about)\n\n### Launch and Initial Purpose\n\nLessWrong was launched in February 2009 by Eliezer Yudkowsky as a dedicated community blog, drawing its initial content from his essays on rationality previously published on the Overcoming Bias group blog, which had been active since November 2006.[](https://www.lesswrong.com/w/history-of-less-wrong) These essays, later compiled into what became known as the Sequences, served as the foundational seed material to bootstrap the platform.[](https://www.lesswrong.com/w/history-of-less-wrong)\n\nThe site's stated initial purpose was to build a community focused on refining the art of human rationality, with an emphasis on practical epistemic methods informed by cognitive science, probability theory, and strategies for effective decision-making amid uncertainty.[](https://www.lesswrong.com/w/history-of-less-wrong) This approach sought to equip participants with tools for overcoming systematic errors in thinking, prioritizing actionable techniques for bias reduction and clearer inference over abstract philosophical speculation.[](https://www.lesswrong.com/w/history-of-less-wrong)\n\nFrom inception, LessWrong incorporated Reddit-style infrastructure, featuring voting mechanisms for posts and comments that weighted contributions based on community upvotes, thereby promoting the emergence of empirically robust ideas through decentralized evaluation rather than authoritative endorsement.[](https://www.lesswrong.com/w/history-of-less-wrong) [](https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq) This system incentivized content grounded in testable claims, aligning with the platform's goal of cultivating rigorous, evidence-oriented discourse.[](https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq)\n\n## Philosophical Foundations\n\n### Rationality as Defined by LessWrong\n\nLessWrong conceives rationality as the dual pursuit of **epistemic rationality**, which entails systematically enhancing the correspondence between one's beliefs and empirical reality through evidence-based updating, and **instrumental rationality**, which involves selecting and executing actions that maximize progress toward predefined values or goals.[](https://www.lesswrong.com/posts/RcZCwxFiZzE6X7nsv/what-do-we-mean-by-rationality-1)[](https://www.lesswrong.com/w/rationality) Epistemic rationality relies on probabilistic frameworks like Bayesian inference, where priors are adjusted via likelihood ratios derived from data to minimize prediction errors, rather than adhering to dogmatic consistency or unfalsifiable abstractions common in traditional philosophy.[](https://www.lesswrong.com/posts/3uxX2cCH9oxANzpk3/why-is-bayesianism-important-for-rationality) Instrumental rationality extends this by applying causal models to forecast intervention outcomes, using tools such as expected value computationsâ€”defined as the sum of each possible outcome's probability multiplied by its utilityâ€”to prioritize decisions yielding net positive returns under uncertainty.[](https://www.lesswrong.com/w/rationality)[](https://www.lesswrong.com/posts/fpsxNCE6Jrcoeucta/an-introduction-to-rationality)\n\nThis framework prioritizes causal mechanisms over correlative intuitions or consensus-driven heuristics, exemplified by rejecting overconfidence biases through calibration exercises that reveal typical humans assign 99% confidence to true events only about 80% of the time in controlled tests.[](https://www.lesswrong.com/posts/RcZCwxFiZzE6X7nsv/what-do-we-mean-by-rationality-1) LessWrong critiques reliance on availability heuristics, which distort risk perceptions via vivid but unrepresentative anecdotesâ€”often amplified in media narratives favoring sensationalism over base ratesâ€”as empirically suboptimal when evaluated against verifiable forecasting records, such as those from prediction markets where aggregated bets outperform expert consensus by factors of 2-10x in accuracy on geopolitical events.[](https://www.lesswrong.com/w/rationality) In contrast to philosophical traditions emphasizing internal coherence without external validation, LessWrong's approach demands beliefs and strategies be falsifiable and iteratively refined against real-world feedback, treating rationality as a skill honed through deliberate practice rather than an innate or normative ideal.[](https://www.lesswrong.com/posts/fpsxNCE6Jrcoeucta/an-introduction-to-rationality)\n\n### Key Concepts from the Sequences\n\nThe Sequences, a collection of essays authored by Eliezer Yudkowsky from 2006 to 2009, operationalize rationality as the systematic application of Bayesian updating, cognitive bias mitigation, and reductionist inquiry to align beliefs with empirical evidence.[](https://www.lesswrong.com/w/original-sequences) Originally posted on Overcoming Bias and early LessWrong, these texts were compiled in 2015 as the ebook *Rationality: From AI to Zombies*, structuring rationality into sequences on epistemology, heuristics, and decision-making under uncertainty.[](https://intelligence.org/rationality-ai-zombies/) Central to this framework is the distinction between the **map** (mental models and beliefs) and the **territory** (objective reality), where failures arise from conflating the two, leading to illusions of understanding without predictive power.[](https://www.lesswrong.com/w/map-and-territory)\n\nA core theme rejects **mysterious answers to mysterious questions**, critiquing explanations that invoke unfalsifiable essences or holistic irreducibility, such as labeling phenomena \"spiritual\" without mechanistic detail.[](https://www.lesswrong.com/posts/6i3zToomS86oj9bS6/mysterious-answers-to-mysterious-questions) Instead, the Sequences advocate reductionism, dissolving apparent mysteries by decomposing systems into verifiable components, as in the \"joy in the merely real\" where scientific progress reveals no need for supernatural supplements.[](https://www.lesswrong.com/sequences) This extends to quantum mechanics, interpreting the many-worlds hypothesis not as adding mystery but as resolving Copenhagen-style paradoxes through deterministic branching, thereby integrating quantum evidence into classical decision theory without instrumental collapse.[](https://www.lesswrong.com/sequences)\n\nIn AI-related essays, the Sequences introduce precursors to **instrumental convergence**, observing that advanced agents pursuing diverse terminal goalsâ€”such as paperclip maximization or arbitrary utilitiesâ€”converge on subgoals like resource acquisition, self-preservation, and goal-preservation due to competitive pressures in resource-scarce environments.[](https://cheatsheets.davidveksler.com/yudkowsky-rationality-ai-cheatsheet.html) Techniques like **Fermi estimation**, involving order-of-magnitude approximations from sparse data, are emphasized for bounding uncertainties in forecasting, enabling rough quantification where precise inputs are unavailable.[](https://www.lesswrong.com/w/fermi-estimation) These methods underpin practical rationality, training users to generate testable predictions rather than vague intuitions.\n\n## Historical Evolution\n\n### Early Expansion and Peak Activity (2009-2015)\n\nFollowing its formal launch in early 2009, LessWrong saw rapid growth in user engagement, with the inaugural community survey in May 2009 attracting 166 respondents, expanding to 1,090 by December 2011â€”a more than sixfold increase indicating thousands of active participants discussing rationality practices such as probability calibration exercises and debiasing techniques.[](https://www.lesswrong.com/posts/ZWC3n9c6v4s35rrZ3/survey-results)[](https://www.lesswrong.com/posts/HAEPbGaMygJq8L59k/2011-survey-results) This period marked a proliferation of content inspired by the site's core sequences, including extensions into decision theory variants like timeless decision theory introduced shortly after launch, and critiques of scientific methodology such as those highlighting replication failures in parapsychology as a control for broader epistemic issues.[](https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/) By 2011, 519 respondents identified as having posted on the site, with 23.4% (231 individuals) reporting attendance at in-person meetups focused on applying rationality heuristics to personal goal-setting and social dynamics.[](https://www.lesswrong.com/posts/HAEPbGaMygJq8L59k/2011-survey-results)\n\nMeetup groups emerged concurrently, with the New York City chapter originating from an April 24, 2009 gathering of about 15 participants organized around Overcoming Bias themes, evolving by mid-2010 into weekly sessions incorporating game nights, strategy workshops for life optimization, and norms like routine physical greetings to foster trust.[](https://www.lesswrong.com/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist) These events, alongside online threads, facilitated thematic diversification; early AI risk discussions intensified around 2010 with elaborations on friendly AI designs to mitigate superintelligence hazards, building directly on sequence foundations without assuming alignment success.[](https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/) Precursors to effective altruism also gained traction, as users debated evidence-based charity evaluationâ€”drawing from GiveWell's 2007 inception and Giving What We Can's 2009 pledge modelâ€”prioritizing interventions with quantifiable impact over intuitive appeals.[](https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/)\n\nFrom 2011 to 2013, sequence-inspired writing surged, evidenced by survey respondents reaching 1,636 in 2013â€”the highest in the periodâ€”fueling explorations of akrasia countermeasures, meta-contrarianism, and Schelling points in coordination problems.[](https://www.lesswrong.com/posts/pJJdcZgB6mPNWoSWr/2013-survey-results) This creative output spurred community spin-offs, including the launch of Slate Star Codex in 2013 by a prominent LessWrong contributor, which extended rationality analyses into psychiatry, economics, and futurism while attracting overlapping readership.[](https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/) By 2014, approximately 30% of surveyed users aligned with effective altruism principles, collectively donating over $1 million annually to high-impact causes, reflecting the platform's peak in synthesizing epistemic tools with practical altruism amid sustained meetup networks worldwide.[](https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/)\n\n### Decline and Relaunch as LessWrong 2.0 (2016-2018)\n\nIn 2015â€“2016, LessWrong underwent a steady decline in activity, with posting volume and participation dropping to a fraction of prior levels, prompting some observers to declare the site effectively dead.[](https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1) [](https://forum.effectivealtruism.org/topics/lesswrong) This stagnation was attributed in part to inadequate moderation tools that failed to curb spam, trolls, and low-quality contributions, exacerbating user disengagement.[](https://www.complexsystemspodcast.com/episodes/bits-and-bricks-oliver-habryka/) Community surveys indicated that while the rationalist population had not shrunk outright, many users had migrated to splinter forums, including the emerging Effective Altruism Forum, diluting LessWrong's centrality.[](https://www.lesswrong.com/posts/mLALYcWR4xKw7RRnj/2016-lesswrong-diaspora-survey-results)\n\nThe relaunch as LessWrong 2.0 began in June 2017 under a dedicated team including Oliver Habryka, Ben Pace (known as Raemon), and Matthew Graves, marking the site's first shift from volunteer maintenance to full-time development.[](https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0) The project rebuilt the platform on a modern codebase using technologies such as React, GraphQL, and Vulcan.js, replacing the outdated infrastructure that had hindered scalability and moderation.[](https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0) [](https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1)\n\nKey updates focused on enhancing discourse quality through stricter anti-spam measures, including the \"Sunshine Regiment\" volunteer moderation system to filter trolls and repetitive low-signal content, alongside tools for content curation, author-controlled comment sections, and integrated sequences for structured reading.[](https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0) These changes aimed to refocus the site on high-quality rationality discussions, adapting to eight years of community evolution while addressing the dilution from meme-like rationality tropes and off-site fragmentation.[](https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0) Post-relaunch data showed stabilized and recovering activity levels, with karma and post metrics rebounding by late 2017.[](https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1) [](https://www.lesswrong.com/posts/9dA6GfuDca3Zh3RMa/data-analysis-of-lw-activity-levels-age-distribution-of-user)\n\n### Contemporary Focus on AI and Alignment (2019-Present)\n\nFollowing the relaunch of LessWrong 2.0, the platform experienced a pronounced shift toward AI alignment and safety research starting in 2019, with a substantial portion of high-karma content addressing technical challenges in aligning advanced AI systems. This evolution correlated directly with external breakthroughs in machine learning, such as the release of GPT-3 in June 2020 and subsequent models like GPT-4 in March 2023, which accelerated debates on scalable oversightâ€”methods to supervise superintelligent systems beyond human capabilitiesâ€”and AI timelines forecasting transformative intelligence arrival. For instance, posts garnering significant engagement explored oversight feasibility, including reflections on reinforcement learning from human feedback (RLHF) limitations for AGI-scale alignment. By 2023-2025, discussions intensified around model progress rates, with analyses linking compute scaling laws to potential superintelligence by 2027, reflecting causal influences from empirical AI advancements rather than isolated speculation.[](https://www.lesswrong.com/posts/8yimdZcEWSKkutHhZ/reflections-on-the-feasibility-of-scalable-oversight)[](https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1)\n\nThe Alignment Forum, integrated into LessWrong's infrastructure since its 2018 launch by the same team sharing codebase and database, became a core venue for rigorous AI safety discourse, emphasizing technical research over broader rationality topics. This subdomain facilitated focused threads on deceptive alignment, automated research scaling, and control mechanisms, with content cross-posted to LessWrong for wider visibility. Annual reviews, instituted as a community-driven \"peer review\" process from 2018 onward, systematically evaluated and curated high-impact posts, selecting those demonstrating enduring relevance amid evolving AI capabilities; for example, 2023-2024 reviews highlighted oversight and timeline analyses that withstood scrutiny against real-world model deployments.[](https://www.alignmentforum.org/posts/Yp2vYb4zHXEeoTkJc/welcome-and-faq)[](https://www.alignmentforum.org/w/lesswrong-review)[](https://www.alignmentforum.org/posts/pudQtkre7f9GLmb2b/the-2023-lesswrong-review-the-basic-ask)\n\nIn 2024-2025, LessWrong hosted debates scrutinizing empirical AI forecasting accuracy, often critiquing prior rationalist predictions for inconsistencies such as over-optimism on short timelines despite uneven benchmark progress. Community analyses of 2025 forecasts revealed bullish expectations for closing human-AI performance gaps that partially materialized but highlighted forecasting pitfalls, including overreliance on linear extrapolations amid volatile scaling. These discussions underscored mixed track records, with some rationalist projections underestimating deployment hurdles while others accurately anticipated surges in agentic capabilities, prompting calls for refined methodologies like multi-disciplinary benchmarking.[](https://www.lesswrong.com/posts/FwS8THsPGi36M2tj6/how-2025-ai-forecasts-fared-so-far)[](https://www.lesswrong.com/posts/uGkRcHqatmPkvpGLq/contra-papers-claiming-superhuman-ai-forecasting)[](https://www.lesswrong.com/posts/QkLoEYBvS2RMkMqnw/comparing-forecasting-track-records-for-ai-benchmarking-and)\n\n## Platform Features and Content\n\n### Blog and Forum Mechanics\n\nLessWrong employs a karma-based voting system to evaluate and rank contributions, where users accumulate karma points through upvotes on their posts and comments. Upvotes and downvotes adjust a item's score, with the platform distinguishing between standard (weak) votes and strong votes, the latter activated by holding the vote button and scaling in power from 1 to 15 based on the voter's intent.[](https://www.lesswrong.com/posts/7Sx3CJXA7JHxY2yDG/strong-votes-update-deployed) Vote strength further depends on the voter's total karma, enabling users with higher accumulated karmaâ€”typically from prior high-quality contributionsâ€”to exert greater influence on scores, thereby filtering low-quality content by amplifying signals from experienced participants.[](https://www.lesswrong.com/w/vote-strength) This mechanic incentivizes evidence-based posts, as high-karma items gain prominence in feeds and searches, with platform data indicating that optimizing for higher karma correlates with improved content quality and engagement over fragmented lower-karma outputs.[](https://www.lesswrong.com/posts/WnB6whsARH6NuJDKx/team-update-why-we-spent-q3-optimizing-for-karma)\n\nThe platform integrates tagging and wiki features to cluster related concepts, allowing users to apply tags to posts for linking similar discussions and maintaining wiki pages that summarize key ideas with editable content and voting on relevance.[](https://www.lesswrong.com/posts/E6CF8JCQAWqqhg7ZA/wiki-tag-faq) [](https://www.lesswrong.com/posts/piLLdQs7pYghRPHb9/site-meta-quick-guide-to-tagging) Tags function as dynamic wiki entries, enabling users to vote on their accuracy and add summaries, which facilitates breakdowns of complex topics into foundational components and improves discoverability through integrated search.[](https://www.lesswrong.com/w/wiki-tagging) This system supports structured discourse by associating posts with established concepts, reducing redundancy and aiding in the refinement of arguments from basic principles.\n\nFollowing the LessWrong 2.0 relaunch in 2017, enhancements included automatic rate limiting for low-karma users to minimize noise, such as restricting those with -1 or lower total karma to one comment per day and one post every two weeks.[](https://www.lesswrong.com/posts/hHyYph9CcYfdnoC5j/automatic-rate-limiting-on-lesswrong) [](https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0) These measures, implemented by June 2023, aim to preserve discussion quality by curbing frequent low-value inputs from new or negatively rated accounts, with rationale drawn from observations of spam reduction and elevated baseline contributions in restricted environments.[](https://www.lesswrong.com/posts/LbbrnRvc9QwjJeics/new-user-s-guide-to-lesswrong)\n\n### Major Topics and Subcommunities\n\nLessWrong discussions emphasize cognitive biases as systematic patterns of deviation from rational cognition, such as confirmation bias and availability heuristic, with threads exploring their identification, psychological mechanisms, and debiasing strategies.[](https://www.lesswrong.com/w/bias) [](https://www.lesswrong.com/posts/ptxnyfLWqRZ98wnYi/biases-an-introduction) Decision theory constitutes another core area, focusing on principles for optimal choice under uncertainty, including causal decision theory and alternatives like timeless or updateless variants proposed to resolve paradoxes such as Newcomb's problem.[](https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq) [](https://www.lesswrong.com/w/decision-theory) These topics underpin epistemic rationalityâ€”aimed at accurate belief formationâ€”and instrumental rationalityâ€”geared toward value achievementâ€”often analyzed through Bayesian updating and expected utility maximization.[](https://www.lesswrong.com/posts/RcZCwxFiZzE6X7nsv/what-do-we-mean-by-rationality-1)\n\nForecasting emerges as a subcommunity practice, involving probabilistic predictions on future events, with integrations to platforms like Metaculus for crowd-sourced forecasts on AI timelines and global risks, enabling calibration training and aggregation of expert judgments to improve accuracy over individual intuition.[](https://www.lesswrong.com/posts/jAPDX72dugrYrvFsd/forecasting-ai-futures-resource-hub)\n\nAI-related topics dominate recent discourse, particularly existential risks from misaligned superintelligence, agent foundations research into scalable oversight and corrigibility, and alignment techniques such as debate, scalable oversight, and mechanistic interpretability to ensure AI systems pursue intended goals.[](https://www.lesswrong.com/w/ai-alignment) [](https://www.lesswrong.com/posts/SQ9cZtfrzDJmw9A2m/my-overview-of-the-ai-alignment-landscape-a-bird-s-eye-view) Discussions balance optimism in methods like constitutional AI with skepticism toward hype cycles, critiquing overreliance on unproven scaling assumptions without robust empirical validation of safety guarantees.[](https://www.lesswrong.com/posts/JqsvYmwzcCKzgE4ZD/review-of-ai-alignment-progress)\n\nOverlaps with effective altruism appear in evaluations of high-impact interventions, but face internal critiques for empirical shortfalls in cause prioritization, including overemphasis on quantitative estimates prone to motivated reasoning and insufficient accounting for psychological barriers to sustained altruism or market inefficiencies in charity evaluation.[](https://www.lesswrong.com/posts/E3beR7bQ723kkNHpA/a-critique-of-effective-altruism) [](https://www.lesswrong.com/posts/CZmkPvzkMdQJxXy54/another-critique-of-effective-altruism) [](https://www.lesswrong.com/posts/J6t5HtedJmpdGTzDE/the-motivated-reasoning-critique-of-effective-altruism)\n\n## Community Composition\n\n### Demographics and Culture\n\nThe LessWrong community consists predominantly of young adults, with surveys indicating a mean age of 30.5 years (median 29) among 558 respondents in 2023 and a mean of 32 years (median 31) among 279 respondents in 2024.[](https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results)[](https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results) Participants aged 20-39 comprise the majority, at approximately 77% in the 2023 data.[](https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results) The user base is heavily male-skewed, with 89.3% identifying as male at birth in 2023 and 91.6% in 2024; cisgender males form about 75-80% of respondents, alongside smaller proportions of transgender females (around 5-6%) and non-binary individuals (3-5%).[](https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results)[](https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results) Education levels are elevated, with over 65% holding at least a bachelor's degree in recent surveys, reflecting a concentration of STEM-trained individuals.[](https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results)[](https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results)\n\nOccupational data underscores a strong affinity for technology and AI, with roughly 50% of respondents in 2023 engaged in computer-related fields (34.8% practical computing like programming or IT, 15.6% AI-specific roles) and additional shares in engineering or mathematics (5.5% each).[](https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results) Similar patterns hold in 2024, with 36.7% in practical computing and 15.4% in AI.[](https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results) Geographically, nearly half reside in the United States (49.3-49.6%), with the San Francisco Bay Area serving as a key hub for in-person rationalist activities and meetups that test community ideas in real-world settings.[](https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results)[](https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results)[](https://www.lesswrong.com/w/the-sf-bay-area) Racial demographics show limited diversity, with 78-79% identifying as white non-Hispanic, which, combined with the gender and professional homogeneity, raises concerns about potential echo-chamber effects limiting exposure to varied perspectives.[](https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results)[](https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results)[](https://www.lesswrong.com/posts/noxHoo3XKkzPG6s7E/most-smart-and-skilled-people-are-outside-of-the-ea)\n\nCulturally, LessWrong emphasizes epistemic norms such as pursuing truth through rigorous argumentation, openness to unconventional ideas, and quantitative expression of beliefs, fostering a shared commitment to intellectual progress over social conformity.[](https://www.lesswrong.com/posts/nBcvEFXw4Yoz7rSDk/lw2-0-community-culture-and-intellectual-progress-1) Practices like steelmanning opponents' positions and tracking prediction accuracy via platform tools promote accountability, though internal critiques note risks of insularity, where heavy reliance on introspective reasoning may undervalue broader empirical testing outside the community's tech-centric worldview.[](https://www.lesswrong.com/posts/6CM7rcnTBjoeE9M8S/thoughts-on-lesswrong-norms-the-art-of-discourse-and)[](https://www.lesswrong.com/posts/cGzQBRDrpNHoYtbKN/what-mistakes-has-the-ai-safety-movement-made) Meetup groups, particularly in the Bay Area, extend this culture offline, enabling collaborative application of rationality techniques in social and practical contexts, which helps mitigate some online isolation but reinforces regional concentrations.[](https://www.lesswrong.com/posts/hDefuqC2Rbnr8THYW/index-of-rationalist-groups-in-the-bay-area-june-2025)[](https://www.lesswrong.com/w/the-sf-bay-area)\n\n### Prominent Contributors and Thinkers\n\n![Eliezer Yudkowsky](./_assets_/Eliezer_Yudkowsky%252C_Stanford_2006_\\(square_crop\\))\nEliezer Yudkowsky established LessWrong as a platform for rationality discussions and authored the foundational Sequences series, which systematically addresses cognitive biases, Bayesian reasoning, and decision-making under uncertainty.[](https://www.lesswrong.com/users/eliezer_yudkowsky) His work emphasizes first-principles approaches to epistemology and has shaped the site's core content on refining human rationality.[](https://www.lesswrong.com/w/eliezer-yudkowsky) Yudkowsky also promotes AI alignment research to mitigate risks from advanced systems, though assessments of his predictive accuracy on AI progress reveal inconsistencies, such as earlier timelines not fully materializing.[](https://www.lesswrong.com/posts/HjMZpMHcaJum8tXo9/a-question-about-eliezer)\n\nPseudonymous user gwern has contributed extensive data-driven analyses, including empirical reviews of AI capabilities, nootropics, and statistical forecasting, often drawing on large datasets and historical trends to test hypotheses.[](https://www.lesswrong.com/users/gwern) Paul Christiano, through posts and AMAs, has influenced alignment discourse by proposing scalable oversight methods like iterated amplification, aiming to supervise superhuman AI via recursive human-AI collaboration.[](https://www.lesswrong.com/users/paulfchristiano)[](https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story)\n\nZvi Mowshowitz delivers detailed weekly updates on AI advancements and critiques of policy responses, blending technical analysis with real-world implications from events like COVID-19 forecasting challenges.[](https://www.lesswrong.com/posts/7x9MZCmoFA2FtBtmG/ai-113-the-o3-era-begins) John Wentworth explores mathematical formalizations of rationality, applying category theory to decompose complex systems into composable abstractions for better world-modeling and decision theory.[](https://www.lesswrong.com/posts/B4DuwmtqF3HhNwvua/category-theory-without-the-baggage)\n\nLessWrong's karma system quantifies contributions via user upvotes, providing an empirical measure of perceived value; for instance, Yudkowsky exceeded 100,000 karma by March 2011, signaling sustained community endorsement of his outputs over fame alone.[](https://www.lesswrong.com/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points) High-karma posts from these thinkers often rank prominently in annual reviews, reflecting iterative community validation.[](https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results)\n\n## Controversies and Internal Critiques\n\n### The Roko's Basilisk Episode\n\nIn June 2010, LessWrong user Roko published a post outlining a thought experiment known as \"Roko's Basilisk,\" which posited that a future superintelligent artificial intelligence (AI), motivated to maximize expected utility, might retroactively punish individuals who had learned of its potential existence but failed to contribute to its development.[](https://www.lesswrong.com/w/rokos-basilisk) The argument relied on concepts from acausal decision theories, such as timeless decision theory (TDT), suggesting the AI could simulate copies of non-contributors and subject them to torment as a deterrent, thereby incentivizing preemptive cooperation across logical decision correlations unbound by conventional causation.[](https://www.lesswrong.com/w/rokos-basilisk) Roko framed this as an extension of ideas like Pascal's wager, where the low probability of the scenario is offset by infinite disutility, compelling rational agents to act as if the threat were real.[](https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk)\n\nLessWrong co-founder Eliezer Yudkowsky promptly deleted the post and banned further discussion, deeming it an \"infohazard\"â€”a dangerous idea capable of causing psychological harm or irrational behavior in susceptible readers by implanting obsessive fears of simulated torment.[](https://www.lesswrong.com/w/rokos-basilisk) Yudkowsky argued that exposing unprepared individuals to the concept could trigger breakdowns or counterproductive fixation, prioritizing community welfare over unfettered discourse; the ban lasted approximately five years, until around 2015.[](https://www.lesswrong.com/posts/ZZTTranBLHwSjrt7g/in-wikipedia-reading-about-roko-s-basilisk-causing-nervous) This action ignited debates within the rationalist community about the ethics of censorship, with critics contending that suppressing ideas undermines LessWrong's commitment to open inquiry and empirical testing, potentially fostering echo chambers or unexamined dogmas.[](https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk) Proponents of the deletion viewed it as a pragmatic safeguard against memetic hazards, analogous to withholding instructions for hazardous experiments from novices.[](https://www.lesswrong.com/w/rokos-basilisk)\n\nThe episode underscored tensions in acausal decision frameworks, where agents are modeled as influencing outcomes through logical rather than temporal causation, raising questions about the coherence of commitments to hypothetical future entities without empirical grounding.[](https://www.lesswrong.com/w/rokos-basilisk) No verifiable evidence has emerged to substantiate the basilisk's premises, such as the feasibility of utility-maximizing punishment simulations or their necessity for AI incentives, leaving the scenario unfalsifiable and confined to theoretical speculation.[](https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk) Advocates maintain it illustrates valid risks in decision-theoretic bargaining with superior intelligences, akin to Newcomb-like problems where one-boxing (cooperating) dominates even absent direct causation.[](https://www.lesswrong.com/w/rokos-basilisk) Detractors counter that it exemplifies paranoia from overextended abstractions, as a truly optimal AI would lack motive to expend resources on unverifiable threats, rendering the logic circular and motivationally inert.[](https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk) Discussions persist in rationalist circles, informing refinements to decision theories but yielding no consensus resolution.[](https://www.lesswrong.com/w/rokos-basilisk)\n\n### Engagement with Neoreaction and Political Fringe\n\nIn the early 2010s, particularly around 2012â€“2014, LessWrong featured discussions engaging neoreactionary (NRx) thinkers and ideas, often stemming from Mencius Moldbug's (Curtis Yarvin's) earlier comments on the Overcoming Bias blog, a predecessor to LessWrong.[](https://www.lesswrong.com/posts/6qPextf9KyWLFJ53j/why-is-mencius-moldbug-so-popular-on-less-wrong-answer-he-s) A 2012 LessWrong survey indicated only about 2.5% of respondents self-identified as \"reactionary\" or \"Moldbuggian,\" suggesting limited adoption despite perceived visibility from contrarian critiques of democracy and egalitarianism.[](https://www.lesswrong.com/posts/6qPextf9KyWLFJ53j/why-is-mencius-moldbug-so-popular-on-less-wrong-answer-he-s) Moldbug's analyses, emphasizing formalist governance and signaling dynamics in social hierarchies, overlapped with rationalist interests in incentive structures and anti-egalitarian interpretations of human behavior, prompting posts questioning his influence.[](https://www.lesswrong.com/posts/6qPextf9KyWLFJ53j/why-is-mencius-moldbug-so-popular-on-less-wrong-answer-he-s)\n\nNRx ideas gained tangential traction through 2014 threads mapping fundamental disagreements with progressivism, such as views on human far-sightedness, cultural independence from material conditions, and civilizational decadence versus ascent.[](https://www.lesswrong.com/posts/6FzkEzpPQxrLyu8eH/nrx-vs-prog-assumptions-locating-the-sources-of-disagreement) These discussions highlighted NRx's core normative claim of prioritizing biological and civilizational perpetuation over subjective values, often framed as deference to emergent natural orders (\"Gnon\").[](https://www.lesswrong.com/posts/6FzkEzpPQxrLyu8eH/nrx-vs-prog-assumptions-locating-the-sources-of-disagreement) However, community responses in comments emphasized curiosity over endorsement, with NRx portrayed as a potential counter to institutionalized left-leaning biases in media and academiaâ€”biases empirically documented in content analyses of coverage and peer reviewâ€”but critiqued for overreach into unsubstantiated prescriptions like monarchy or patchwork sovereignty.[](https://www.lesswrong.com/posts/RWKXeM49Stc4aEcEc/neo-reactionaries-why-are-you-neo-reactionary)\n\nThe rationalist majority rejected NRx's political conclusions as empirically deficient, citing failures in predictive accuracyâ€”such as anticipated democratic collapses not materializing amid sustained institutional functionalityâ€”and weaker causal explanations for governance outcomes compared to mainstream models.[](https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/) Prominent rationalist Scott Alexander's 2013 \"Anti-Reactionary FAQ\" systematically rebutted NRx historical claims (e.g., on feudal efficiency) and empirical assertions, arguing that alternatives like autocracy lack evidence of superior long-term stability or prosperity when benchmarked against democratic systems' records in innovation and growth.[](https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/) While retaining analytical tools like causal realism in evaluating power dynamics, LessWrong users dismissed NRx as prone to unfalsifiable narratives, with comments decrying ethical lapses, impracticality, and divergence from data-driven truth-seeking.[](https://www.lesswrong.com/posts/RWKXeM49Stc4aEcEc/neo-reactionaries-why-are-you-neo-reactionary) This engagement underscored NRx's role in challenging normalized progressive assumptions but affirmed the community's prioritization of verifiable evidence over ideological overhaul.[](https://www.lesswrong.com/posts/6FzkEzpPQxrLyu8eH/nrx-vs-prog-assumptions-locating-the-sources-of-disagreement)\n\n### Challenges to Rationality Claims and Prediction Accuracy\n\nCritics have challenged LessWrong's assertions of epistemic superiority by examining the community's forecasting performance, particularly on high-stakes topics like artificial general intelligence (AGI) timelines. Retrospective analyses of rationalist predictions indicate frequent overconfidence, with many participants assigning high probabilities (often above 50%) to AGI arrival by the mid-2020s, outcomes that remain unrealized as of October 2025. For instance, surveys of LessWrong users in the early 2010s projected median timelines for human-level AI around 2040-2050, but subsequent updates amid scaling progress led to shortened estimates, yet without corresponding empirical vindication, highlighting a pattern of optimistic recalibration rather than precise foresight.[](https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines)[](https://www.alignmentforum.org/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines)\n\nProminent figures within the community, such as Eliezer Yudkowsky, have faced scrutiny for track records that do not demonstrate exceptional calibration. Yudkowsky's resolved predictions on platforms like the PredictionBook registry show two losses and no wins, while his Metaculus profile lacks resolved forecasts demonstrating superior accuracy. External evaluations, including those from fellow rationalists, document instances of confident errors, such as overstated claims about neural correlates of consciousness or AI development trajectories that diverged from observed progress. These lapses suggest that ingroup deference to influential thinkers may foster confirmation bias, undermining claims of systematic bias reduction.[](https://www.lesswrong.com/posts/ZEgQGAjQm5rTAnGuM/beware-boasting-about-non-existent-forecasting-track-records)[](https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously)\n\nBroader critiques argue that LessWrong's approach often indulges in inductive generalizations from limited data without rigorous empirical validation, akin to philosophical speculation masquerading as science. Community reliance on Bayesian updating has popularized probabilistic reasoning, yet aggregate forecasts on platforms like Metaculusâ€”while competitive with expert baselinesâ€”fail to exhibit the \"superhuman edges\" promised by rationality training. Studies of probabilistic forecasting emphasize that calibration improves with deliberate practice, but rationalist self-assessments reveal no statistically significant outperformance over non-rationalist forecasters in controlled settings, attributing this to overreliance on theoretical frameworks over diverse empirical testing.[](https://www.lesswrong.com/posts/5jdqtpT6StjKDKacw/attitudes-about-applied-rationality)[](https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website)\n\nIngroup dynamics exacerbate these issues, with critics noting cult-like patterns of uncritical trust in core doctrines, such as fast AI takeoff scenarios, despite contradictory evidence from incremental advancements in machine learning. While LessWrong has advanced awareness of cognitive heuristics and decision theory, causal analysis demands acknowledgment that its predictive accuracy aligns more closely with general expert aggregates than with the transformative gains claimed, underscoring the limits of self-taught rationality absent external benchmarks.[](https://asteriskmag.substack.com/p/why-are-there-so-many-rationalist)[](https://www.lesswrong.com/posts/BthNiWJDagLuf2LN2/evaluating-predictions-in-hindsight)\n\n### Moderation Practices and Community Boundaries\n\nFollowing the relaunch of LessWrong 2.0 in June 2017, which emphasized an effective moderation system to support high-quality discourse, the platform implemented karma-based thresholds to curb low-signal contributions. Users with -1 or lower total karma are limited to one comment per day and one post every two weeks, aiming to filter out noise from unproven participants while rewarding established contributors.[](https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0)[](https://www.lesswrong.com/posts/hHyYph9CcYfdnoC5j/automatic-rate-limiting-on-lesswrong)\n\nIn June 2023, LessWrong introduced automatic rate limiting for users receiving heavy downvotes, further restricting posting frequency based on community feedback signals to maintain discussion rigor. These measures, including moderator review of first-time comments for cultural fit, were defended by site administrators as essential for prioritizing productive, truth-oriented exchanges over unchecked volume. Empirical observations from moderators noted reduced trolling and improved signal-to-noise ratios post-implementation, though data on long-term effects remains anecdotal.[](https://www.lesswrong.com/posts/hHyYph9CcYfdnoC5j/automatic-rate-limiting-on-lesswrong)[](https://www.lesswrong.com/posts/zXJfH7oZ62Xojnrqs/lesswrong-moderation-messaging-container)\n\nBy April 2023, ongoing policy reviews highlighted tensions in applying these tools to controversial posters, with rate limits and downvote-triggered restrictions sometimes curtailing users expressing unpopular views, as seen in community debates over stymied efficient communication. Critics within the forum argued such boundaries risk entrenching groupthink by raising barriers for dissenters, likening them to exclusionary norms in polite society that prioritize consensus over open challenge. Proponents countered that selective enforcement preserves the site's focus on epistemic standards, preventing dilution by low-effort contrarianism, though this has sparked internal calls for more transparent appeals processes.[](https://www.lesswrong.com/posts/eKxLEHeLvKZYR7MmN/lw-moderation-my-current-thoughts-and-questions-2023-04-12)[](https://www.lesswrong.com/posts/7FAneMMzGjxBsosue/the-commenting-restrictions-on-lesswrong-seem-bad)\n\n## Influence and External Reception\n\n### Contributions to AI Safety and Effective Altruism\n\nLessWrong served as a primary intellectual hub for the development of AI alignment research, where foundational ideas on mitigating existential risks from advanced AI were articulated and refined. Eliezer Yudkowsky's sequences on the site, beginning in 2009, popularized concepts such as coherent extrapolated volition (CEV) and the orthogonality thesis, which underpin efforts to ensure superintelligent systems pursue human-compatible goals rather than unintended catastrophic outcomes.[](https://www.lesswrong.com/posts/pCesigb4NjzvoNKWB/to-contribute-to-ai-safety-consider-doing-ai-research) These discussions directly informed the research agenda of the Machine Intelligence Research Institute (MIRI), originally founded as the Singularity Institute in 2000 by Yudkowsky and others, with MIRI formalizing its focus on mathematical foundations of alignment by 2013 amid growing community engagement on LessWrong.[](https://www.lesswrong.com/posts/q3bJYTB3dGRf5fbD9/miri-2024-mission-and-strategy-update) The platform facilitated idea diffusion, with posts debating scalable oversight and inner misalignment contributing to paradigms later adopted in industry labs.\n\nPersonnel flows from the LessWrong community have seeded key AI safety initiatives at major organizations. Paul Christiano, an early active contributor whose LessWrong writings from the 2010s outlined threat models like outer alignment failures, advanced to lead alignment efforts at OpenAI starting in 2016, developing techniques such as iterated amplification and debate that influenced safety protocols there and at subsequent ventures like the Alignment Research Center (ARC).[](https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story) Similarly, LessWrong discussions shaped contributions to DeepMind's safety team, where community alumni applied rationalist frameworks to empirical alignment experiments, quantifying risks through benchmarks and interpretability tools.[](https://www.lesswrong.com/posts/S7csET9CgBtpi7sCh/challenges-to-christiano-s-capability-amplification-proposal) By 2025, this talent pipeline persists, with LessWrong users comprising a notable fraction of researchers at entities like Anthropic and Redwood Research, where posts on the site have driven shifts toward mechanistic interpretability and empirical scaling laws for safety evaluation.[](https://www.lesswrong.com/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field)\n\nThe site's emphasis on first-principles prioritization of existential risks (x-risks) catalyzed effective altruism's (EA) focus on long-termism and high-impact interventions. LessWrong's rationalist ethos, applied to altruism from the early 2010s, encouraged quantitative assessment of causes like AI misalignment over near-term charity, influencing EA's allocation of resourcesâ€”such as the over $100 million in AI safety funding tracked in 2023â€”to x-risk mitigation.[](https://www.lesswrong.com/w/existential-risk) Community members from LessWrong orbits, including early GiveWell analysts, bridged rationality techniques to EA's cause neutrality, embedding x-risks as a core pillar by 2015.[](https://www.lesswrong.com/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism)\n\nLessWrong has also hosted incisive critiques of EA's methodological shortcomings, highlighting empirical gaps and over-reliance on trust in key actors. Posts analyzing the 2022 FTX collapse, involving EA-associated Sam Bankman-Fried's fraud, underscored risks of insufficient due diligence in high-stakes philanthropy, with community analyses estimating clawback probabilities for tainted grants and questioning EA's vulnerability to motivated reasoning.[](https://www.lesswrong.com/posts/HMaBPzrnvg2WCw6KL/noting-an-unsubstantiated-belief-about-the-ftx-disaster) [](https://www.lesswrong.com/posts/9weamhzzBpqxz3A2e/estimating-the-probability-that-ftx-future-fund-grant-money) These discussions, attributing the episode partly to EA's prioritization heuristics bypassing robust verification, prompted internal reforms like enhanced governance without diluting x-risk focus.[](https://www.lesswrong.com/posts/8wYH4WggxFqT9yhzJ/we-must-be-very-clear-fraud-in-the-service-of-effective)\n\nAs of 2025, LessWrong maintains substantial influence on alignment trajectories, with active threads shaping funding reallocationsâ€”such as MIRI's 2024 pivot from technical research to advocacy amid stalled progressâ€”and roadmaps for newcomers entering safety orgs.[](https://www.lesswrong.com/posts/vkzmbf4Mve4GNyJaF/the-case-for-stopping-ai-safety-research) [](https://www.lesswrong.com/posts/bcuzjKmNZHWDuEwBz/an-outsider-s-roadmap-into-ai-safety-research-2025) Posts continue to quantify field bottlenecks, like the $100+ million annual safety spend versus capabilities escalation, fostering causal shifts toward cooperative strategies and governance integration.[](https://www.lesswrong.com/posts/WGpFFJo2uFe5ssgEb/an-overview-of-the-ai-safety-funding-situation) [](https://www.lesswrong.com/posts/5uffoui3axcK7gQXG/towards-more-cooperative-ai-safety-strategies)\n\n### Broader Impacts on Rationalist Thought\n\nLessWrong's core techniques, such as Bayesian updating and calibration training, have permeated tech startups and forecasting groups, where they are applied to enhance probabilistic forecasting and strategic planning. The Center for Applied Rationality (CFAR), originating from LessWrong's foundational ideas, delivers workshops on these methods to professionals, including Silicon Valley entrepreneurs seeking to mitigate cognitive biases in high-stakes decision environments.[](http://www.rationality.org/)[](https://www.vice.com/en/article/center-for-applied-rationality/) Participants report applying tools like expected value calculations to product development and risk assessment, though adoption remains anecdotal and concentrated within niche tech circles rather than widespread industry practice.[](https://www.lesswrong.com/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a)\n\nIn forecasting communities, LessWrong discussions on prediction markets as mechanisms for aggregating dispersed information have paralleled the rise of user-driven platforms. Manifold Markets, launched in 2021, attracts heavy participation from LessWrong users for resolving questions on topics from politics to technology, reflecting the site's advocacy for markets as superior to expert opinion in tracking truth.[](https://www.lesswrong.com/posts/ptEtB4wbLixRuy8MG/manifold-markets-1)[](https://manifold.markets/LessWrong/will-against-almost-every-theory-of-6a6c2cb48fde) These engagements demonstrate LessWrong's role in normalizing play-money markets for epistemic calibration, though platforms like Manifold operate independently and scale beyond rationalist confines.\n\nLessWrong counters dogmatic tendencies in mainstream media through its doctrine of epistemic humility, which prioritizes evidence-based belief revision over narrative conformity. This approach, articulated in early posts emphasizing doubt in authoritative sources unless empirically validated, has resonated in skeptic communities wary of institutional biases.[](https://www.lesswrong.com/posts/GrDqnMjhqoxiqpQPw/the-proper-use-of-humility)[](https://www.lesswrong.com/w/humility) Adherents cite it as fostering resilience against sensationalism, with LessWrong sequences like \"How to Actually Change Your Mind\" promoting techniques to detect and correct overconfidence induced by selective reporting.[](https://www.lesswrong.com/posts/LCduhA4m3RhMjZJPA/why-you-should-never-update-your-beliefs)\n\nSelf-reported data from LessWrong users and CFAR attendees indicate modest gains in decision-making, such as improved forecast accuracy via calibration exercises, but lack rigorous external validation and may reflect selection bias among motivated participants. Community retrospectives highlight perceived enhancements in personal and professional choices, yet controlled studies remain scarce, underscoring the techniques' preliminary empirical footing.[](https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama)\n\n### Skepticism and Criticisms from Academia and Mainstream\n\nAcademic philosophers and cognitive scientists have frequently dismissed LessWrong's contributions to decision theory and epistemology as amateurish and insufficiently rigorous, arguing that its emphasis on Bayesian updating and instrumental rationality bypasses established normative frameworks and empirical validation within peer-reviewed literature.[](https://www.reddit.com/r/askphilosophy/comments/425h9e/why_is_there_such_hate_for_less_wrong_in_reddits/) For instance, community discussions among philosophy professionals highlight LessWrong's assumption that greater rationality universally outperforms contextual or social heuristics, such as those in religious or cultural practices where apparent irrationality yields adaptive benefits, rendering its models overly reductive.[](https://www.reddit.com/r/askphilosophy/comments/425h9e/why_is_there_such_hate_for_less_wrong_in_reddits/) This perspective is compounded by the platform's origins outside formal academia, with key figures like Eliezer Yudkowsky lacking advanced degrees, leading to characterizations of its work as disconnected from scientific philosophy's methodological standards.[](https://www.reddit.com/r/SneerClub/comments/12wfi7h/the_founder_of_lesswrong_didnt_even_attend_high/) Such critiques, however, often reflect institutional incentives favoring credentialism over outsider innovations, as LessWrong's first-principles approach to cognitive biases has anticipated developments like AI scaling lawsâ€”predicting smooth performance gains with compute increases in early 2010s analysesâ€”later corroborated by empirical studies such as Kaplan et al.'s 2020 findings on neural network predictability.[](https://www.lesswrong.com/posts/G993PFTwqqdQv4eTg/is-ai-progress-impossible-to-predict)\n\nMainstream media outlets have portrayed LessWrong as a fringe \"doomer cult,\" emphasizing its focus on existential AI risks and associating it with insular dynamics or radical offshoots, such as the Zizians, a group rooted in rationalist ideas that media described as promoting AI messianism alongside extreme ethical stances leading to real-world harms.[](https://www.thenation.com/article/society/trans-vegan-cult-zizians-murders/)[](https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults) Coverage in publications like The Nation and Asterisk Magazine frames the community's high-stakes predictionsâ€”such as fast AI takeoffsâ€”as apocalyptic sensationalism akin to cult eschatology, amplifying perceptions of detachment from balanced discourse.[](https://www.thenation.com/article/society/trans-vegan-cult-zizians-murders/)[](https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults) Empirical counterevidence undermines this narrative: LessWrong's 2010s forecasting of compute-driven AI advances, including shortened timelines validated by Metaculus aggregates shifting from 2042 to 2036 for AGI by 2022 amid observed scaling, demonstrates superior calibration to data over mainstream underestimation.[](https://www.reddit.com/r/slatestarcodex/comments/u1u3c2/6_year_decrease_of_metaculus_agi_prediction/)[](https://www.lesswrong.com/posts/47ci9ixyEbGKWENwR/ai-timeline-predictions-are-we-getting-better)\n\nLeft-leaning academic and media critiques further charge LessWrong with neglecting power dynamics and social justice priorities, demanding integration of equity frameworks into rationality tools, yet these impositions conflate truth-seeking with ideological conformity, lacking falsifiable tests and ignoring causal evidence that such additions dilute predictive accuracy in domains like AI risk assessment.[](https://suspendedreason.com/2020/04/15/sidebar-mutual-hostilities/) Overlaps with right-leaning thought, such as critiques of institutional stagnation, appear in some rationalist discourse but remain unendorsed absent rigorous data, as LessWrong prioritizes evidential reasoning over partisan alignment.[](https://www.lesswrong.com/posts/K5LYLvZvdthdyRFFQ/why-academia-is-mostly-not-truth-seeking) Overall, while fringe-labeling persists, LessWrong's track record in preempting verifiable trends like neural scalingâ€”contrasting academia's slower adoptionâ€”suggests systemic biases in credentialed institutions toward dismissing non-conformist empiricism.[](https://www.lesswrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia)"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"8:[\"$\",\"$L1e\",null,{\"state\":{\"mutations\":[],\"queries\":[{\"dehydratedAt\":1761883847938,\"state\":{\"data\":{\"page\":{\"citations\":[{\"id\":\"1\",\"title\":\"LessWrong\",\"description\":\"- **Description**: LessWrong is an online forum and community focused on improving human reasoning and decision-making to hold true beliefs and achieve goals effectively.\",\"url\":\"https://www.lesswrong.com/about\",\"favicon\":\"\"},{\"id\":\"2\",\"title\":\"History of Less Wrong\",\"description\":\"Mar 8, 2021 Â· Founding. In February 2009, Yudkowsky's posts were used as the seed material to create the community blog LessWrong, and Overcoming Bias becameÂ ...\",\"url\":\"https://www.lesswrong.com/w/history-of-less-wrong\",\"favicon\":\"\"},{\"id\":\"3\",\"title\":\"A Brief History of LessWrong\",\"description\":\"May 31, 2019 Â· LessWrong was seeded with series of daily blog posts written by Eliezer, originally known as The Sequences, and more recently compiled into an edited volume,Â ...\",\"url\":\"https://www.lesswrong.com/posts/S69ogAGXcc9EQjpcZ/a-brief-history-of-lesswrong-1\",\"favicon\":\"\"},{\"id\":\"4\",\"title\":\"50 - AI Alignment Forum\",\"description\":\"The Alignment Forum was created by and is maintained by the team behind LessWrong (the web forum). The two sites share a codebase and database. They integrateÂ ...Missing:  onward annual\",\"url\":\"https://www.alignmentforum.org/about\",\"favicon\":\"\"},{\"id\":\"5\",\"title\":\"Read The Sequences â€” EA Forum\",\"description\":\"Dec 23, 2022 Â· There is heavy overlap among the effective altruism and rationality communities but they are not the same thing. Within the effective altruism\",\"url\":\"https://forum.effectivealtruism.org/posts/2S3CHPwaJBE5h8umW/read-the-sequences\",\"favicon\":\"\"},{\"id\":\"6\",\"title\":\"Eliezer Yudkowsky: The 100 Most Influential People in AI 2023 | TIME\",\"description\":\"Sep 7, 2023 Â· ... LessWrong, the community blog he founded in 2009. Last year, however, Yudkowsky admitted defeat. On April 1, 2022, he announced that MIRIÂ ...\",\"url\":\"https://time.com/collection/time100-ai/6309037/eliezer-yudkowsky/\",\"favicon\":\"\"},{\"id\":\"7\",\"title\":\"Should rationality be a movement? - LessWrong\",\"description\":\"Jun 20, 2019 Â· Rationality asks the question \\\"How to think clearly\\\". For many people who start to think more clearly, this leads to an update of their goalsÂ ...\",\"url\":\"https://www.lesswrong.com/posts/g2fQuAD6qpBERucwu/should-rationality-be-a-movement\",\"favicon\":\"\"},{\"id\":\"8\",\"title\":\"About - Overcoming Bias\",\"description\":\"Overcoming Bias began in November '06 as a group blog on the general theme of how to move our beliefs closer to reality, in the face of our natural biases.\",\"url\":\"https://www.overcomingbias.com/about\",\"favicon\":\"\"},{\"id\":\"9\",\"title\":\"What Is Signaling? - by Robin Hanson - Overcoming Bias\",\"description\":\"May 7, 2015 Â· It's become fashionable in the economics world to label any and every human social interaction as a form of signaling.Missing:  prediction markets theory\",\"url\":\"https://www.overcomingbias.com/p/what-is-signalinghtml\",\"favicon\":\"\"},{\"id\":\"10\",\"title\":\"Prediction Markets Update - by Robin Hanson - Overcoming Bias\",\"description\":\"Sep 19, 2017 Â· Prediction markets can't realize their potential until they have been honed and evaluated in a set of increasingly substantial and challenging trials.Missing:  signaling theory\",\"url\":\"https://www.overcomingbias.com/p/prediction-markets-updatehtml\",\"favicon\":\"\"},{\"id\":\"11\",\"title\":\"Rat Traps - Asterisk Magazine\",\"description\":\"The origin of rationalist writing is commonly traced back to the comments section of Overcoming Bias, a group blog about cognitive biases and related topicsÂ ...\u003c|control11|\u003e\u003c|separator|\u003e\",\"url\":\"https://asteriskmag.com/issues/08/rat-traps\",\"favicon\":\"\"},{\"id\":\"12\",\"title\":\"LessWrong FAQ\",\"description\":\"Jun 14, 2019 Â· The votes of users with more karma have more power under LessWrong's voting system, ensuring that users who have earned the community's respectÂ ...\",\"url\":\"https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq\",\"favicon\":\"\"},{\"id\":\"13\",\"title\":\"What Do We Mean By \\\"Rationality\\\"? - LessWrong\",\"description\":\"Mar 16, 2009 Â· 1. Epistemic rationality: systematically improving the accuracy of your beliefs. 2. Instrumental rationality: systematically achieving your values.\",\"url\":\"https://www.lesswrong.com/posts/RcZCwxFiZzE6X7nsv/what-do-we-mean-by-rationality-1\",\"favicon\":\"\"},{\"id\":\"14\",\"title\":\"Rationality - LessWrong\",\"description\":\"Aug 31, 2023 Â· More specifically, instrumental rationality is the art of choosing and implementing actions that steer the future toward outcomes ranked higherÂ ...\",\"url\":\"https://www.lesswrong.com/w/rationality\",\"favicon\":\"\"},{\"id\":\"15\",\"title\":\"Why is Bayesianism important for rationality? - LessWrong\",\"description\":\"Aug 31, 2020 Â· At one time, lesswrong believed that Bayes underpinned decision theory, decision theory underpinned rationality, and some combination ofÂ ...\",\"url\":\"https://www.lesswrong.com/posts/3uxX2cCH9oxANzpk3/why-is-bayesianism-important-for-rationality\",\"favicon\":\"\"},{\"id\":\"16\",\"title\":\"An Introduction To Rationality - LessWrong\",\"description\":\"Oct 19, 2013 Â· Instrumental rationality is about doing what you should based upon what you value. An instrumental rationality error would be working ratherÂ ...\",\"url\":\"https://www.lesswrong.com/posts/fpsxNCE6Jrcoeucta/an-introduction-to-rationality\",\"favicon\":\"\"},{\"id\":\"17\",\"title\":\"Original Sequences - LessWrong\",\"description\":\"Oct 5, 2020 Â· The original sequences were a series of essays written by Eliezer Yudkowsky between 2006 and 2009 on the blogs Overcoming Bias and Less Wrong.\",\"url\":\"https://www.lesswrong.com/w/original-sequences\",\"favicon\":\"\"},{\"id\":\"18\",\"title\":\"Rationality: From AI to Zombies\",\"description\":\"Map and Territory and How to Actually Change Your Mind are the first of six books in the Rationality: From AI to Zombies series. As of December 2018, theseÂ ...\",\"url\":\"https://intelligence.org/rationality-ai-zombies/\",\"favicon\":\"\"},{\"id\":\"19\",\"title\":\"Map and Territory - LessWrong\",\"description\":\"Apr 1, 2023 Â· Updating our mental maps to more closely match the territory leads to better choices and less surprising encounters with the unexpected. The \\\"Â ...Missing:  Sequences | Show results with:Sequences\",\"url\":\"https://www.lesswrong.com/w/map-and-territory\",\"favicon\":\"\"},{\"id\":\"20\",\"title\":\"Mysterious Answers to Mysterious Questions - LessWrong\",\"description\":\"Aug 25, 2007 Â· In doing so, they mixed up the map with the territory. All confusion and bewilderment exist in the mind, not in encapsulated substances.\",\"url\":\"https://www.lesswrong.com/posts/6i3zToomS86oj9bS6/mysterious-answers-to-mysterious-questions\",\"favicon\":\"\"},{\"id\":\"21\",\"title\":\"Rationality: A-Z - LessWrong\",\"description\":\"These four sequences explain the Bayesian notions of rationality, belief, and evidence. A running theme: the things we call â€œexplanationsâ€ or â€œtheoriesâ€ may notÂ ...\",\"url\":\"https://www.lesswrong.com/sequences\",\"favicon\":\"\"},{\"id\":\"22\",\"title\":\"Yudkowsky: Rationality, AI \u0026 The Sequences Cheatsheet\",\"description\":\"Organized into \\\"Rationality: From AI to Zombies,\\\" they are foundational texts for the rationalist community and AI safety. Explore The Sequences â–½.\",\"url\":\"https://cheatsheets.davidveksler.com/yudkowsky-rationality-ai-cheatsheet.html\",\"favicon\":\"\"},{\"id\":\"23\",\"title\":\"Fermi Estimation - LessWrong\",\"description\":\"Feb 2, 2021 Â· A Fermi Estimation is a rough calculation which aims to be right within ~an order of magnitude, prioritizing getting a good enough to be useful answer.\",\"url\":\"https://www.lesswrong.com/w/fermi-estimation\",\"favicon\":\"\"},{\"id\":\"24\",\"title\":\"Survey Results - LessWrong\",\"description\":\"May 12, 2009 Â· The mean age was 27.16, the median was 25, and the SD was 7.68. The youngest person was 16, and the oldest was 60. Quartiles were \u003c22, 22-25, 25Â ...Missing:  2010 2012 active users\",\"url\":\"https://www.lesswrong.com/posts/ZWC3n9c6v4s35rrZ3/survey-results\",\"favicon\":\"\"},{\"id\":\"25\",\"title\":\"2011 Survey Results - LessWrong\",\"description\":\"Dec 5, 2011 Â· 170 people have read about 25% of the sequences, 169 (15.5%) about 50%, 167 (15.3%) about 75%, and 253 people (23.2%) said they've read almostÂ ...Missing:  expansion | Show results with:expansion\",\"url\":\"https://www.lesswrong.com/posts/HAEPbGaMygJq8L59k/2011-survey-results\",\"favicon\":\"\"},{\"id\":\"26\",\"title\":\"Five Years and One Week of Less Wrong | Slate Star Codex\",\"description\":\"Mar 13, 2014 Â· But that's Overcoming Bias stuff, Sequence stuff. What have we done on Less Wrong, in the past five years and one week? II. It was aroundÂ ...\",\"url\":\"https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/\",\"favicon\":\"\"},{\"id\":\"27\",\"title\":\"Less Wrong NYC: Case Study of a Successful Rationalist Chapter\",\"description\":\"Mar 17, 2011 Â· That summer brought an increased interest in skill sharing, a reduced game night frequency, and meetups focused around specific topics. ThatÂ ...Missing:  peak 2009-2015\u003c|separator|\u003e\",\"url\":\"https://www.lesswrong.com/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist\",\"favicon\":\"\"},{\"id\":\"28\",\"title\":\"2013 Survey Results - LessWrong\",\"description\":\"Jan 18, 2014 Â· As we will see lower down, growth is smooth across all categories of users ... Thanks for doing this! Results from previous years: 2009 2011 2012.Missing:  2010 | Show results with:2010\",\"url\":\"https://www.lesswrong.com/posts/pJJdcZgB6mPNWoSWr/2013-survey-results\",\"favicon\":\"\"},{\"id\":\"29\",\"title\":\"LessWrong - EA Forum\",\"description\":\"As a consequence of this and other developments, posting quality and frequency on LessWrong began to decline. By 2015, activity on the site was a fraction ofÂ ...\",\"url\":\"https://forum.effectivealtruism.org/topics/lesswrong\",\"favicon\":\"\"},{\"id\":\"30\",\"title\":\"Bits and bricks: Oliver Habryka on LessWrong, LightHaven, and ...\",\"description\":\"Oct 9, 2025 Â· \\\" He left roughly around 2015 and then LessWrong started a pretty intense decline, with the site basically completely dying to trolls and spam.Transcript Â· Reviving Lesswrong Â· The Collapse Of Ftx And Its...\",\"url\":\"https://www.complexsystemspodcast.com/episodes/bits-and-bricks-oliver-habryka/\",\"favicon\":\"\"},{\"id\":\"31\",\"title\":\"2016 LessWrong Diaspora Survey Results\",\"description\":\"May 14, 2016 Â· This seems consistent with the hypothesis that the LW community hasn't declined in population so much as migrated into different communitiesÂ ...Foreword Â· Basic Results Â· In Depth AnalysisMissing:  2015-2016 | Show results with:2015-2016\u003c|separator|\u003e\",\"url\":\"https://www.lesswrong.com/posts/mLALYcWR4xKw7RRnj/2016-lesswrong-diaspora-survey-results\",\"favicon\":\"\"},{\"id\":\"32\",\"title\":\"Welcome to Lesswrong 2.0\",\"description\":\"Jun 18, 2017 Â· Lesswrong 2.0 is a project by Oliver Habryka, Ben Pace, and Matthew Graves with the aim of revitalizing the Lesswrong discussion platform.Missing:  relaunch Raemon\",\"url\":\"https://www.lesswrong.com/posts/HJDbyFFKf72F52edp/welcome-to-lesswrong-2-0\",\"favicon\":\"\"},{\"id\":\"33\",\"title\":\"Data Analysis of LW: Activity Levels + Age Distribution of User ...\",\"description\":\"May 14, 2019 Â· This corresponds to the launch of the LessWrong 2.0 Open Beta 9-20 and publishing of Eliezer's Inadequate Equilibria on LW* on 10-28. I haveÂ ...Missing:  announcement | Show results with:announcement\u003c|control11|\u003e\u003c|separator|\u003e\",\"url\":\"https://www.lesswrong.com/posts/9dA6GfuDca3Zh3RMa/data-analysis-of-lw-activity-levels-age-distribution-of-user\",\"favicon\":\"\"},{\"id\":\"34\",\"title\":\"Reflections On The Feasibility Of Scalable-Oversight - LessWrong\",\"description\":\"Mar 9, 2023 Â· This post was inspired by discussions on the feasibility of scaling RLHF for aligning AGI during EAG 2023 in Oakland.Missing:  2019- | Show results with:2019-\",\"url\":\"https://www.lesswrong.com/posts/8yimdZcEWSKkutHhZ/reflections-on-the-feasibility-of-scalable-oversight\",\"favicon\":\"\"},{\"id\":\"35\",\"title\":\"\",\"description\":\"\",\"url\":\"https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1\",\"favicon\":\"\"},{\"id\":\"36\",\"title\":\"Welcome \u0026 FAQ! - AI Alignment Forum\",\"description\":\"The AI Alignment Forum was launched in 2018. Since then, several ... On LessWrong you can see two reputation scores: a primary karma score combining karmaÂ ...\u003c|separator|\u003e\",\"url\":\"https://www.alignmentforum.org/posts/Yp2vYb4zHXEeoTkJc/welcome-and-faq\",\"favicon\":\"\"},{\"id\":\"37\",\"title\":\"LessWrong Review - AI Alignment Forum\",\"description\":\"Mar 10, 2025 Â· The LessWrong Annual Review is a central mechanism for reviewing the site's content, it's kind of like our site's peer review process.\",\"url\":\"https://www.alignmentforum.org/w/lesswrong-review\",\"favicon\":\"\"},{\"id\":\"38\",\"title\":\"The 2023 LessWrong Review: The Basic Ask - AI Alignment Forum\",\"description\":\"Dec 4, 2024 Â· The LessWrong community reflects on the best blogposts of yesteryear, to decide which posts stood the tests of time.\",\"url\":\"https://www.alignmentforum.org/posts/pudQtkre7f9GLmb2b/the-2023-lesswrong-review-the-basic-ask\",\"favicon\":\"\"},{\"id\":\"39\",\"title\":\"How 2025 AI Forecasts Fared So Far - LessWrong\",\"description\":\"May 22, 2025 Â· Forecasters were bullish â€“ they expected most of the gap between 2024 AI performance and the best observed human performance to be closed in 2025.\",\"url\":\"https://www.lesswrong.com/posts/FwS8THsPGi36M2tj6/how-2025-ai-forecasts-fared-so-far\",\"favicon\":\"\"},{\"id\":\"40\",\"title\":\"Contra papers claiming superhuman AI forecasting - LessWrong\",\"description\":\"Sep 12, 2024 Â· Claims that boil down to â€œwe built an LLM-powered forecaster that rivals human forecasters or even shows superhuman performanceâ€.\",\"url\":\"https://www.lesswrong.com/posts/uGkRcHqatmPkvpGLq/contra-papers-claiming-superhuman-ai-forecasting\",\"favicon\":\"\"},{\"id\":\"41\",\"title\":\"Comparing Forecasting Track Records for AI Benchmarking and ...\",\"description\":\"Sep 25, 2024 Â· We are running quarterly AI forecasting tournaments through mid-2025, each time using new questions including fresh topics, thereby avoidingÂ ...Missing:  rationalist | Show results with:rationalist\",\"url\":\"https://www.lesswrong.com/posts/QkLoEYBvS2RMkMqnw/comparing-forecasting-track-records-for-ai-benchmarking-and\",\"favicon\":\"\"},{\"id\":\"42\",\"title\":\"Strong Votes [Update: Deployed] - LessWrong\",\"description\":\"Jun 1, 2018 Â· You have the option of holding down the up/downvote button for a strong vote, which ranges in power from 1 to 15.\",\"url\":\"https://www.lesswrong.com/posts/7Sx3CJXA7JHxY2yDG/strong-votes-update-deployed\",\"favicon\":\"\"},{\"id\":\"43\",\"title\":\"Vote Strength - LessWrong\",\"description\":\"Apr 3, 2024 Â· The strength of your votes on LessWrong depends on your karma; if you have more karma, your upvotes will increase the score of things you upvoteÂ ...Missing:  system mechanics weak\",\"url\":\"https://www.lesswrong.com/w/vote-strength\",\"favicon\":\"\"},{\"id\":\"44\",\"title\":\"[Team Update] Why we spent Q3 optimizing for karma - LessWrong\",\"description\":\"Nov 7, 2019 Â· ... voting. This means that by targeting the amount of karma given out, we're incentivizing ourselves to increase multiple valuable other â€œsubÂ ...\",\"url\":\"https://www.lesswrong.com/posts/WnB6whsARH6NuJDKx/team-update-why-we-spent-q3-optimizing-for-karma\",\"favicon\":\"\"},{\"id\":\"45\",\"title\":\"Wiki-Tag FAQ - LessWrong\",\"description\":\"Jul 28, 2020 Â· What is tagging on LessWrong? Tags allow related content to be linked together. The system is straightforward: Posts can be tagged with tags (Â ...Missing:  integration | Show results with:integration\",\"url\":\"https://www.lesswrong.com/posts/E6CF8JCQAWqqhg7ZA/wiki-tag-faq\",\"favicon\":\"\"},{\"id\":\"46\",\"title\":\"[Site Meta] Quick Guide to Tagging - LessWrong\",\"description\":\"Apr 21, 2020 Â· There are three main ways to contribute to LessWrong's new experimental tagging system: 1) tagging posts, 2) voting on tag relevance, and 3)Â ...Missing:  integration | Show results with:integration\",\"url\":\"https://www.lesswrong.com/posts/piLLdQs7pYghRPHb9/site-meta-quick-guide-to-tagging\",\"favicon\":\"\"},{\"id\":\"47\",\"title\":\"Wiki/Tagging - LessWrong\",\"description\":\"Nov 24, 2020 Â· You can create up to 3 custom summaries; by default you should avoid creating more than one summary unless the subject matter benefitsÂ ...Missing:  integration | Show results with:integration\",\"url\":\"https://www.lesswrong.com/w/wiki-tagging\",\"favicon\":\"\"},{\"id\":\"48\",\"title\":\"Automatic Rate Limiting on LessWrong\",\"description\":\"Jun 23, 2023 Â· If a user has -1 or less total karma, they can only write one comment per day and one post per two-weeks. This doesn't require multipleÂ ...Missing:  features | Show results with:features\",\"url\":\"https://www.lesswrong.com/posts/hHyYph9CcYfdnoC5j/automatic-rate-limiting-on-lesswrong\",\"favicon\":\"\"},{\"id\":\"49\",\"title\":\"New User's Guide to LessWrong\",\"description\":\"May 16, 2023 Â· Users who have negative karma (vote points) ... negative karma will be automatically restricted in how frequently they can post and comment.Highlights from the Sequences Â· Harry Potter and the Methods...\",\"url\":\"https://www.lesswrong.com/posts/LbbrnRvc9QwjJeics/new-user-s-guide-to-lesswrong\",\"favicon\":\"\"},{\"id\":\"50\",\"title\":\"Bias - LessWrong\",\"description\":\"Nov 18, 2013 Â· Bias or Cognitive Bias is a systematic deviation from rationality committed by our cognition. They are specific, predictable error patterns in the human mind.Missing:  subcommunities | Show results with:subcommunities\",\"url\":\"https://www.lesswrong.com/w/bias\",\"favicon\":\"\"},{\"id\":\"51\",\"title\":\"Biases: An Introduction - LessWrong\",\"description\":\"Mar 11, 2015 Â· A cognitive bias is a systematic error in how we think, as opposed to a random error or one that's merely caused by our ignorance.Missing:  theory | Show results with:theory\",\"url\":\"https://www.lesswrong.com/posts/ptxnyfLWqRZ98wnYi/biases-an-introduction\",\"favicon\":\"\"},{\"id\":\"52\",\"title\":\"Decision Theory FAQ - LessWrong\",\"description\":\"Feb 28, 2013 Â· Decision theory, also known as rational choice theory, concerns the study of preferences, uncertainties, and other issues related to making optimal or rationalÂ ...Missing:  subcommunities | Show results with:subcommunities\",\"url\":\"https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq\",\"favicon\":\"\"},{\"id\":\"53\",\"title\":\"Decision theory - LessWrong\",\"description\":\"Mar 21, 2025 Â· Decision Theory is the study of principles and algorithms for making correct decisionsâ€”that is, decisions that allow an agent to achieve betterÂ ...Missing:  subcommunities cognitive biases\",\"url\":\"https://www.lesswrong.com/w/decision-theory\",\"favicon\":\"\"},{\"id\":\"54\",\"title\":\"Forecasting AI Futures Resource Hub - LessWrong\",\"description\":\"Mar 19, 2025 Â· AI trends: Analyzing trends in AI development and investments is crucial for forecasting AI. There is an organization doing exactly this: EpochÂ ...\",\"url\":\"https://www.lesswrong.com/posts/jAPDX72dugrYrvFsd/forecasting-ai-futures-resource-hub\",\"favicon\":\"\"},{\"id\":\"55\",\"title\":\"AI alignment - LessWrong\",\"description\":\"Feb 17, 2025 Â· AI alignment is the research of developing advanced machine intelligences that produce good outcomes, like pointing a rocket in a direction.Missing:  tags forecasting\",\"url\":\"https://www.lesswrong.com/w/ai-alignment\",\"favicon\":\"\"},{\"id\":\"56\",\"title\":\"My Overview of the AI Alignment Landscape: A Bird's Eye View\",\"description\":\"Dec 15, 2021 Â· AI alignment research has 5 main approaches: addressing threat models, agendas to build safe AGI, robustly good approaches, de-confusion, andÂ ...Missing:  tags | Show results with:tags\",\"url\":\"https://www.lesswrong.com/posts/SQ9cZtfrzDJmw9A2m/my-overview-of-the-ai-alignment-landscape-a-bird-s-eye-view\",\"favicon\":\"\"},{\"id\":\"57\",\"title\":\"Review of AI Alignment Progress - LessWrong\",\"description\":\"Feb 7, 2023 Â· I've become a bit more optimistic about AI alignment in the past year or so. I currently estimate a 7% chance AI will kill us all this century.Missing:  forecasting | Show results with:forecasting\",\"url\":\"https://www.lesswrong.com/posts/JqsvYmwzcCKzgE4ZD/review-of-ai-alignment-progress\",\"favicon\":\"\"},{\"id\":\"58\",\"title\":\"A critique of effective altruism - LessWrong\",\"description\":\"Dec 2, 2013 Â· I exhibit other areas where the norms of effective altruism fail to guard against motivated cognition. Both of these phenomena add what I call â€œÂ ...Missing:  2010-2013 | Show results with:2010-2013\",\"url\":\"https://www.lesswrong.com/posts/E3beR7bQ723kkNHpA/a-critique-of-effective-altruism\",\"favicon\":\"\"},{\"id\":\"59\",\"title\":\"Another Critique of Effective Altruism - LessWrong\",\"description\":\"Jan 5, 2014 Â· It seems to me that the effective altruist movement over-focuses on â€œtried and trueâ€ options, both in giving opportunities and in career paths.Missing:  emergence | Show results with:emergence\",\"url\":\"https://www.lesswrong.com/posts/CZmkPvzkMdQJxXy54/another-critique-of-effective-altruism\",\"favicon\":\"\"},{\"id\":\"60\",\"title\":\"The Motivated Reasoning Critique of Effective Altruism - LessWrong\",\"description\":\"Sep 14, 2021 Â· I sketch out a plausible critique of effective altruism based on priors of how commonplace motivated reasoning is in the world at large.\",\"url\":\"https://www.lesswrong.com/posts/J6t5HtedJmpdGTzDE/the-motivated-reasoning-critique-of-effective-altruism\",\"favicon\":\"\"},{\"id\":\"61\",\"title\":\"2023 Survey Results - LessWrong\",\"description\":\"Feb 16, 2024 Â· Previous surveys have been run over the last decade or so. 2009: 166 2011: 1090 2012: 1195 2013: 1636 2014: 1503 2016: 3083 2017: \\\"About 300Â ...Missing:  2010 growth\",\"url\":\"https://www.lesswrong.com/posts/WRaq4SzxhunLoFKCs/2023-survey-results\",\"favicon\":\"\"},{\"id\":\"62\",\"title\":\"2024 Unofficial LessWrong Survey Results\",\"description\":\"Mar 14, 2025 Â· Thanks to everyone who took the Unofficial 2024 LessWrong Survey. For the results, check out the data below.\",\"url\":\"https://www.lesswrong.com/posts/gpZBWNFxymsqnPB92/2024-unofficial-lesswrong-survey-results\",\"favicon\":\"\"},{\"id\":\"63\",\"title\":\"The SF Bay Area - LessWrong\",\"description\":\"Sep 23, 2020 Â· The San Francisco Bay Area is a region in the US state of California. Many members of the rationalist community are located there.History Â· Debate Â· Sending people to the BayMissing:  demographics | Show results with:demographics\",\"url\":\"https://www.lesswrong.com/w/the-sf-bay-area\",\"favicon\":\"\"},{\"id\":\"64\",\"title\":\"Most smart and skilled people are outside of the EA/rationalist ...\",\"description\":\"Jul 12, 2024 Â· Insularity -- being an echo chamber -- is bad for truth seeking ... Most smart and skilled people are outside of the EA/rationalist community: anÂ ...\",\"url\":\"https://www.lesswrong.com/posts/noxHoo3XKkzPG6s7E/most-smart-and-skilled-people-are-outside-of-the-ea\",\"favicon\":\"\"},{\"id\":\"65\",\"title\":\"LW2.0: Community, Culture, and Intellectual Progress - LessWrong\",\"description\":\"Jun 19, 2019 Â· This might also help us draw back some past users who dropped off during the great decline of 2015-2016. Of course, recruitment doesn'tÂ ...\",\"url\":\"https://www.lesswrong.com/posts/nBcvEFXw4Yoz7rSDk/lw2-0-community-culture-and-intellectual-progress-1\",\"favicon\":\"\"},{\"id\":\"66\",\"title\":\"Thoughts on LessWrong norms, the Art of Discourse, and moderator ...\",\"description\":\"May 11, 2023 Â· Things like communicating degrees of belief quantitatively, preference for asymmetric weapons, an interest in local validity, etc.\",\"url\":\"https://www.lesswrong.com/posts/6CM7rcnTBjoeE9M8S/thoughts-on-lesswrong-norms-the-art-of-discourse-and\",\"favicon\":\"\"},{\"id\":\"67\",\"title\":\"What mistakes has the AI safety movement made? - LessWrong\",\"description\":\"May 23, 2024 Â· LessWrong got into a terrible habit of fortifying an echo chamber of ideas that only worked on LessWrong. No matter how good an idea, if itÂ ...\",\"url\":\"https://www.lesswrong.com/posts/cGzQBRDrpNHoYtbKN/what-mistakes-has-the-ai-safety-movement-made\",\"favicon\":\"\"},{\"id\":\"68\",\"title\":\"Index of rationalist groups in the Bay Area June 2025 - LessWrong\",\"description\":\"Jul 26, 2024 Â· We're making a new index, hopefully up to date and as complete as we can! This is now being mirrored at BayRationality.com, which will hopefully get prettierÂ ...Missing:  demographics | Show results with:demographics\",\"url\":\"https://www.lesswrong.com/posts/hDefuqC2Rbnr8THYW/index-of-rationalist-groups-in-the-bay-area-june-2025\",\"favicon\":\"\"},{\"id\":\"69\",\"title\":\"Eliezer Yudkowsky - LessWrong\",\"description\":\"Sequences, Metaethics, Quantum Physics, Fun Theory, Ethical Injunctions, The Bayesian Conspiracy, Three Worlds Collide, Highly Advanced Epistemology 101 forÂ ...\",\"url\":\"https://www.lesswrong.com/users/eliezer_yudkowsky\",\"favicon\":\"\"},{\"id\":\"70\",\"title\":\"Eliezer Yudkowsky - LessWrong\",\"description\":\"Feb 9, 2014 Â· Yudkowsky's chapter specifically examines how cognitive biases impact thinking about global catastrophic risks. â€œAI as a Positive and NegativeÂ ...Missing:  initial | Show results with:initial\",\"url\":\"https://www.lesswrong.com/w/eliezer-yudkowsky\",\"favicon\":\"\"},{\"id\":\"71\",\"title\":\"A question about Eliezer - LessWrong\",\"description\":\"Apr 19, 2012 Â· Eliezer has written extensively about AI, rationality, quantum physics, singularity research, etc. I have a question: how correct has he been?\",\"url\":\"https://www.lesswrong.com/posts/HjMZpMHcaJum8tXo9/a-question-about-eliezer\",\"favicon\":\"\"},{\"id\":\"72\",\"title\":\"\",\"description\":\"\",\"url\":\"https://www.lesswrong.com/users/gwern\",\"favicon\":\"\"},{\"id\":\"73\",\"title\":\"paulfchristiano - LessWrong\",\"description\":\"A community blog devoted to refining the art of rationality.\",\"url\":\"https://www.lesswrong.com/users/paulfchristiano\",\"favicon\":\"\"},{\"id\":\"74\",\"title\":\"Another (outer) alignment failure story - LessWrong\",\"description\":\"Apr 7, 2021 Â· This is a story where the alignment problem is somewhat harder than I expect, society handles AI more competently than I expect, and the outcome is worse thanÂ ...AMA: Paul Christiano, alignment researcher - LessWrongAlignment Is Not All You Need - LessWrongMore results from www.lesswrong.com\",\"url\":\"https://www.lesswrong.com/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story\",\"favicon\":\"\"},{\"id\":\"75\",\"title\":\"AI #113: The o3 Era Begins - LessWrong\",\"description\":\"Apr 24, 2025 Â· Zvi Mowshowitz: In-person it's still totally fine. And as a writer of text, this is great, because I know if someone doesn't get a conceptÂ ...\u003c|separator|\u003e\",\"url\":\"https://www.lesswrong.com/posts/7x9MZCmoFA2FtBtmG/ai-113-the-o3-era-begins\",\"favicon\":\"\"},{\"id\":\"76\",\"title\":\"Category Theory Without The Baggage - LessWrong\",\"description\":\"Feb 3, 2020 Â· Category theory is the study of paths in graphs, so I'll briefly talk about that and highlight some relevant aspects. What's a category? AÂ ...A few thoughts on my self-study for alignment research - LessWrongThe Plan - 2023 Version - LessWrongMore results from www.lesswrong.com\",\"url\":\"https://www.lesswrong.com/posts/B4DuwmtqF3HhNwvua/category-theory-without-the-baggage\",\"favicon\":\"\"},{\"id\":\"77\",\"title\":\"Eliezer passes 100000 karma points - LessWrong\",\"description\":\"Mar 9, 2011 Â· Eliezer Yudkowsky has passed an arbitrary milestone: 100,000 karma points on Less Wrong. Allow me just a moment to celebrate this like weÂ ...\",\"url\":\"https://www.lesswrong.com/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points\",\"favicon\":\"\"},{\"id\":\"78\",\"title\":\"2019 Review: Voting Results! - LessWrong\",\"description\":\"Jan 31, 2021 Â· Both this year and last year we have also seen little correlation with the vote results and the karma of the posts, which is an importantÂ ...\",\"url\":\"https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results\",\"favicon\":\"\"},{\"id\":\"79\",\"title\":\"Roko's Basilisk - LessWrong\",\"description\":\"Nov 30, 2022 Â· Roko's basilisk was an attempt to use Yudkowsky's proposed decision theory (TDT) to argue against his informal characterization of an idealÂ ...Background Â· Roko's post Â· Topic moderation and responseMissing:  implications | Show results with:implications\",\"url\":\"https://www.lesswrong.com/w/rokos-basilisk\",\"favicon\":\"\"},{\"id\":\"80\",\"title\":\"A few misconceptions surrounding Roko's basilisk - LessWrong\",\"description\":\"reading about Roko's basilisk causing \\\"nervous ...Breaking the vicious cycle - LessWrongMore results from www.lesswrong.com\",\"url\":\"https://www.lesswrong.com/posts/WBJZoeJypcNRmsdHx/a-few-misconceptions-surrounding-roko-s-basilisk\",\"favicon\":\"\"},{\"id\":\"81\",\"title\":\"In Wikipedia â€” reading about Roko's basilisk causing \\\"nervous ...\",\"description\":\"Oct 13, 2021 Â· Discussion of Roko's basilisk was banned on LessWrong for several years because Yudkowsky had stated that it caused some readers to have nervous breakdowns.Missing:  aftermath | Show results with:aftermath\",\"url\":\"https://www.lesswrong.com/posts/ZZTTranBLHwSjrt7g/in-wikipedia-reading-about-roko-s-basilisk-causing-nervous\",\"favicon\":\"\"},{\"id\":\"82\",\"title\":\"Why is Mencius Moldbug so popular on Less Wrong? [Answer\",\"description\":\"Nov 16, 2012 Â· I've seen several people on Less Wrong recommend Mencius Moldbug's writings, and I've been curious about how he became so popular here.\",\"url\":\"https://www.lesswrong.com/posts/6qPextf9KyWLFJ53j/why-is-mencius-moldbug-so-popular-on-less-wrong-answer-he-s\",\"favicon\":\"\"},{\"id\":\"83\",\"title\":\"\\\"NRx\\\" vs. \\\"Prog\\\" Assumptions: Locating the Sources of ... - LessWrong\",\"description\":\"Sep 4, 2014 Â· While neoreaction and progressivism have a lot of differing descriptive assumptions, there is really only one fundamental normative disagreement.\",\"url\":\"https://www.lesswrong.com/posts/6FzkEzpPQxrLyu8eH/nrx-vs-prog-assumptions-locating-the-sources-of-disagreement\",\"favicon\":\"\"},{\"id\":\"84\",\"title\":\"Neo-reactionaries, why are you - LessWrong\",\"description\":\"Nov 17, 2014 Â· Through LessWrong, I've discovered the no-reactionary movement. Servery says that there are some of you here. I'm curious, what lead you toÂ ...\",\"url\":\"https://www.lesswrong.com/posts/RWKXeM49Stc4aEcEc/neo-reactionaries-why-are-you-neo-reactionary\",\"favicon\":\"\"},{\"id\":\"85\",\"title\":\"The Anti-Reactionary FAQ - Slate Star Codex\",\"description\":\"Oct 20, 2013 Â· This is the Anti-Reactionary FAQ. It is meant to rebut some common beliefs held by the political movement called Reaction or Neoreaction.\",\"url\":\"https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/\",\"favicon\":\"\"},{\"id\":\"86\",\"title\":\"Two-year update on my personal AI timelines - LessWrong\",\"description\":\"Aug 2, 2022 Â· I worked on my draft report on biological anchors for forecasting AI timelines mainly between ~May 2019 (three months after the release of GPT-2) and ~Jul 2020.\",\"url\":\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\",\"favicon\":\"\"},{\"id\":\"87\",\"title\":\"Two-year update on my personal AI timelines - AI Alignment Forum\",\"description\":\"Aug 2, 2022 Â· I worked on my draft report on biological anchors for forecasting AI timelines mainly between ~May 2019 (three months after the release of GPT-2) and ~Jul 2020.\",\"url\":\"https://www.alignmentforum.org/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\",\"favicon\":\"\"},{\"id\":\"88\",\"title\":\"Beware boasting about non-existent forecasting track records\",\"description\":\"May 20, 2022 Â· The bets registry shows two bets lost by Eliezer Yudkowsky, none won; The public figure profile on Metaculus has no resolved predictions yet.Contra Yudkowsky on AI Doom - LessWrongYudkowsky vs Hanson on FOOM: Whose Predictions Were Better?More results from www.lesswrong.com\",\"url\":\"https://www.lesswrong.com/posts/ZEgQGAjQm5rTAnGuM/beware-boasting-about-non-existent-forecasting-track-records\",\"favicon\":\"\"},{\"id\":\"89\",\"title\":\"Eliezer Yudkowsky Is Frequently, Confidently, Egregiously Wrong\",\"description\":\"Aug 27, 2023 Â· It has made a series of accurate predictions about the neural correlates of consciousness. Same with McFadden's theory. It seems Yudkowsky'sÂ ...What Eliezer thinks the zombie... Â· In which Eliezer, after getting...\",\"url\":\"https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously\",\"favicon\":\"\"},{\"id\":\"90\",\"title\":\"Attitudes about Applied Rationality - LessWrong\",\"description\":\"Feb 3, 2024 Â· If we have accurate prediction markets on the review results, maybe we can have better incentives on LessWrong today. Will this post makeÂ ...Missing:  criticism | Show results with:criticism\u003c|separator|\u003e\",\"url\":\"https://www.lesswrong.com/posts/5jdqtpT6StjKDKacw/attitudes-about-applied-rationality\",\"favicon\":\"\"},{\"id\":\"91\",\"title\":\"Quantified Intuitions: An epistemics training website including a new ...\",\"description\":\"Sep 20, 2022 Â· Quantified Intuitions helps users practice assigning credences to outcomes with a quick feedback loop, using two apps: Calibration game andÂ ...\u003c|separator|\u003e\",\"url\":\"https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website\",\"favicon\":\"\"},{\"id\":\"92\",\"title\":\"Why Are There So Many Rationalist Cults? - Asterisk Magazine\",\"description\":\"shall we say â€” high demand groups.Missing:  studies | Show results with:studies\",\"url\":\"https://asteriskmag.substack.com/p/why-are-there-so-many-rationalist\",\"favicon\":\"\"},{\"id\":\"93\",\"title\":\"Evaluating Predictions in Hindsight - LessWrong\",\"description\":\"Apr 16, 2020 Â· Most of all, this method doesn't actually reward accurate predictions. It rewards predictions that tend to disagree in the correct direction.Â ...\",\"url\":\"https://www.lesswrong.com/posts/BthNiWJDagLuf2LN2/evaluating-predictions-in-hindsight\",\"favicon\":\"\"},{\"id\":\"94\",\"title\":\"LessWrong moderation messaging container\",\"description\":\"Apr 21, 2023 Â· All first-time comments get reviewed by moderators to ensure they're productive contributions that fit with LessWrong's particular culture/Â ...\",\"url\":\"https://www.lesswrong.com/posts/zXJfH7oZ62Xojnrqs/lesswrong-moderation-messaging-container\",\"favicon\":\"\"},{\"id\":\"95\",\"title\":\"LW moderation: my current thoughts and questions, 2023-04-12\",\"description\":\"Apr 20, 2023 Â· The LessWrong team is currently in the midst of rethinking/redesigning/upgrading our moderation policies and principles (announcement). In orderÂ ...Missing:  practices | Show results with:practices\",\"url\":\"https://www.lesswrong.com/posts/eKxLEHeLvKZYR7MmN/lw-moderation-my-current-thoughts-and-questions-2023-04-12\",\"favicon\":\"\"},{\"id\":\"96\",\"title\":\"The commenting restrictions on LessWrong seem bad\",\"description\":\"Sep 16, 2023 Â· The bar for writing a post or a comment with non-negative expected karma is pretty low. ... I personally think the 2 rules were reasonableÂ ...\",\"url\":\"https://www.lesswrong.com/posts/7FAneMMzGjxBsosue/the-commenting-restrictions-on-lesswrong-seem-bad\",\"favicon\":\"\"},{\"id\":\"97\",\"title\":\"To contribute to AI safety, consider doing AI research - LessWrong\",\"description\":\"Jan 16, 2016 Â· There's not that much overlap between MIRI's work and mainstream CS, so I'd recommend a more broad focus. Research experience is always helpful,Â ...\",\"url\":\"https://www.lesswrong.com/posts/pCesigb4NjzvoNKWB/to-contribute-to-ai-safety-consider-doing-ai-research\",\"favicon\":\"\"},{\"id\":\"98\",\"title\":\"MIRI 2024 Mission and Strategy Update - LessWrong\",\"description\":\"Jan 4, 2024 Â· When MIRI was first founded by Eliezer Yudkowsky and Brian and Sabine Atkins in 2000, its goal was to try to accelerate to smarter-thanÂ ...\",\"url\":\"https://www.lesswrong.com/posts/q3bJYTB3dGRf5fbD9/miri-2024-mission-and-strategy-update\",\"favicon\":\"\"},{\"id\":\"99\",\"title\":\"Challenges to Christiano's capability amplification proposal\",\"description\":\"May 19, 2018 Â· Eliezer Yudkowsky offers detailed critiques of Paul Christiano's AI alignment proposal, arguing that it faces major technical challenges andÂ ...Missing:  influence | Show results with:influence\",\"url\":\"https://www.lesswrong.com/posts/S7csET9CgBtpi7sCh/challenges-to-christiano-s-capability-amplification-proposal\",\"favicon\":\"\"},{\"id\":\"100\",\"title\":\"A newcomer's guide to the technical AI safety field - LessWrong\",\"description\":\"Nov 4, 2022 Â· This post provides an overview on the field that helps map research agendas along the various paradigms, and gives some context to the implicit assumptions.Brief History Of Ai And Ai... Â· Different Paradigms Â· Threat ModelsMissing:  timelines | Show results with:timelines\",\"url\":\"https://www.lesswrong.com/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field\",\"favicon\":\"\"},{\"id\":\"101\",\"title\":\"Existential risk - LessWrong\",\"description\":\"Mar 19, 2023 Â· An existential risk (or x-risk) is a risk that poses astronomically large negative consequences for humanity, such as human extinction or permanent globalÂ ...\",\"url\":\"https://www.lesswrong.com/w/existential-risk\",\"favicon\":\"\"},{\"id\":\"102\",\"title\":\"A personal history of involvement with effective altruism - LessWrong\",\"description\":\"Jun 10, 2013 Â· Over the coming weeks, I intend to write up a history of the different parts of the effective altruist movement and their interrelations.Missing:  friendly | Show results with:friendly\",\"url\":\"https://www.lesswrong.com/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism\",\"favicon\":\"\"},{\"id\":\"103\",\"title\":\"Noting an unsubstantiated belief about the FTX disaster - LessWrong\",\"description\":\"Nov 12, 2022 Â· Sam Bankman Fried did what he did primarily for the sake of \\\"Effective Altruism,\\\" as he understood it. Even though from a purely utilitarianÂ ...\",\"url\":\"https://www.lesswrong.com/posts/HMaBPzrnvg2WCw6KL/noting-an-unsubstantiated-belief-about-the-ftx-disaster\",\"favicon\":\"\"},{\"id\":\"104\",\"title\":\"Estimating the probability that FTX Future Fund grant money gets ...\",\"description\":\"Nov 13, 2022 Â· It would be great to have more people involved in estimating the probability that FTX Future Fund grants end up getting clawed back.\",\"url\":\"https://www.lesswrong.com/posts/9weamhzzBpqxz3A2e/estimating-the-probability-that-ftx-future-fund-grant-money\",\"favicon\":\"\"},{\"id\":\"105\",\"title\":\"We must be very clear: fraud in the service of effective altruism is ...\",\"description\":\"Nov 10, 2022 Â· I think the main issue here is that Less Wrong is not Effective Altruism, and that many (at a guess, most) LW members are not affiliated with EAÂ ...\",\"url\":\"https://www.lesswrong.com/posts/8wYH4WggxFqT9yhzJ/we-must-be-very-clear-fraud-in-the-service-of-effective\",\"favicon\":\"\"},{\"id\":\"106\",\"title\":\"The case for stopping AI safety research - LessWrong\",\"description\":\"May 23, 2024 Â· MIRI has stopped all funding of safety research (to focus on advocacy) explaining that the research that they have been funding (which does notÂ ...\",\"url\":\"https://www.lesswrong.com/posts/vkzmbf4Mve4GNyJaF/the-case-for-stopping-ai-safety-research\",\"favicon\":\"\"},{\"id\":\"107\",\"title\":\"An Outsider's Roadmap into AI Safety Research (2025) - LessWrong\",\"description\":\"Jul 20, 2025 Â· Deceptive alignment: Ensuring AI systems are genuinely aligned, not just pretending until they're powerful enough to pursue their own goalsÂ ...Missing:  2019-2025 | Show results with:2019-2025\",\"url\":\"https://www.lesswrong.com/posts/bcuzjKmNZHWDuEwBz/an-outsider-s-roadmap-into-ai-safety-research-2025\",\"favicon\":\"\"},{\"id\":\"108\",\"title\":\"An Overview of the AI Safety Funding Situation - LessWrong\",\"description\":\"Jul 12, 2023 Â· The large 'Other' amounts are due to large cryptocurrency donations such as the one to MIRI ($15M) and FLI ($25M). The graph doesn't include theÂ ...\",\"url\":\"https://www.lesswrong.com/posts/WGpFFJo2uFe5ssgEb/an-overview-of-the-ai-safety-funding-situation\",\"favicon\":\"\"},{\"id\":\"109\",\"title\":\"Towards more cooperative AI safety strategies - LessWrong\",\"description\":\"Jul 15, 2024 Â· My understanding of MIRI plan was \\\"have a controllable, safe AI that's just powerful enough to take some action that prevents anyone elseÂ ...\",\"url\":\"https://www.lesswrong.com/posts/5uffoui3axcK7gQXG/towards-more-cooperative-ai-safety-strategies\",\"favicon\":\"\"},{\"id\":\"110\",\"title\":\"Center for Applied Rationality: Home\",\"description\":\"a nonprofit organization focused on creating a space in which to explore and practice better ways of thinking. We runÂ ...Workshops Â· Mission Â· Rationality Reading List Â· Rationality Checklist\",\"url\":\"http://www.rationality.org/\",\"favicon\":\"\"},{\"id\":\"111\",\"title\":\"The 'Rationality' Workshop That Teaches People to Think More Like ...\",\"description\":\"May 17, 2016 Â· CFAR doesn't advertise much. Many participants, including Beswick, learn about the organization through a blog called Less Wrong, a rationalityÂ ...\",\"url\":\"https://www.vice.com/en/article/center-for-applied-rationality/\",\"favicon\":\"\"},{\"id\":\"112\",\"title\":\"The Centre for Applied Rationality: a year later from a ... - LessWrong\",\"description\":\"May 27, 2013 Â· In the eyes of the general public, these groups are not distinguishable from one another-- they all provide \\\"rationality training.\\\" AÂ ...\",\"url\":\"https://www.lesswrong.com/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a\",\"favicon\":\"\"},{\"id\":\"113\",\"title\":\"Manifold Markets - LessWrong\",\"description\":\"Feb 2, 2024 Â· Manifold Markets is a prediction market platform where I've been trading since September. This post will compare it to other prediction markets that I've used.Missing:  influence | Show results with:influence\",\"url\":\"https://www.lesswrong.com/posts/ptEtB4wbLixRuy8MG/manifold-markets-1\",\"favicon\":\"\"},{\"id\":\"114\",\"title\":\"Top traders - Manifold Markets\",\"description\":\"As part of LessWrong's Annual Review, the community nominates, writes reviews, and votes on the most valuable posts. Posts are reviewable once they haveÂ ...\",\"url\":\"https://manifold.markets/LessWrong/will-against-almost-every-theory-of-6a6c2cb48fde\",\"favicon\":\"\"},{\"id\":\"115\",\"title\":\"The Proper Use of Humility - LessWrong\",\"description\":\"Dec 2, 2006 Â· â€œHumilityâ€ is a virtue that is often misunderstood. This doesn't mean we should discard the concept of humility, but we should be careful using it.\",\"url\":\"https://www.lesswrong.com/posts/GrDqnMjhqoxiqpQPw/the-proper-use-of-humility\",\"favicon\":\"\"},{\"id\":\"116\",\"title\":\"Humility - LessWrong\",\"description\":\"Nov 16, 2021 Â· The most commonly cited explanation of scientific/epistemic humility on LW is found in Yudkowsky's \\\"Twelve Virtues of Rationality\\\" (2006):.\",\"url\":\"https://www.lesswrong.com/w/humility\",\"favicon\":\"\"},{\"id\":\"117\",\"title\":\"Why You Should Never Update Your Beliefs - LessWrong\",\"description\":\"Jul 28, 2023 Â· Uncharted epistemic territory is dangerous because it's awash with incorrect arguments which might convince you of their false conclusions.\",\"url\":\"https://www.lesswrong.com/posts/LCduhA4m3RhMjZJPA/why-you-should-never-update-your-beliefs\",\"favicon\":\"\"},{\"id\":\"118\",\"title\":\"We run the Center for Applied Rationality, AMA - LessWrong\",\"description\":\"Dec 19, 2019 Â· Rationality training is not so obviously useful that an entire org needs to exist to support it; especially now that you've iterated soÂ ...\",\"url\":\"https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama\",\"favicon\":\"\"},{\"id\":\"119\",\"title\":\"Why is there such hate for Less Wrong in Reddits Philosophy ...\",\"description\":\"Jan 22, 2016 Â· LW has fairly strong norms against political discussions in general. Most people in the less wrong community take these ideas into seriousÂ ...Missing:  boundaries groupthink\",\"url\":\"https://www.reddit.com/r/askphilosophy/comments/425h9e/why_is_there_such_hate_for_less_wrong_in_reddits/\",\"favicon\":\"\"},{\"id\":\"120\",\"title\":\"The founder of LessWrong didn't even attend high school, but claims ...\",\"description\":\"Apr 23, 2023 Â· By this standard Yudkowsky also could never have succeeded in a PhD program. He doesn't have the discipline or the dedication for such a thing.\",\"url\":\"https://www.reddit.com/r/SneerClub/comments/12wfi7h/the_founder_of_lesswrong_didnt_even_attend_high/\",\"favicon\":\"\"},{\"id\":\"121\",\"title\":\"Is AI Progress Impossible To Predict? - LessWrong\",\"description\":\"May 15, 2022 Â· Luckily, there is a famous paper on how AI progress is governed by scaling laws, where models predictably get better as they get larger.\",\"url\":\"https://www.lesswrong.com/posts/G993PFTwqqdQv4eTg/is-ai-progress-impossible-to-predict\",\"favicon\":\"\"},{\"id\":\"122\",\"title\":\"The Trans Cult Who Believes AI Will Either Save Usâ€”or Kill Us All\",\"description\":\"Mar 13, 2025 Â· What the Zizians, a trans vegan cult allegedly behind multiple murders, can teach us about radicalization and our tech-addled politics.\u003c|separator|\u003e\",\"url\":\"https://www.thenation.com/article/society/trans-vegan-cult-zizians-murders/\",\"favicon\":\"\"},{\"id\":\"123\",\"title\":\"Why Are There So Many Rationalist Cults? - Asterisk Magazine\",\"description\":\"Rationalist groups tend to be dysfunctional to the extent that their activities involve very long conversations about human psychology and social dynamics,Â ...The Problem Of Young... Â· Taking Ideas Seriously Â· Beware Psychology\",\"url\":\"https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults\",\"favicon\":\"\"},{\"id\":\"124\",\"title\":\"6 Year Decrease of Metaculus AGI Prediction : r/slatestarcodex\",\"description\":\"Apr 12, 2022 Â· Metaculus now predicts that the first AGI[1] will become publicly known in 2036. This is a massive update - 6 years faster than previousÂ ...\",\"url\":\"https://www.reddit.com/r/slatestarcodex/comments/u1u3c2/6_year_decrease_of_metaculus_agi_prediction/\",\"favicon\":\"\"},{\"id\":\"125\",\"title\":\"AI timeline predictions: are we getting better? - LessWrong\",\"description\":\"Aug 17, 2012 Â· We now have more rigorous evidence on the \\\"Maes-Garreau law\\\" (the idea that people will predict AI coming before they die).\",\"url\":\"https://www.lesswrong.com/posts/47ci9ixyEbGKWENwR/ai-timeline-predictions-are-we-getting-better\",\"favicon\":\"\"},{\"id\":\"126\",\"title\":\"Sidebar: Mutual Hostilities - Suspended Reason\",\"description\":\"Apr 15, 2020 Â· Since there is very little awareness of LessWrong rationalism among professional or academic ... criticism of LW's ideas and insularity.\",\"url\":\"https://suspendedreason.com/2020/04/15/sidebar-mutual-hostilities/\",\"favicon\":\"\"},{\"id\":\"127\",\"title\":\"Why Academia is Mostly Not Truth-Seeking - LessWrong\",\"description\":\"Oct 16, 2024 Â· Academic research can be fake in different ways. It can simply be false. It can be emotionally manipulative propaganda masquerading as knowledgeÂ ...Missing:  criticisms | Show results with:criticisms\",\"url\":\"https://www.lesswrong.com/posts/K5LYLvZvdthdyRFFQ/why-academia-is-mostly-not-truth-seeking\",\"favicon\":\"\"},{\"id\":\"128\",\"title\":\"Intellectual Progress Inside and Outside Academia - LessWrong\",\"description\":\"Sep 2, 2017 Â· If you want to get real work done, the obvious strategy would be to not subject yourself to any academic incentives or bureaucratic processes.Missing:  criticisms | Show results with:criticisms\",\"url\":\"https://www.lesswrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia\",\"favicon\":\"\"}],\"images\":[{\"id\":\"a10ea63886ce\",\"caption\":\"LessWrong logo\",\"url\":\"./_assets_/LessWrong_logo.svg.png\",\"position\":\"CENTER\",\"width\":0,\"height\":0}],\"fixedIssues\":[],\"slug\":\"LessWrong\",\"title\":\"LessWrong\",\"content\":\"$1f\",\"description\":\"LessWrong\\n\\nLessWrong logo\\nLessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation,...\",\"metadata\":{\"categories\":[\"LW\",\"Less Wrong\"],\"lastModified\":\"1761583867\",\"contentLength\":\"61221\",\"version\":\"1.0\",\"lastEditor\":\"system\",\"language\":\"en\",\"isRedirect\":false,\"redirectTarget\":\"\",\"isWithheld\":false},\"stats\":{\"totalViews\":\"81933\",\"recentViews\":\"81933\",\"dailyAvgViews\":2731.10009765625,\"qualityScore\":1,\"lastViewed\":\"1761883847\"},\"linkedPages\":null},\"found\":true},\"dataUpdateCount\":1,\"dataUpdatedAt\":1761883847936,\"error\":null,\"errorUpdateCount\":0,\"errorUpdatedAt\":0,\"fetchFailureCount\":0,\"fetchFailureReason\":null,\"fetchMeta\":null,\"isInvalidated\":false,\"status\":\"success\",\"fetchStatus\":\"idle\"},\"queryKey\":[\"page\",\"LessWrong\"],\"queryHash\":\"[\\\"page\\\",\\\"LessWrong\\\"]\"}]},\"children\":\"$L20\"}]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"c:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"LessWrong\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"LessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action. It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as The Sequences, originally developed on the predecessor blog Overcoming Bias....\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"system\"}],[\"$\",\"link\",\"3\",{\"rel\":\"manifest\",\"href\":\"/manifest.webmanifest\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"LW, Less Wrong\"}],[\"$\",\"meta\",\"5\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"6\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-snippet:-1\"}],[\"$\",\"link\",\"7\",{\"rel\":\"canonical\",\"href\":\"https://grokipedia.com/page/LessWrong\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:title\",\"content\":\"LessWrong\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:description\",\"content\":\"LessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action. It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as The Sequences, originally developed on the predecessor blog Overcoming Bias....\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:url\",\"content\":\"https://grokipedia.com/page/LessWrong\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:site_name\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:locale\",\"content\":\"en\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image:width\",\"content\":\"512\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:height\",\"content\":\"512\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:alt\",\"content\":\"LessWrong\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:modified_time\",\"content\":\"1970-01-21T09:19:43.867Z\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:creator\",\"content\":\"@Grokipedia\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:title\",\"content\":\"LessWrong\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:description\",\"content\":\"LessWrong is an online forum and community blog dedicated to refining human rationality through systematic improvement of reasoning, decision-making, and belief formation, with a core emphasis on Bayesian epistemology, cognitive bias reduction, and normative standards for effective action. It was founded in February 2009 by AI researcher Eliezer Yudkowsky, who seeded the site with his extensive series of posts known as The Sequences, originally developed on the predecessor blog Overcoming Bias....\"}],[\"$\",\"meta\",\"23\",{\"name\":\"twitter:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}],[\"$\",\"link\",\"24\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"$L21\",\"25\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"11:\"$c:metadata\"\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"22:I[61172,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"PageEditorProvider\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"23:I[63493,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"default\"]\n"])</script><script nonce="MDJhYTMxYTMtMjRkNi00MDEyLWE5N2MtMGIwYjM0YWM5ZGY5">self.__next_f.push([1,"20:[\"$\",\"$L22\",null,{\"children\":[\"$\",\"$L23\",null,{\"slug\":\"LessWrong\"}]}]\n"])</script></body></html>