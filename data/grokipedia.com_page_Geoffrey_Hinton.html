<!DOCTYPE html><html lang="en" class="bg-surface-base antialiased"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, interactive-widget=resizes-content"/><link rel="stylesheet" href="/_next/static/css/62c4caba71dfda84.css" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/eb3d87f98fe1565f.css" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1b5e561215938d4d.css" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/0227d069a630d414.css" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/f87fff2ab93d05a7.css" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh" href="/_next/static/chunks/webpack-e121ed42680f327e.js"/><script src="/_next/static/chunks/78a669d9-e7993486b22c4915.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/40c4a5a7-abdabb07419d1cfc.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/2230-f7c87dc9fa57c408.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/main-app-536d4b8fca62396a.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/63f0ec43-8ee6a76d70472249.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/7670-7326298c9856172b.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/282-691fffb366e24ca5.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/7515-336759ef5dad2b52.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/927-34e2a6da3e15e26b.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/5855-243eeca8f0e4cabd.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/4393-1c8dff25ec904469.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/2225-454cf9f44775e7ce.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/7618-43536a8fb0dd3bfe.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/app/page/%5Bslug%5D/layout-55a344716dd57c44.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/7720-3a1e7e411adba2d3.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/7086-1f1c4891d766e04f.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/app/page/%5Bslug%5D/not-found-69a3edc7db5749d6.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/app/global-error-4d07d20223cd4b4c.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/8208b75a-a48e5a4507a0de91.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/5497-ab85ef3ea59dd353.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/6281-c6e84786dade3614.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/2660-d983a7f287e89f18.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/5002-9735c25beda556ba.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/3655-6717081f7512305a.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/8945-e4e3cf487f5e27c7.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/9214-a10614844a67ba31.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/4789-2080f6497f78b5b6.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/app/layout-226f2bd71acf9f9e.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/24cf1b50-159cca90b09285e0.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/9ffa21ba-c069766d809bd4c7.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/600-9a9fcafaaa6c1c4c.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/5448-2a3cfd853d899c9a.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/8-8ca70ca619d8e099.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/app/error-4a29e9399afba038.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><script src="/_next/static/chunks/app/not-found-dd95690acf732f18.js" async="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script><meta name="next-size-adjust" content=""/><title>Grokipedia</title><meta name="description" content="Grokipedia is an open source, comprehensive collection of all knowledge."/><link rel="icon" type="image/x-icon" href="/favicon.ico" sizes="48x48"/><link rel="icon" href="/images/icon-dark.png" media="(prefers-color-scheme: light)" type="image/png"/><link rel="icon" href="/images/icon-light.png" media="(prefers-color-scheme: dark)" type="image/png"/><link rel="apple-touch-icon" href="/icon-192x192.png"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-snippet:-1"/><meta property="og:title" content="Grokipedia"/><meta property="og:description" content="Grokipedia is an open source, comprehensive collection of all knowledge."/><meta property="og:url" content="https://grokipedia.com"/><meta property="og:site_name" content="Grokipedia"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta property="og:image" content="https://grokipedia.com/icon-512x512.png"/><meta property="og:image:width" content="512"/><meta property="og:image:height" content="512"/><meta property="og:image:alt" content="Grokipedia"/><meta name="twitter:card" content="summary"/><meta name="twitter:creator" content="@Grokipedia"/><meta name="twitter:title" content="Grokipedia"/><meta name="twitter:description" content="Grokipedia is an open source, comprehensive collection of all knowledge."/><meta name="twitter:image" content="https://grokipedia.com/icon-512x512.png"/><title>Geoffrey Hinton</title><meta name="description" content="Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning. Hinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978. As University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the..."/><meta name="author" content="system"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="keywords" content="Geoff Hinton, Geoffrey E. Hinton, Godfather of AI, Godfather of Deep Learning"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-snippet:-1"/><link rel="canonical" href="https://grokipedia.com/page/Geoffrey_Hinton"/><meta property="og:title" content="Geoffrey Hinton"/><meta property="og:description" content="Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning. Hinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978. As University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the..."/><meta property="og:url" content="https://grokipedia.com/page/Geoffrey_Hinton"/><meta property="og:site_name" content="Grokipedia"/><meta property="og:locale" content="en"/><meta property="og:image" content="https://grokipedia.com/icon-512x512.png"/><meta property="og:image:width" content="512"/><meta property="og:image:height" content="512"/><meta property="og:image:alt" content="Geoffrey Hinton"/><meta property="og:type" content="article"/><meta property="article:modified_time" content="1970-01-21T09:19:42.298Z"/><meta name="twitter:card" content="summary"/><meta name="twitter:creator" content="@Grokipedia"/><meta name="twitter:title" content="Geoffrey Hinton"/><meta name="twitter:description" content="Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning. Hinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978. As University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the..."/><meta name="twitter:image" content="https://grokipedia.com/icon-512x512.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="sentry-trace" content="0def2b7a44c99e3175c4c679b88ce913-c11111c8e5364859-1"/><meta name="baggage" content="sentry-environment=production,sentry-public_key=5f2258f71198ee26a355127af230c3a6,sentry-trace_id=0def2b7a44c99e3175c4c679b88ce913,sentry-org_id=4508179396558848,sentry-transaction=GET%20%2Fpage%2F%5Bslug%5D,sentry-sampled=true,sentry-sample_rand=0.5472308701702913,sentry-sample_rate=1"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule="" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh"></script></head><body class="flex h-[100svh] w-full flex-col __variable_13c637 __variable_8a0ba0 __variable_779740 __variable_2484fd __variable_525cc3 __variable_13486b"><div hidden=""><!--$--><!--/$--></div><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","dark",null,["light","dark"],null,true,true)</script><header class="h-16 bg-surface-base fixed top-0 z-50 w-full"><div class="hidden h-full grid-cols-[1fr_3fr_1fr] items-center gap-4 !py-0 md:grid max-w-full py-6 px-4 w-full mx-auto"><div class="-ml-2 justify-self-start"><a class="cursor-pointer" href="/"><svg width="200" height="auto" viewBox="0 0 955 225" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M99.6937 159.214C90.008 159.214 81.5652 157.414 74.3652 153.814C67.1652 150.214 61.5509 144.986 57.5223 138.129C53.5794 131.271 51.608 123.043 51.608 113.443C51.608 103.843 53.5794 95.4857 57.5223 88.3714C61.5509 81.2572 67.1652 75.7286 74.3652 71.7857C81.6509 67.8429 90.1794 65.8714 99.9509 65.8714C103.208 65.8714 106.679 66.1286 110.365 66.6429C114.051 67.0714 117.222 67.6714 119.879 68.4429C121.508 68.8714 123.008 69.2572 124.379 69.6C125.751 69.9429 127.122 70.1143 128.494 70.1143C129.522 70.1143 130.551 69.9857 131.579 69.7286C131.751 73.5 131.922 77.4 132.094 81.4286C132.265 85.4572 132.522 89.6572 132.865 94.0286C131.065 94.2857 129.565 94.3714 128.365 94.2857C126.651 86.4 123.522 80.5714 118.979 76.8C114.437 72.9429 108.394 71.0143 100.851 71.0143C94.8509 71.0143 89.708 72.1286 85.4223 74.3572C81.2223 76.5 77.7937 79.4572 75.1366 83.2286C72.5652 87 70.6794 91.3714 69.4794 96.3429C68.2794 101.229 67.6794 106.457 67.6794 112.029C67.6794 120.171 68.9223 127.371 71.408 133.629C73.8937 139.886 77.6652 144.814 82.7223 148.414C87.8652 151.929 94.2937 153.686 102.008 153.686C104.408 153.686 107.065 153.471 109.979 153.043C112.894 152.529 115.679 151.757 118.337 150.729V134.529C118.337 131.871 118.208 129.814 117.951 128.357C117.779 126.814 117.222 125.7 116.279 125.014C115.422 124.329 114.008 123.857 112.037 123.6C110.151 123.257 107.537 122.957 104.194 122.7C103.937 121.329 103.937 119.957 104.194 118.586C105.994 118.586 108.179 118.629 110.751 118.714C113.322 118.714 115.894 118.757 118.465 118.843C121.122 118.843 123.308 118.843 125.022 118.843C127.679 118.843 130.722 118.8 134.151 118.714C137.665 118.629 140.665 118.586 143.151 118.586C143.322 119.871 143.322 121.2 143.151 122.571C139.637 123 137.108 123.429 135.565 123.857C134.022 124.286 133.079 125.143 132.737 126.429C132.394 127.714 132.222 129.9 132.222 132.986V137.1C132.222 141.129 132.308 144.514 132.479 147.257C132.737 150 132.951 151.971 133.122 153.171C121.208 157.2 110.065 159.214 99.6937 159.214ZM148.19 157.414C147.933 156.043 147.933 154.714 148.19 153.429C151.105 153.257 153.248 153 154.619 152.657C155.99 152.229 156.89 151.371 157.319 150.086C157.748 148.8 157.962 146.743 157.962 143.914V115.114C157.962 111.771 157.79 109.286 157.448 107.657C157.19 106.029 156.376 104.914 155.005 104.314C153.719 103.629 151.49 103.071 148.319 102.643C148.062 101.443 148.062 100.329 148.319 99.3C151.748 98.6143 155.09 97.8429 158.348 96.9857C161.605 96.0429 165.033 94.8429 168.633 93.3857L170.819 94.1572V105.471C176.819 97.8429 182.948 94.0286 189.205 94.0286C192.205 94.0286 194.433 94.8429 195.89 96.4714C197.348 98.0143 198.076 99.7714 198.076 101.743C198.076 104.057 197.305 105.857 195.762 107.143C194.219 108.343 192.462 108.943 190.49 108.943C188.862 108.943 187.233 108.514 185.605 107.657C184.062 106.8 182.905 105.471 182.133 103.671C179.219 103.671 176.605 104.829 174.29 107.143C172.062 109.371 170.948 111.986 170.948 114.986V142.629C170.948 145.971 171.119 148.371 171.462 149.829C171.89 151.286 172.919 152.229 174.548 152.657C176.262 153 179.005 153.257 182.776 153.429C182.948 154.629 182.948 155.957 182.776 157.414C179.862 157.414 176.862 157.371 173.776 157.286C170.69 157.2 167.519 157.157 164.262 157.157C161.09 157.157 158.262 157.2 155.776 157.286C153.376 157.371 150.848 157.414 148.19 157.414ZM229.285 158.829C223.028 158.829 217.542 157.5 212.828 154.843C208.199 152.1 204.599 148.371 202.028 143.657C199.457 138.857 198.171 133.371 198.171 127.2C198.171 120.514 199.499 114.686 202.157 109.714C204.899 104.743 208.714 100.886 213.599 98.1429C218.485 95.4 224.099 94.0286 230.442 94.0286C236.699 94.0286 242.142 95.4 246.771 98.1429C251.399 100.886 254.999 104.657 257.571 109.457C260.142 114.257 261.428 119.7 261.428 125.786C261.428 132.043 260.057 137.7 257.314 142.757C254.657 147.729 250.928 151.671 246.128 154.586C241.328 157.414 235.714 158.829 229.285 158.829ZM212.699 125.657C212.699 134.4 214.114 141.343 216.942 146.486C219.857 151.543 224.185 154.071 229.928 154.071C235.414 154.071 239.614 151.671 242.528 146.871C245.442 141.986 246.899 135.471 246.899 127.329C246.899 118.671 245.442 111.771 242.528 106.629C239.614 101.486 235.371 98.9143 229.799 98.9143C224.314 98.9143 220.071 101.271 217.071 105.986C214.157 110.7 212.699 117.257 212.699 125.657ZM267.394 157.414C267.308 157.071 267.265 156.729 267.265 156.386C267.265 156.043 267.265 155.7 267.265 155.357C267.265 155.014 267.265 154.714 267.265 154.457C267.265 154.114 267.308 153.771 267.394 153.429C270.308 153.257 272.451 153 273.822 152.657C275.194 152.229 276.094 151.371 276.522 150.086C276.951 148.8 277.165 146.743 277.165 143.914V79.5C277.165 76.8429 276.908 74.8714 276.394 73.5857C275.965 72.2143 274.979 71.2714 273.437 70.7572C271.979 70.1572 269.751 69.7286 266.751 69.4714C266.665 69.1286 266.622 68.8286 266.622 68.5714C266.622 68.3143 266.622 68.0572 266.622 67.8C266.622 67.4572 266.622 67.1572 266.622 66.9C266.622 66.6429 266.665 66.3429 266.751 66C270.179 65.5714 273.694 64.9286 277.294 64.0714C280.894 63.1286 284.579 61.8429 288.351 60.2143L290.537 60.9857C290.451 62.8714 290.365 65.0143 290.279 67.4143C290.279 69.8143 290.279 72.4286 290.279 75.2572V122.957C291.308 122.957 292.165 122.786 292.851 122.443C293.537 122.1 294.094 121.757 294.522 121.414C294.694 121.243 295.037 120.943 295.551 120.514C296.065 120 296.965 119.1 298.251 117.814C299.537 116.529 301.379 114.6 303.779 112.029C306.008 109.543 307.765 107.614 309.051 106.243C310.422 104.786 311.108 103.586 311.108 102.643C311.108 101.957 310.508 101.4 309.308 100.971C308.194 100.457 306.651 100.157 304.679 100.071C304.594 99.7286 304.551 99.3857 304.551 99.0429C304.551 98.7 304.551 98.3572 304.551 98.0143C304.551 97.6714 304.551 97.3286 304.551 96.9857C304.551 96.6429 304.594 96.3 304.679 95.9572C306.394 95.9572 308.537 96 311.108 96.0857C313.765 96.1714 316.122 96.2143 318.179 96.2143C319.208 96.2143 320.665 96.2143 322.551 96.2143C324.522 96.1286 326.494 96.0857 328.465 96.0857C330.437 96.0857 331.894 96.0857 332.837 96.0857C332.922 96.4286 332.965 96.7714 332.965 97.1143C333.051 97.4572 333.094 97.8 333.094 98.1429C333.094 98.4857 333.051 98.8286 332.965 99.1714C332.965 99.4286 332.922 99.7286 332.837 100.071C328.379 100.157 324.608 101.271 321.522 103.414C318.437 105.471 315.479 107.914 312.651 110.743L303.394 120L321.137 143.4C323.022 145.886 324.565 147.857 325.765 149.314C327.051 150.686 328.422 151.671 329.879 152.271C331.337 152.871 333.351 153.257 335.922 153.429C336.094 154.629 336.094 155.957 335.922 157.414C334.808 157.414 333.137 157.371 330.908 157.286C328.765 157.2 325.379 157.157 320.751 157.157C320.065 157.157 319.037 157.157 317.665 157.157C316.294 157.157 315.008 157.243 313.808 157.414C313.808 156.471 313.294 155.186 312.265 153.557C311.237 151.843 310.422 150.6 309.822 149.829C309.565 149.4 308.922 148.5 307.894 147.129C306.865 145.671 305.622 144 304.165 142.114C302.794 140.143 301.379 138.171 299.922 136.2C298.465 134.143 297.137 132.343 295.937 130.8C294.994 129.514 294.094 128.529 293.237 127.843C292.465 127.071 291.479 126.686 290.279 126.686V142.629C290.279 145.971 290.408 148.371 290.665 149.829C291.008 151.286 291.737 152.229 292.851 152.657C294.051 153 295.851 153.257 298.251 153.429C298.422 154.714 298.422 156.043 298.251 157.414C296.022 157.414 293.665 157.371 291.179 157.286C288.779 157.2 286.165 157.157 283.337 157.157C280.594 157.157 277.894 157.2 275.237 157.286C272.579 157.371 269.965 157.414 267.394 157.414ZM369.34 157.414C366.94 157.414 364.454 157.371 361.883 157.286C359.311 157.2 356.526 157.157 353.526 157.157C350.783 157.157 347.997 157.2 345.169 157.286C342.426 157.371 339.769 157.414 337.197 157.414C336.94 156.043 336.94 154.714 337.197 153.429C340.111 153.257 342.254 153 343.626 152.657C344.997 152.229 345.897 151.371 346.326 150.086C346.754 148.8 346.969 146.743 346.969 143.914V115.114C346.969 111.771 346.84 109.286 346.583 107.657C346.326 106.029 345.511 104.914 344.14 104.314C342.854 103.629 340.583 103.071 337.326 102.643C337.069 101.443 337.069 100.329 337.326 99.3C341.097 98.6143 344.697 97.7572 348.126 96.7286C351.554 95.7 354.854 94.5857 358.026 93.3857L360.211 94.1572C360.126 96.8143 360.04 99.3 359.954 101.614C359.954 103.929 359.954 106.114 359.954 108.171V142.629C359.954 145.971 360.126 148.371 360.469 149.829C360.897 151.286 361.754 152.229 363.04 152.657C364.411 153 366.511 153.257 369.34 153.429C369.597 154.714 369.597 156.043 369.34 157.414ZM343.626 71.5286C343.626 69.0429 344.483 66.9429 346.197 65.2286C347.997 63.5143 350.14 62.6572 352.626 62.6572C355.026 62.6572 357.083 63.5143 358.797 65.2286C360.597 66.9429 361.497 69 361.497 71.4C361.497 73.6286 360.64 75.6857 358.926 77.5715C357.211 79.3714 355.026 80.2714 352.369 80.2714C349.969 80.2714 347.911 79.4143 346.197 77.7C344.483 75.9857 343.626 73.9286 343.626 71.5286ZM372.678 188.914C372.592 187.543 372.592 186.214 372.678 184.929C375.678 184.757 377.864 184.457 379.235 184.029C380.607 183.6 381.464 182.743 381.807 181.457C382.235 180.257 382.45 178.286 382.45 175.543V115.114C382.45 111.771 382.278 109.286 381.935 107.657C381.678 106.029 380.864 104.914 379.492 104.314C378.207 103.629 375.978 103.071 372.807 102.643C372.635 101.443 372.635 100.329 372.807 99.3C376.321 98.6143 379.75 97.8 383.092 96.8572C386.435 95.9143 389.907 94.7572 393.507 93.3857L395.307 94.2857C395.221 96.4286 395.178 98.2714 395.178 99.8143C395.178 101.271 395.178 102.686 395.178 104.057C398.521 100.543 401.821 98.0143 405.078 96.4714C408.335 94.8429 411.807 94.0286 415.492 94.0286C420.892 94.0286 425.435 95.4429 429.121 98.2714C432.892 101.1 435.764 104.786 437.735 109.329C439.707 113.871 440.692 118.8 440.692 124.114C440.692 130.371 439.321 136.157 436.578 141.471C433.921 146.7 430.192 150.9 425.392 154.071C420.592 157.243 415.021 158.829 408.678 158.829C406.192 158.829 403.835 158.614 401.607 158.186C399.378 157.843 397.278 157.329 395.307 156.643V174C395.307 177.343 395.564 179.743 396.078 181.2C396.592 182.657 397.707 183.557 399.421 183.9C401.135 184.329 403.835 184.629 407.521 184.8C407.607 186.171 407.607 187.543 407.521 188.914C404.607 188.914 401.65 188.871 398.65 188.786C395.735 188.7 392.521 188.657 389.007 188.657C385.664 188.657 382.792 188.7 380.392 188.786C377.992 188.871 375.421 188.914 372.678 188.914ZM395.178 146.1C398.864 151.414 403.75 154.071 409.835 154.071C414.121 154.071 417.507 152.871 419.992 150.471C422.564 148.071 424.407 144.943 425.521 141.086C426.721 137.229 427.321 133.157 427.321 128.871C427.321 124.586 426.764 120.386 425.65 116.271C424.535 112.157 422.692 108.771 420.121 106.114C417.635 103.371 414.207 102 409.835 102C404.607 102 399.721 104.529 395.178 109.586V146.1ZM477.335 158.829C471.25 158.829 466.107 157.414 461.907 154.586C457.707 151.757 454.493 147.986 452.264 143.271C450.121 138.471 449.05 133.2 449.05 127.457C449.05 121.543 450.164 116.057 452.393 111C454.707 105.943 458.05 101.871 462.421 98.7857C466.793 95.6143 472.107 94.0286 478.364 94.0286C485.907 94.0286 491.778 96.3 495.978 100.843C500.264 105.3 502.407 111.086 502.407 118.2C502.407 119.057 502.364 119.829 502.278 120.514C502.278 121.114 502.235 121.629 502.15 122.057L461.65 121.671C461.65 122.014 461.65 122.314 461.65 122.571C461.65 130.971 463.578 137.571 467.435 142.371C471.293 147.171 476.693 149.571 483.635 149.571C489.464 149.571 495.207 147.686 500.864 143.914C501.721 144.943 502.364 145.929 502.793 146.871C495.507 154.843 487.021 158.829 477.335 158.829ZM462.035 116.914L488.65 116.4C488.735 116.229 488.778 116.014 488.778 115.757C488.778 115.414 488.778 115.2 488.778 115.114C488.778 110.486 487.75 106.629 485.693 103.543C483.721 100.457 480.764 98.9143 476.821 98.9143C473.135 98.9143 469.921 100.414 467.178 103.414C464.435 106.414 462.721 110.914 462.035 116.914ZM559.644 158.957L557.587 158.057L557.073 149.186C554.073 152.443 550.987 154.886 547.816 156.514C544.73 158.057 541.302 158.829 537.53 158.829C532.216 158.829 527.544 157.414 523.516 154.586C519.573 151.671 516.53 147.9 514.387 143.271C512.244 138.643 511.173 133.629 511.173 128.229C511.173 121.971 512.502 116.271 515.159 111.129C517.902 105.986 521.716 101.871 526.602 98.7857C531.573 95.6143 537.359 94.0286 543.959 94.0286C545.93 94.0286 547.987 94.2 550.13 94.5429C552.273 94.8 554.502 95.2714 556.816 95.9572V79.5C556.816 76.8429 556.559 74.8714 556.044 73.5857C555.53 72.2143 554.502 71.2714 552.959 70.7572C551.502 70.1572 549.273 69.7286 546.273 69.4714C546.016 68.3572 546.016 67.2 546.273 66C549.702 65.5714 553.216 64.9286 556.816 64.0714C560.416 63.1286 564.102 61.8429 567.873 60.2143L570.059 60.9857C569.973 62.8714 569.887 65.0143 569.802 67.4143C569.802 69.8143 569.802 72.4286 569.802 75.2572V139.029C569.802 142.286 569.93 144.729 570.187 146.357C570.445 147.986 571.216 149.143 572.502 149.829C573.787 150.429 575.973 150.986 579.059 151.5C579.316 152.614 579.316 153.771 579.059 154.971C575.63 155.486 572.287 156.043 569.03 156.643C565.773 157.243 562.644 158.014 559.644 158.957ZM556.944 106.886C553.259 101.829 548.416 99.3 542.416 99.3C536.502 99.3 532.044 101.486 529.044 105.857C526.044 110.143 524.544 116.1 524.544 123.729C524.544 128.186 525.144 132.471 526.344 136.586C527.544 140.7 529.516 144.086 532.259 146.743C535.002 149.4 538.644 150.729 543.187 150.729C548.93 150.729 553.516 148.243 556.944 143.271V106.886ZM615.699 157.414C613.299 157.414 610.813 157.371 608.242 157.286C605.67 157.2 602.885 157.157 599.885 157.157C597.142 157.157 594.356 157.2 591.527 157.286C588.785 157.371 586.127 157.414 583.556 157.414C583.299 156.043 583.299 154.714 583.556 153.429C586.47 153.257 588.613 153 589.985 152.657C591.356 152.229 592.256 151.371 592.685 150.086C593.113 148.8 593.327 146.743 593.327 143.914V115.114C593.327 111.771 593.199 109.286 592.942 107.657C592.685 106.029 591.87 104.914 590.499 104.314C589.213 103.629 586.942 103.071 583.685 102.643C583.427 101.443 583.427 100.329 583.685 99.3C587.456 98.6143 591.056 97.7572 594.485 96.7286C597.913 95.7 601.213 94.5857 604.385 93.3857L606.57 94.1572C606.485 96.8143 606.399 99.3 606.313 101.614C606.313 103.929 606.313 106.114 606.313 108.171V142.629C606.313 145.971 606.485 148.371 606.827 149.829C607.256 151.286 608.113 152.229 609.399 152.657C610.77 153 612.87 153.257 615.699 153.429C615.956 154.714 615.956 156.043 615.699 157.414ZM589.985 71.5286C589.985 69.0429 590.842 66.9429 592.556 65.2286C594.356 63.5143 596.499 62.6572 598.985 62.6572C601.385 62.6572 603.442 63.5143 605.156 65.2286C606.956 66.9429 607.856 69 607.856 71.4C607.856 73.6286 606.999 75.6857 605.285 77.5715C603.57 79.3714 601.385 80.2714 598.727 80.2714C596.327 80.2714 594.27 79.4143 592.556 77.7C590.842 75.9857 589.985 73.9286 589.985 71.5286ZM665.837 158.571C660.18 158.571 656.623 155.743 655.165 150.086C649.08 155.914 642.865 158.829 636.523 158.829C632.151 158.829 628.423 157.543 625.337 154.971C622.337 152.314 620.837 148.671 620.837 144.043C620.837 132.729 632.365 125.614 655.423 122.7C655.423 120.643 655.423 118.543 655.423 116.4C655.508 114.257 655.551 111.986 655.551 109.586C655.551 106.586 654.437 104.271 652.208 102.643C650.065 100.929 647.451 100.071 644.365 100.071C642.137 100.071 640.251 100.414 638.708 101.1C638.708 103.071 638.28 105.086 637.423 107.143C636.565 109.2 635.365 110.957 633.823 112.414C632.365 113.786 630.565 114.471 628.423 114.471C626.537 114.471 625.037 113.957 623.923 112.929C622.894 111.814 622.38 110.486 622.38 108.943C622.38 106.886 623.323 104.957 625.208 103.157C627.18 101.271 629.665 99.6857 632.665 98.4C635.665 97.0286 638.794 95.9572 642.051 95.1857C645.308 94.4143 648.223 94.0286 650.794 94.0286C653.965 94.0286 656.88 94.6286 659.537 95.8286C662.28 96.9429 664.465 98.6572 666.094 100.971C667.808 103.2 668.665 105.986 668.665 109.329C668.665 111.386 668.623 114.086 668.537 117.429C668.451 120.686 668.365 124.2 668.28 127.971C668.28 131.657 668.237 135.171 668.151 138.514C668.065 141.857 668.023 144.557 668.023 146.614C668.023 149.357 669.223 150.729 671.623 150.729C673.165 150.729 675.523 150.214 678.694 149.186C679.037 149.614 679.251 150.086 679.337 150.6C679.508 151.114 679.637 151.586 679.723 152.014C677.58 154.329 675.308 156 672.908 157.029C670.594 158.057 668.237 158.571 665.837 158.571ZM655.165 146.614L655.423 127.329C647.537 128.357 642.094 130.029 639.094 132.343C636.18 134.657 634.723 137.614 634.723 141.214C634.723 144.214 635.494 146.529 637.037 148.157C638.665 149.7 640.68 150.471 643.08 150.471C644.623 150.471 646.337 150.129 648.223 149.443C650.194 148.757 652.508 147.814 655.165 146.614Z" fill="currentColor"></path><rect x="715" y="65" width="195" height="105" rx="52.5" fill="currentColor" fill-opacity="0.05"></rect><path d="M767.529 142.875L754.049 107.938H762.552L769.309 127.582C769.705 128.812 770.078 130.032 770.43 131.24C770.781 132.449 771.078 133.559 771.32 134.569H771.616C771.858 133.559 772.144 132.449 772.473 131.24C772.825 130.032 773.198 128.812 773.594 127.582L780.186 107.938H788.689L775.472 142.875H767.529ZM810.856 143.633C806.901 143.633 803.528 142.71 800.737 140.865C797.969 138.997 795.871 136.305 794.442 132.79C793.014 129.252 792.3 124.989 792.3 120.001V118.255C792.3 113.245 793.014 108.982 794.442 105.467C795.871 101.929 797.969 99.2373 800.737 97.3916C803.528 95.5239 806.901 94.5901 810.856 94.5901C814.789 94.5901 818.129 95.5129 820.875 97.3586C823.644 99.2043 825.731 101.907 827.138 105.467C828.566 109.004 829.28 113.267 829.28 118.255V120.001C829.28 124.989 828.577 129.252 827.171 132.79C825.764 136.327 823.677 139.019 820.908 140.865C818.162 142.71 814.811 143.633 810.856 143.633ZM810.889 136.382C813.064 136.382 814.877 135.789 816.327 134.602C817.799 133.416 818.898 131.658 819.623 129.329C820.348 126.978 820.711 124.066 820.711 120.595V117.694C820.711 114.223 820.337 111.311 819.59 108.96C818.865 106.609 817.777 104.84 816.327 103.654C814.877 102.445 813.064 101.841 810.889 101.841C808.714 101.841 806.879 102.434 805.385 103.621C803.912 104.785 802.792 106.554 802.023 108.927C801.276 111.278 800.902 114.201 800.902 117.694V120.595C800.902 124.044 801.287 126.945 802.056 129.296C802.825 131.647 803.945 133.416 805.418 134.602C806.89 135.789 808.714 136.382 810.889 136.382ZM838.988 143.205C838 143.205 837.099 142.985 836.286 142.545C835.495 142.106 834.879 141.491 834.44 140.7C834.001 139.909 833.781 139.019 833.781 138.03C833.781 137.019 834.001 136.118 834.44 135.327C834.879 134.536 835.495 133.921 836.286 133.482C837.099 133.042 838 132.823 838.988 132.823C839.977 132.823 840.867 133.042 841.658 133.482C842.449 133.921 843.064 134.536 843.504 135.327C843.943 136.118 844.163 137.019 844.163 138.03C844.163 139.019 843.943 139.909 843.504 140.7C843.064 141.491 842.449 142.106 841.658 142.545C840.867 142.985 839.977 143.205 838.988 143.205ZM857.365 142.875V104.511L846.39 111.663V103.357L858.453 95.3481H865.802V142.875H857.365Z" fill="currentColor"></path></svg></a></div><div class="mx-auto flex w-full"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 border-input text-primary hover:border-primary/15 border hover:bg-overlay-hover py-2 max-w-full px-3 shadow-none sm:w-80 focus-visible:z-1 mx-auto h-full w-full rounded-full bg-surface-l1" type="button"><div class="flex items-center justify-between sm:w-full gap-4"><div class="flex items-center justify-start gap-2"><span class="inline-flex items-center justify-center p-0 m-0 w-4 h-4 text-muted" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-4 h-4" focusable="false" style="fill:currentColor"><path d="m18.031 16.617 4.283 4.282-1.415 1.415-4.282-4.283A8.96 8.96 0 0 1 11 20c-4.968 0-9-4.032-9-9s4.032-9 9-9 9 4.032 9 9a8.96 8.96 0 0 1-1.969 5.617m-2.006-.742A6.98 6.98 0 0 0 18 11c0-3.867-3.133-7-7-7s-7 3.133-7 7 3.133 7 7 7a6.98 6.98 0 0 0 4.875-1.975z"></path></svg></span><p class="text-sm text-muted hidden sm:block">Search</p></div><span class="hidden sm:block"><div class="bg-foreground/10 text-muted inline-flex items-center rounded-md px-1 py-0.5 text-center font-sans text-xs font-normal tracking-widest rtl:space-x-reverse"><span>âŒ˜</span><span class="text-xs">K</span></div></span></div></button></div><div class="flex items-center gap-2 justify-self-end"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover px-4 py-2 w-9 h-9 flex-shrink-0" type="button" id="radix-_R_7apfiumdb_" aria-haspopup="menu" aria-expanded="false" data-state="closed"><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M12 18a6 6 0 1 1 0-12 6 6 0 0 1 0 12m0-2a4 4 0 1 0 0-8 4 4 0 0 0 0 8M11 1h2v3h-2zm0 19h2v3h-2zM3.515 4.929l1.414-1.414L7.05 5.636 5.636 7.05zM16.95 18.364l1.414-1.414 2.121 2.121-1.414 1.414zm2.121-14.85 1.414 1.415-2.121 2.121-1.414-1.414zM5.636 16.95l1.414 1.414-2.121 2.121-1.414-1.414zM23 11v2h-3v-2zM4 11v2H1v-2z"></path></svg></span><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 absolute rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M10 7a7 7 0 0 0 12 4.9v.1c0 5.523-4.477 10-10 10S2 17.523 2 12 6.477 2 12 2h.1A6.98 6.98 0 0 0 10 7m-6 5a8 8 0 0 0 15.062 3.762A9 9 0 0 1 8.238 4.938 8 8 0 0 0 4 12"></path></svg></span><span class="sr-only">Toggle theme</span></button></div></div><div class="flex h-full items-center md:hidden justify-between max-w-full py-6 px-4 w-full mx-auto pt-8"><div class="flex items-center"><div class="-ml-2"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover h-9 w-9" type="button" aria-label="Toggle table of contents"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-list h-6 w-6"><path d="M3 12h.01"></path><path d="M3 18h.01"></path><path d="M3 6h.01"></path><path d="M8 12h13"></path><path d="M8 18h13"></path><path d="M8 6h13"></path></svg></button></div><a class="cursor-pointer" href="/"><svg width="160" height="auto" viewBox="0 0 955 225" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M99.6937 159.214C90.008 159.214 81.5652 157.414 74.3652 153.814C67.1652 150.214 61.5509 144.986 57.5223 138.129C53.5794 131.271 51.608 123.043 51.608 113.443C51.608 103.843 53.5794 95.4857 57.5223 88.3714C61.5509 81.2572 67.1652 75.7286 74.3652 71.7857C81.6509 67.8429 90.1794 65.8714 99.9509 65.8714C103.208 65.8714 106.679 66.1286 110.365 66.6429C114.051 67.0714 117.222 67.6714 119.879 68.4429C121.508 68.8714 123.008 69.2572 124.379 69.6C125.751 69.9429 127.122 70.1143 128.494 70.1143C129.522 70.1143 130.551 69.9857 131.579 69.7286C131.751 73.5 131.922 77.4 132.094 81.4286C132.265 85.4572 132.522 89.6572 132.865 94.0286C131.065 94.2857 129.565 94.3714 128.365 94.2857C126.651 86.4 123.522 80.5714 118.979 76.8C114.437 72.9429 108.394 71.0143 100.851 71.0143C94.8509 71.0143 89.708 72.1286 85.4223 74.3572C81.2223 76.5 77.7937 79.4572 75.1366 83.2286C72.5652 87 70.6794 91.3714 69.4794 96.3429C68.2794 101.229 67.6794 106.457 67.6794 112.029C67.6794 120.171 68.9223 127.371 71.408 133.629C73.8937 139.886 77.6652 144.814 82.7223 148.414C87.8652 151.929 94.2937 153.686 102.008 153.686C104.408 153.686 107.065 153.471 109.979 153.043C112.894 152.529 115.679 151.757 118.337 150.729V134.529C118.337 131.871 118.208 129.814 117.951 128.357C117.779 126.814 117.222 125.7 116.279 125.014C115.422 124.329 114.008 123.857 112.037 123.6C110.151 123.257 107.537 122.957 104.194 122.7C103.937 121.329 103.937 119.957 104.194 118.586C105.994 118.586 108.179 118.629 110.751 118.714C113.322 118.714 115.894 118.757 118.465 118.843C121.122 118.843 123.308 118.843 125.022 118.843C127.679 118.843 130.722 118.8 134.151 118.714C137.665 118.629 140.665 118.586 143.151 118.586C143.322 119.871 143.322 121.2 143.151 122.571C139.637 123 137.108 123.429 135.565 123.857C134.022 124.286 133.079 125.143 132.737 126.429C132.394 127.714 132.222 129.9 132.222 132.986V137.1C132.222 141.129 132.308 144.514 132.479 147.257C132.737 150 132.951 151.971 133.122 153.171C121.208 157.2 110.065 159.214 99.6937 159.214ZM148.19 157.414C147.933 156.043 147.933 154.714 148.19 153.429C151.105 153.257 153.248 153 154.619 152.657C155.99 152.229 156.89 151.371 157.319 150.086C157.748 148.8 157.962 146.743 157.962 143.914V115.114C157.962 111.771 157.79 109.286 157.448 107.657C157.19 106.029 156.376 104.914 155.005 104.314C153.719 103.629 151.49 103.071 148.319 102.643C148.062 101.443 148.062 100.329 148.319 99.3C151.748 98.6143 155.09 97.8429 158.348 96.9857C161.605 96.0429 165.033 94.8429 168.633 93.3857L170.819 94.1572V105.471C176.819 97.8429 182.948 94.0286 189.205 94.0286C192.205 94.0286 194.433 94.8429 195.89 96.4714C197.348 98.0143 198.076 99.7714 198.076 101.743C198.076 104.057 197.305 105.857 195.762 107.143C194.219 108.343 192.462 108.943 190.49 108.943C188.862 108.943 187.233 108.514 185.605 107.657C184.062 106.8 182.905 105.471 182.133 103.671C179.219 103.671 176.605 104.829 174.29 107.143C172.062 109.371 170.948 111.986 170.948 114.986V142.629C170.948 145.971 171.119 148.371 171.462 149.829C171.89 151.286 172.919 152.229 174.548 152.657C176.262 153 179.005 153.257 182.776 153.429C182.948 154.629 182.948 155.957 182.776 157.414C179.862 157.414 176.862 157.371 173.776 157.286C170.69 157.2 167.519 157.157 164.262 157.157C161.09 157.157 158.262 157.2 155.776 157.286C153.376 157.371 150.848 157.414 148.19 157.414ZM229.285 158.829C223.028 158.829 217.542 157.5 212.828 154.843C208.199 152.1 204.599 148.371 202.028 143.657C199.457 138.857 198.171 133.371 198.171 127.2C198.171 120.514 199.499 114.686 202.157 109.714C204.899 104.743 208.714 100.886 213.599 98.1429C218.485 95.4 224.099 94.0286 230.442 94.0286C236.699 94.0286 242.142 95.4 246.771 98.1429C251.399 100.886 254.999 104.657 257.571 109.457C260.142 114.257 261.428 119.7 261.428 125.786C261.428 132.043 260.057 137.7 257.314 142.757C254.657 147.729 250.928 151.671 246.128 154.586C241.328 157.414 235.714 158.829 229.285 158.829ZM212.699 125.657C212.699 134.4 214.114 141.343 216.942 146.486C219.857 151.543 224.185 154.071 229.928 154.071C235.414 154.071 239.614 151.671 242.528 146.871C245.442 141.986 246.899 135.471 246.899 127.329C246.899 118.671 245.442 111.771 242.528 106.629C239.614 101.486 235.371 98.9143 229.799 98.9143C224.314 98.9143 220.071 101.271 217.071 105.986C214.157 110.7 212.699 117.257 212.699 125.657ZM267.394 157.414C267.308 157.071 267.265 156.729 267.265 156.386C267.265 156.043 267.265 155.7 267.265 155.357C267.265 155.014 267.265 154.714 267.265 154.457C267.265 154.114 267.308 153.771 267.394 153.429C270.308 153.257 272.451 153 273.822 152.657C275.194 152.229 276.094 151.371 276.522 150.086C276.951 148.8 277.165 146.743 277.165 143.914V79.5C277.165 76.8429 276.908 74.8714 276.394 73.5857C275.965 72.2143 274.979 71.2714 273.437 70.7572C271.979 70.1572 269.751 69.7286 266.751 69.4714C266.665 69.1286 266.622 68.8286 266.622 68.5714C266.622 68.3143 266.622 68.0572 266.622 67.8C266.622 67.4572 266.622 67.1572 266.622 66.9C266.622 66.6429 266.665 66.3429 266.751 66C270.179 65.5714 273.694 64.9286 277.294 64.0714C280.894 63.1286 284.579 61.8429 288.351 60.2143L290.537 60.9857C290.451 62.8714 290.365 65.0143 290.279 67.4143C290.279 69.8143 290.279 72.4286 290.279 75.2572V122.957C291.308 122.957 292.165 122.786 292.851 122.443C293.537 122.1 294.094 121.757 294.522 121.414C294.694 121.243 295.037 120.943 295.551 120.514C296.065 120 296.965 119.1 298.251 117.814C299.537 116.529 301.379 114.6 303.779 112.029C306.008 109.543 307.765 107.614 309.051 106.243C310.422 104.786 311.108 103.586 311.108 102.643C311.108 101.957 310.508 101.4 309.308 100.971C308.194 100.457 306.651 100.157 304.679 100.071C304.594 99.7286 304.551 99.3857 304.551 99.0429C304.551 98.7 304.551 98.3572 304.551 98.0143C304.551 97.6714 304.551 97.3286 304.551 96.9857C304.551 96.6429 304.594 96.3 304.679 95.9572C306.394 95.9572 308.537 96 311.108 96.0857C313.765 96.1714 316.122 96.2143 318.179 96.2143C319.208 96.2143 320.665 96.2143 322.551 96.2143C324.522 96.1286 326.494 96.0857 328.465 96.0857C330.437 96.0857 331.894 96.0857 332.837 96.0857C332.922 96.4286 332.965 96.7714 332.965 97.1143C333.051 97.4572 333.094 97.8 333.094 98.1429C333.094 98.4857 333.051 98.8286 332.965 99.1714C332.965 99.4286 332.922 99.7286 332.837 100.071C328.379 100.157 324.608 101.271 321.522 103.414C318.437 105.471 315.479 107.914 312.651 110.743L303.394 120L321.137 143.4C323.022 145.886 324.565 147.857 325.765 149.314C327.051 150.686 328.422 151.671 329.879 152.271C331.337 152.871 333.351 153.257 335.922 153.429C336.094 154.629 336.094 155.957 335.922 157.414C334.808 157.414 333.137 157.371 330.908 157.286C328.765 157.2 325.379 157.157 320.751 157.157C320.065 157.157 319.037 157.157 317.665 157.157C316.294 157.157 315.008 157.243 313.808 157.414C313.808 156.471 313.294 155.186 312.265 153.557C311.237 151.843 310.422 150.6 309.822 149.829C309.565 149.4 308.922 148.5 307.894 147.129C306.865 145.671 305.622 144 304.165 142.114C302.794 140.143 301.379 138.171 299.922 136.2C298.465 134.143 297.137 132.343 295.937 130.8C294.994 129.514 294.094 128.529 293.237 127.843C292.465 127.071 291.479 126.686 290.279 126.686V142.629C290.279 145.971 290.408 148.371 290.665 149.829C291.008 151.286 291.737 152.229 292.851 152.657C294.051 153 295.851 153.257 298.251 153.429C298.422 154.714 298.422 156.043 298.251 157.414C296.022 157.414 293.665 157.371 291.179 157.286C288.779 157.2 286.165 157.157 283.337 157.157C280.594 157.157 277.894 157.2 275.237 157.286C272.579 157.371 269.965 157.414 267.394 157.414ZM369.34 157.414C366.94 157.414 364.454 157.371 361.883 157.286C359.311 157.2 356.526 157.157 353.526 157.157C350.783 157.157 347.997 157.2 345.169 157.286C342.426 157.371 339.769 157.414 337.197 157.414C336.94 156.043 336.94 154.714 337.197 153.429C340.111 153.257 342.254 153 343.626 152.657C344.997 152.229 345.897 151.371 346.326 150.086C346.754 148.8 346.969 146.743 346.969 143.914V115.114C346.969 111.771 346.84 109.286 346.583 107.657C346.326 106.029 345.511 104.914 344.14 104.314C342.854 103.629 340.583 103.071 337.326 102.643C337.069 101.443 337.069 100.329 337.326 99.3C341.097 98.6143 344.697 97.7572 348.126 96.7286C351.554 95.7 354.854 94.5857 358.026 93.3857L360.211 94.1572C360.126 96.8143 360.04 99.3 359.954 101.614C359.954 103.929 359.954 106.114 359.954 108.171V142.629C359.954 145.971 360.126 148.371 360.469 149.829C360.897 151.286 361.754 152.229 363.04 152.657C364.411 153 366.511 153.257 369.34 153.429C369.597 154.714 369.597 156.043 369.34 157.414ZM343.626 71.5286C343.626 69.0429 344.483 66.9429 346.197 65.2286C347.997 63.5143 350.14 62.6572 352.626 62.6572C355.026 62.6572 357.083 63.5143 358.797 65.2286C360.597 66.9429 361.497 69 361.497 71.4C361.497 73.6286 360.64 75.6857 358.926 77.5715C357.211 79.3714 355.026 80.2714 352.369 80.2714C349.969 80.2714 347.911 79.4143 346.197 77.7C344.483 75.9857 343.626 73.9286 343.626 71.5286ZM372.678 188.914C372.592 187.543 372.592 186.214 372.678 184.929C375.678 184.757 377.864 184.457 379.235 184.029C380.607 183.6 381.464 182.743 381.807 181.457C382.235 180.257 382.45 178.286 382.45 175.543V115.114C382.45 111.771 382.278 109.286 381.935 107.657C381.678 106.029 380.864 104.914 379.492 104.314C378.207 103.629 375.978 103.071 372.807 102.643C372.635 101.443 372.635 100.329 372.807 99.3C376.321 98.6143 379.75 97.8 383.092 96.8572C386.435 95.9143 389.907 94.7572 393.507 93.3857L395.307 94.2857C395.221 96.4286 395.178 98.2714 395.178 99.8143C395.178 101.271 395.178 102.686 395.178 104.057C398.521 100.543 401.821 98.0143 405.078 96.4714C408.335 94.8429 411.807 94.0286 415.492 94.0286C420.892 94.0286 425.435 95.4429 429.121 98.2714C432.892 101.1 435.764 104.786 437.735 109.329C439.707 113.871 440.692 118.8 440.692 124.114C440.692 130.371 439.321 136.157 436.578 141.471C433.921 146.7 430.192 150.9 425.392 154.071C420.592 157.243 415.021 158.829 408.678 158.829C406.192 158.829 403.835 158.614 401.607 158.186C399.378 157.843 397.278 157.329 395.307 156.643V174C395.307 177.343 395.564 179.743 396.078 181.2C396.592 182.657 397.707 183.557 399.421 183.9C401.135 184.329 403.835 184.629 407.521 184.8C407.607 186.171 407.607 187.543 407.521 188.914C404.607 188.914 401.65 188.871 398.65 188.786C395.735 188.7 392.521 188.657 389.007 188.657C385.664 188.657 382.792 188.7 380.392 188.786C377.992 188.871 375.421 188.914 372.678 188.914ZM395.178 146.1C398.864 151.414 403.75 154.071 409.835 154.071C414.121 154.071 417.507 152.871 419.992 150.471C422.564 148.071 424.407 144.943 425.521 141.086C426.721 137.229 427.321 133.157 427.321 128.871C427.321 124.586 426.764 120.386 425.65 116.271C424.535 112.157 422.692 108.771 420.121 106.114C417.635 103.371 414.207 102 409.835 102C404.607 102 399.721 104.529 395.178 109.586V146.1ZM477.335 158.829C471.25 158.829 466.107 157.414 461.907 154.586C457.707 151.757 454.493 147.986 452.264 143.271C450.121 138.471 449.05 133.2 449.05 127.457C449.05 121.543 450.164 116.057 452.393 111C454.707 105.943 458.05 101.871 462.421 98.7857C466.793 95.6143 472.107 94.0286 478.364 94.0286C485.907 94.0286 491.778 96.3 495.978 100.843C500.264 105.3 502.407 111.086 502.407 118.2C502.407 119.057 502.364 119.829 502.278 120.514C502.278 121.114 502.235 121.629 502.15 122.057L461.65 121.671C461.65 122.014 461.65 122.314 461.65 122.571C461.65 130.971 463.578 137.571 467.435 142.371C471.293 147.171 476.693 149.571 483.635 149.571C489.464 149.571 495.207 147.686 500.864 143.914C501.721 144.943 502.364 145.929 502.793 146.871C495.507 154.843 487.021 158.829 477.335 158.829ZM462.035 116.914L488.65 116.4C488.735 116.229 488.778 116.014 488.778 115.757C488.778 115.414 488.778 115.2 488.778 115.114C488.778 110.486 487.75 106.629 485.693 103.543C483.721 100.457 480.764 98.9143 476.821 98.9143C473.135 98.9143 469.921 100.414 467.178 103.414C464.435 106.414 462.721 110.914 462.035 116.914ZM559.644 158.957L557.587 158.057L557.073 149.186C554.073 152.443 550.987 154.886 547.816 156.514C544.73 158.057 541.302 158.829 537.53 158.829C532.216 158.829 527.544 157.414 523.516 154.586C519.573 151.671 516.53 147.9 514.387 143.271C512.244 138.643 511.173 133.629 511.173 128.229C511.173 121.971 512.502 116.271 515.159 111.129C517.902 105.986 521.716 101.871 526.602 98.7857C531.573 95.6143 537.359 94.0286 543.959 94.0286C545.93 94.0286 547.987 94.2 550.13 94.5429C552.273 94.8 554.502 95.2714 556.816 95.9572V79.5C556.816 76.8429 556.559 74.8714 556.044 73.5857C555.53 72.2143 554.502 71.2714 552.959 70.7572C551.502 70.1572 549.273 69.7286 546.273 69.4714C546.016 68.3572 546.016 67.2 546.273 66C549.702 65.5714 553.216 64.9286 556.816 64.0714C560.416 63.1286 564.102 61.8429 567.873 60.2143L570.059 60.9857C569.973 62.8714 569.887 65.0143 569.802 67.4143C569.802 69.8143 569.802 72.4286 569.802 75.2572V139.029C569.802 142.286 569.93 144.729 570.187 146.357C570.445 147.986 571.216 149.143 572.502 149.829C573.787 150.429 575.973 150.986 579.059 151.5C579.316 152.614 579.316 153.771 579.059 154.971C575.63 155.486 572.287 156.043 569.03 156.643C565.773 157.243 562.644 158.014 559.644 158.957ZM556.944 106.886C553.259 101.829 548.416 99.3 542.416 99.3C536.502 99.3 532.044 101.486 529.044 105.857C526.044 110.143 524.544 116.1 524.544 123.729C524.544 128.186 525.144 132.471 526.344 136.586C527.544 140.7 529.516 144.086 532.259 146.743C535.002 149.4 538.644 150.729 543.187 150.729C548.93 150.729 553.516 148.243 556.944 143.271V106.886ZM615.699 157.414C613.299 157.414 610.813 157.371 608.242 157.286C605.67 157.2 602.885 157.157 599.885 157.157C597.142 157.157 594.356 157.2 591.527 157.286C588.785 157.371 586.127 157.414 583.556 157.414C583.299 156.043 583.299 154.714 583.556 153.429C586.47 153.257 588.613 153 589.985 152.657C591.356 152.229 592.256 151.371 592.685 150.086C593.113 148.8 593.327 146.743 593.327 143.914V115.114C593.327 111.771 593.199 109.286 592.942 107.657C592.685 106.029 591.87 104.914 590.499 104.314C589.213 103.629 586.942 103.071 583.685 102.643C583.427 101.443 583.427 100.329 583.685 99.3C587.456 98.6143 591.056 97.7572 594.485 96.7286C597.913 95.7 601.213 94.5857 604.385 93.3857L606.57 94.1572C606.485 96.8143 606.399 99.3 606.313 101.614C606.313 103.929 606.313 106.114 606.313 108.171V142.629C606.313 145.971 606.485 148.371 606.827 149.829C607.256 151.286 608.113 152.229 609.399 152.657C610.77 153 612.87 153.257 615.699 153.429C615.956 154.714 615.956 156.043 615.699 157.414ZM589.985 71.5286C589.985 69.0429 590.842 66.9429 592.556 65.2286C594.356 63.5143 596.499 62.6572 598.985 62.6572C601.385 62.6572 603.442 63.5143 605.156 65.2286C606.956 66.9429 607.856 69 607.856 71.4C607.856 73.6286 606.999 75.6857 605.285 77.5715C603.57 79.3714 601.385 80.2714 598.727 80.2714C596.327 80.2714 594.27 79.4143 592.556 77.7C590.842 75.9857 589.985 73.9286 589.985 71.5286ZM665.837 158.571C660.18 158.571 656.623 155.743 655.165 150.086C649.08 155.914 642.865 158.829 636.523 158.829C632.151 158.829 628.423 157.543 625.337 154.971C622.337 152.314 620.837 148.671 620.837 144.043C620.837 132.729 632.365 125.614 655.423 122.7C655.423 120.643 655.423 118.543 655.423 116.4C655.508 114.257 655.551 111.986 655.551 109.586C655.551 106.586 654.437 104.271 652.208 102.643C650.065 100.929 647.451 100.071 644.365 100.071C642.137 100.071 640.251 100.414 638.708 101.1C638.708 103.071 638.28 105.086 637.423 107.143C636.565 109.2 635.365 110.957 633.823 112.414C632.365 113.786 630.565 114.471 628.423 114.471C626.537 114.471 625.037 113.957 623.923 112.929C622.894 111.814 622.38 110.486 622.38 108.943C622.38 106.886 623.323 104.957 625.208 103.157C627.18 101.271 629.665 99.6857 632.665 98.4C635.665 97.0286 638.794 95.9572 642.051 95.1857C645.308 94.4143 648.223 94.0286 650.794 94.0286C653.965 94.0286 656.88 94.6286 659.537 95.8286C662.28 96.9429 664.465 98.6572 666.094 100.971C667.808 103.2 668.665 105.986 668.665 109.329C668.665 111.386 668.623 114.086 668.537 117.429C668.451 120.686 668.365 124.2 668.28 127.971C668.28 131.657 668.237 135.171 668.151 138.514C668.065 141.857 668.023 144.557 668.023 146.614C668.023 149.357 669.223 150.729 671.623 150.729C673.165 150.729 675.523 150.214 678.694 149.186C679.037 149.614 679.251 150.086 679.337 150.6C679.508 151.114 679.637 151.586 679.723 152.014C677.58 154.329 675.308 156 672.908 157.029C670.594 158.057 668.237 158.571 665.837 158.571ZM655.165 146.614L655.423 127.329C647.537 128.357 642.094 130.029 639.094 132.343C636.18 134.657 634.723 137.614 634.723 141.214C634.723 144.214 635.494 146.529 637.037 148.157C638.665 149.7 640.68 150.471 643.08 150.471C644.623 150.471 646.337 150.129 648.223 149.443C650.194 148.757 652.508 147.814 655.165 146.614Z" fill="currentColor"></path><rect x="715" y="65" width="195" height="105" rx="52.5" fill="currentColor" fill-opacity="0.05"></rect><path d="M767.529 142.875L754.049 107.938H762.552L769.309 127.582C769.705 128.812 770.078 130.032 770.43 131.24C770.781 132.449 771.078 133.559 771.32 134.569H771.616C771.858 133.559 772.144 132.449 772.473 131.24C772.825 130.032 773.198 128.812 773.594 127.582L780.186 107.938H788.689L775.472 142.875H767.529ZM810.856 143.633C806.901 143.633 803.528 142.71 800.737 140.865C797.969 138.997 795.871 136.305 794.442 132.79C793.014 129.252 792.3 124.989 792.3 120.001V118.255C792.3 113.245 793.014 108.982 794.442 105.467C795.871 101.929 797.969 99.2373 800.737 97.3916C803.528 95.5239 806.901 94.5901 810.856 94.5901C814.789 94.5901 818.129 95.5129 820.875 97.3586C823.644 99.2043 825.731 101.907 827.138 105.467C828.566 109.004 829.28 113.267 829.28 118.255V120.001C829.28 124.989 828.577 129.252 827.171 132.79C825.764 136.327 823.677 139.019 820.908 140.865C818.162 142.71 814.811 143.633 810.856 143.633ZM810.889 136.382C813.064 136.382 814.877 135.789 816.327 134.602C817.799 133.416 818.898 131.658 819.623 129.329C820.348 126.978 820.711 124.066 820.711 120.595V117.694C820.711 114.223 820.337 111.311 819.59 108.96C818.865 106.609 817.777 104.84 816.327 103.654C814.877 102.445 813.064 101.841 810.889 101.841C808.714 101.841 806.879 102.434 805.385 103.621C803.912 104.785 802.792 106.554 802.023 108.927C801.276 111.278 800.902 114.201 800.902 117.694V120.595C800.902 124.044 801.287 126.945 802.056 129.296C802.825 131.647 803.945 133.416 805.418 134.602C806.89 135.789 808.714 136.382 810.889 136.382ZM838.988 143.205C838 143.205 837.099 142.985 836.286 142.545C835.495 142.106 834.879 141.491 834.44 140.7C834.001 139.909 833.781 139.019 833.781 138.03C833.781 137.019 834.001 136.118 834.44 135.327C834.879 134.536 835.495 133.921 836.286 133.482C837.099 133.042 838 132.823 838.988 132.823C839.977 132.823 840.867 133.042 841.658 133.482C842.449 133.921 843.064 134.536 843.504 135.327C843.943 136.118 844.163 137.019 844.163 138.03C844.163 139.019 843.943 139.909 843.504 140.7C843.064 141.491 842.449 142.106 841.658 142.545C840.867 142.985 839.977 143.205 838.988 143.205ZM857.365 142.875V104.511L846.39 111.663V103.357L858.453 95.3481H865.802V142.875H857.365Z" fill="currentColor"></path></svg></a></div><div class="flex items-center gap-1"><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover px-4 py-2 w-9 h-9 flex-shrink-0 [&amp;_svg]:!w-5" type="button" id="radix-_R_aipfiumdb_" aria-haspopup="menu" aria-expanded="false" data-state="closed"><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M12 18a6 6 0 1 1 0-12 6 6 0 0 1 0 12m0-2a4 4 0 1 0 0-8 4 4 0 0 0 0 8M11 1h2v3h-2zm0 19h2v3h-2zM3.515 4.929l1.414-1.414L7.05 5.636 5.636 7.05zM16.95 18.364l1.414-1.414 2.121 2.121-1.414 1.414zm2.121-14.85 1.414 1.415-2.121 2.121-1.414-1.414zM5.636 16.95l1.414 1.414-2.121 2.121-1.414-1.414zM23 11v2h-3v-2zM4 11v2H1v-2z"></path></svg></span><span class="inline-flex items-center justify-center p-0 m-0 w-6 h-6 absolute rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-6 h-6" focusable="false" style="fill:currentColor"><path d="M10 7a7 7 0 0 0 12 4.9v.1c0 5.523-4.477 10-10 10S2 17.523 2 12 6.477 2 12 2h.1A6.98 6.98 0 0 0 10 7m-6 5a8 8 0 0 0 15.062 3.762A9 9 0 0 1 8.238 4.938 8 8 0 0 0 4 12"></path></svg></span><span class="sr-only">Toggle theme</span></button><button class="focus-visible:ring-ring inline-flex items-center justify-center gap-x-2 whitespace-nowrap rounded-full text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary hover:bg-overlay-hover h-9 w-9" type="button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-search h-5 w-5"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button></div></div></header><div class="bg-surface-base fixed right-0 top-16 z-50 h-[calc(100vh-4rem)] w-full transform border-l transition-transform duration-300 ease-in-out sm:w-1/2 md:hidden translate-x-full"><div class="flex flex-col gap-4 p-4"><div class="flex flex-row gap-2"><button class="focus-visible:ring-ring inline-flex items-center gap-x-2 whitespace-nowrap text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 border-input text-primary hover:border-primary/15 border hover:bg-overlay-hover py-2 max-w-full shadow-none sm:w-80 h-10 w-full justify-start rounded-full bg-surface-l1 px-4" type="button"><div class="flex items-center justify-between sm:w-full gap-4"><div class="flex items-center justify-start gap-2"><span class="inline-flex items-center justify-center p-0 m-0 w-4 h-4 text-muted" data-namespace="@xai/icons" data-slot="icon"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true" class="w-4 h-4" focusable="false" style="fill:currentColor"><path d="m18.031 16.617 4.283 4.282-1.415 1.415-4.282-4.283A8.96 8.96 0 0 1 11 20c-4.968 0-9-4.032-9-9s4.032-9 9-9 9 4.032 9 9a8.96 8.96 0 0 1-1.969 5.617m-2.006-.742A6.98 6.98 0 0 0 18 11c0-3.867-3.133-7-7-7s-7 3.133-7 7 3.133 7 7 7a6.98 6.98 0 0 0 4.875-1.975z"></path></svg></span><p class="text-sm text-muted hidden sm:block">Search</p></div><span class="hidden sm:block"><div class="bg-foreground/10 text-muted inline-flex items-center rounded-md px-1 py-0.5 text-center font-sans text-xs font-normal tracking-widest rtl:space-x-reverse"><span>âŒ˜</span><span class="text-xs">K</span></div></span></div></button></div></div></div><div><div class="min-[1350px]:grid min-[1350px]:grid-cols-[1fr_3fr_1fr]"><nav class="bg-surface-base hidden h-[calc(100vh-4rem)] overflow-y-auto px-6 pb-32 min-[1350px]:sticky min-[1350px]:top-16 min-[1350px]:block scrollbar-none [-ms-overflow-style:none] [scrollbar-width:none] [&amp;::-webkit-scrollbar]:hidden [overscroll-behavior:contain] pt-8"><ul class="space-y-2 text-sm"><li style="padding-left:0rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#geoffrey-hinton" class="transition-opacity hover:opacity-100 opacity-50">Geoffrey Hinton</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#early-life-and-education" class="transition-opacity hover:opacity-100 opacity-50">Early Life and Education</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#family-background-and-early-influences" class="transition-opacity hover:opacity-100 opacity-50">Family Background and Early Influences</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#academic-training" class="transition-opacity hover:opacity-100 opacity-50">Academic Training</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#professional-career" class="transition-opacity hover:opacity-100 opacity-50">Professional Career</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#early-academic-positions" class="transition-opacity hover:opacity-100 opacity-50">Early Academic Positions</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#career-at-the-university-of-toronto" class="transition-opacity hover:opacity-100 opacity-50">Career at the University of Toronto</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#industry-roles-and-google-involvement" class="transition-opacity hover:opacity-100 opacity-50">Industry Roles and Google Involvement</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#key-research-contributions" class="transition-opacity hover:opacity-100 opacity-50">Key Research Contributions</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#boltzmann-machines-and-unsupervised-learning" class="transition-opacity hover:opacity-100 opacity-50">Boltzmann Machines and Unsupervised Learning</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#backpropagation-algorithm" class="transition-opacity hover:opacity-100 opacity-50">Backpropagation Algorithm</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#deep-belief-networks-and-the-revival-of-deep-learning" class="transition-opacity hover:opacity-100 opacity-50">Deep Belief Networks and the Revival of Deep Learning</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#applications-in-speech-and-image-recognition" class="transition-opacity hover:opacity-100 opacity-50">Applications in Speech and Image Recognition</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#awards-and-recognition" class="transition-opacity hover:opacity-100 opacity-50">Awards and Recognition</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#major-honors-and-prizes" class="transition-opacity hover:opacity-100 opacity-50">Major Honors and Prizes</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#nobel-prize-in-physics-2024" class="transition-opacity hover:opacity-100 opacity-50">Nobel Prize in Physics (2024)</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#public-positions-on-ai" class="transition-opacity hover:opacity-100 opacity-50">Public Positions on AI</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#evolution-of-views-on-ai-capabilities" class="transition-opacity hover:opacity-100 opacity-50">Evolution of Views on AI Capabilities</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#concerns-over-superintelligence-and-existential-risks" class="transition-opacity hover:opacity-100 opacity-50">Concerns Over Superintelligence and Existential Risks</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#economic-and-misuse-risks" class="transition-opacity hover:opacity-100 opacity-50">Economic and Misuse Risks</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#criticisms-and-responses" class="transition-opacity hover:opacity-100 opacity-50">Criticisms and Responses</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#skepticism-toward-ai-doomerism" class="transition-opacity hover:opacity-100 opacity-50">Skepticism Toward AI Doomerism</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#controversies-over-past-predictions-and-ethical-stance" class="transition-opacity hover:opacity-100 opacity-50">Controversies Over Past Predictions and Ethical Stance</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#personal-life" class="transition-opacity hover:opacity-100 opacity-50">Personal Life</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#family-and-heritage" class="transition-opacity hover:opacity-100 opacity-50">Family and Heritage</a></li><li style="padding-left:1.5rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#later-years-and-retirement" class="transition-opacity hover:opacity-100 opacity-50">Later Years and Retirement</a></li><li style="padding-left:0.75rem" class="flex items-start gap-2"><div class="bg-foreground mt-[0.5rem] h-1 w-1 flex-shrink-0 transition-opacity opacity-0"></div><a href="#references" class="transition-opacity hover:opacity-100 opacity-50">References</a></li></ul></nav><div class="relative top-16 pb-32 pt-8 px-4 md:px-8"><div class="mx-auto max-w-[850px]"><button data-state="closed" type="button" class="flex items-center"><div class="text-fg-tertiary mb-2 flex cursor-help items-center gap-2 text-sm"><span class="inline-flex items-center justify-center p-0 m-0" data-namespace="@xai/icons" data-slot="icon" style="height:16px;width:16px"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 33 33" aria-hidden="true" class="" focusable="false" style="fill:currentColor;height:16px;width:16px"><path fill="currentColor" d="m13.237 21.04 11.082-8.19c.543-.4 1.32-.244 1.578.38 1.363 3.288.754 7.241-1.957 9.955-2.71 2.714-6.482 3.31-9.93 1.954l-3.765 1.745c5.401 3.697 11.96 2.782 16.059-1.324 3.251-3.255 4.258-7.692 3.317-11.693l.008.009c-1.365-5.878.336-8.227 3.82-13.031q.123-.17.247-.345l-4.585 4.59v-.014L13.234 21.044M10.95 23.031c-3.877-3.707-3.208-9.446.1-12.755 2.446-2.449 6.454-3.448 9.952-1.979L24.76 6.56c-.677-.49-1.545-1.017-2.54-1.387A12.465 12.465 0 0 0 8.675 7.901c-3.519 3.523-4.625 8.94-2.725 13.561 1.42 3.454-.907 5.898-3.251 8.364-.83.874-1.664 1.749-2.335 2.674l10.583-9.466"></path></svg></span><span>Fact-checked by Grok<!-- --> <!-- -->4 days ago</span></div></button><article class="text-[16px]"><h1 id="geoffrey-hinton" class="group relative mb-2 scroll-mt-24 font-serif text-[2.125em] font-semibold tracking-[-1px] [&amp;:not(:first-child)]:mt-14" node="[object Object]">Geoffrey Hinton<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h1>
<span class="mb-4 block break-words text-[1em] leading-7">
Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_60qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_80qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup>
Hinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[2]</sup>
As University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the Boltzmann machine, a neural network capable of autonomously identifying patterns in data through unsupervised learning.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_g0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_i0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup>
In 2024, Hinton shared the Nobel Prize in Physics with John Hopfield for foundational discoveries and inventions that enable machine learning with artificial neural networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_m0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup>
His work laid the groundwork for modern AI systems by demonstrating how networks could learn hierarchical representations of data, influencing breakthroughs in image recognition and natural language processing.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_q0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_s0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup>
After a decade at Google, where he contributed to advancing deep learning technologies, Hinton resigned in 2023 to discuss potential existential risks from superintelligent AI without corporate constraints.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_100qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[4]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_120qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[5]</sup></span>
<h2 id="early-life-and-education" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Early Life and Education<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="family-background-and-early-influences" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Family Background and Early Influences<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Geoffrey Everest Hinton was born on December 6, 1947, in Wimbledon, London, England, to Howard Everest Hinton, an eminent entomologist and professor at the University of Bristol, and Margaret Clark, a schoolteacher.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_42abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[6]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_62abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[7]</sup> Howard Hinton, a Fellow of the Royal Society, specialized in insect biology and maintained a politically radical outlook shaped by his upbringing in Mexico during the Mexican Revolution and his Berkeley education, which included Stalinist leanings that influenced family dynamics, such as prohibiting Geoffrey from pursuing biology due to opposition to genetic determinism.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a2abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[7]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c2abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton descends from a lineage of intellectuals, with his great-great-grandfather George Boole (1815â€“1864), the mathematician who developed Boolean algebra foundational to modern computing, married to Mary Everest Boole, niece of George Everest, the surveyor after whom Mount Everest is namedâ€”reflected in Hinton&#x27;s middle name.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_42qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_62qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[7]</sup> Other notable forebears include great-grandfather Charles Howard Hinton (1853â€“1907), a mathematician known for work on higher-dimensional geometry and science fiction, and great-great-grandfather James Hinton (1822â€“1875), a surgeon and author.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a2qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup> Extended relatives encompass great-uncle Sebastian Hinton, inventor of the jungle gym, and cousin Joan Hinton (1921â€“2010), a nuclear physicist who contributed to the Manhattan Project before relocating to China as a dairy farmer.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_e2qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[7]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_g2qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The family&#x27;s scientific heritage imposed high expectations, with Hinton&#x27;s father emphasizing rigorous intellectual effort amid a household filled with siblings, exotic animals like vipers, turtles, and lizards kept in the garage, fostering an early affinity for biological observation despite ideological constraints.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_43abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[7]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_63abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[6]</sup> At age four, Hinton experienced a formative curiosity when puzzled by a penny&#x27;s apparent motion on a moving bus, sparking lifelong inquiry into underlying mechanisms of perception and complex systems.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a3abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[6]</sup> In his teens, a high school friend&#x27;s notion of the brain functioning like a hologram ignited interest in neural processes, steering him toward cognitive science and artificial intelligence as avenues to model human-like intuition in machines, influenced by the family&#x27;s tradition of probing reality&#x27;s structures.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_e3abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_g3abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[7]</sup></span>
<h3 id="academic-training" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Academic Training<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton earned a Bachelor of Arts degree in experimental psychology from King&#x27;s College, Cambridge, in 1970, after initially exploring subjects including physiology, philosophy, and physics.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_44abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[9]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_64abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[10]</sup> Following graduation, he spent a year apprenticed in carpentry before pursuing graduate studies.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a4abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[11]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In 1972, Hinton began doctoral research in artificial intelligence at the University of Edinburgh, completing his PhD in 1978 with a thesis titled <em>Relaxation and its Role in Vision</em>, which examined mechanisms for interpreting imperfect visual data through consistent combinations of features.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_84qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[9]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a4qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[12]</sup> Despite initial discouragement from professors regarding his interest in neural networks, he persisted in developing ideas connecting psychological processes to computational models.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_e4qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[10]</sup> His work at Edinburgh laid early groundwork for his lifelong focus on machine learning architectures inspired by brain function.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_i4qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[13]</sup></span>
<h2 id="professional-career" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Professional Career<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="early-academic-positions" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Early Academic Positions<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Following his PhD in artificial intelligence from the University of Edinburgh in 1978, Hinton conducted postdoctoral research at the University of Sussex as a post-doctoral researcher in the late 1970s, where he began developing early theories on neural networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_46abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[14]</sup> He subsequently joined the University of California, San Diego as a Sloan Foundation postdoctoral researcher and visiting scholar from October 1978 to September 1980, collaborating with cognitive psychologists on neural network models of human cognition.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_86abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[11]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a6abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[15]</sup> Hinton briefly returned to UCSD in spring 1982 as a visiting assistant professor.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_e6abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[16]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In 1982, Hinton accepted a faculty position in the Computer Science Department at Carnegie Mellon University, serving for five years until 1987.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_46qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[17]</sup> During this period, he contributed to foundational work in connectionist learning procedures, including collaborations that advanced understanding of backpropagation in multilayer neural networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_86qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[18]</sup> These early positions provided Hinton with opportunities to explore unsupervised learning and Boltzmann machines amid limited funding for neural network research in the post-1970s &quot;AI winter.&quot;<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c6qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[19]</sup></span>
<h3 id="career-at-the-university-of-toronto" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Career at the University of Toronto<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton joined the Department of Computer Science at the University of Toronto in 1987 as a professor, shortly after becoming a fellow of the Canadian Institute for Advanced Research (CIFAR), which supported his relocation and research in neural networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_47qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[20]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_67qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[21]</sup> There, he built a influential research group that advanced machine learning techniques, including the creation of the CIFAR-10 and CIFAR-100 datasets in collaboration with students Alex Krizhevsky and Vinod Nair, comprising 60,000 32x32 color images across 10 and 100 classes respectively for training convolutional neural networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[22]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">From 1998 to 2001, Hinton took a leave of absence to establish and direct the Gatsby Computational Neuroscience Unit at University College London, after which he returned to his position at Toronto.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_48abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[23]</sup> Upon return, he directed CIFAR&#x27;s &quot;Neural Computation and Adaptive Perception&quot; program from 2004 to 2013, coordinating interdisciplinary efforts across institutions to explore hierarchical learning models and perceptual systems.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_88abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[9]</sup> Under his leadership, the Toronto group produced foundational work in deep learning, such as efficient pre-training methods for multilayer networks, which laid groundwork for later applications in object recognition.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_c8abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[9]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In 2017, Hinton co-founded the Vector Institute for Artificial Intelligence in Toronto, an independent research organization affiliated with the University of Toronto, and assumed the role of Chief Scientific Advisor, guiding its focus on scalable AI algorithms and ethical deployment.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_48qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[23]</sup> This initiative bolstered Toronto&#x27;s status as a global AI hub, attracting talent and funding while integrating with university programs. He continued as a full-time faculty member until transitioning to University Professor Emeritus status, maintaining an active presence through supervision of PhD students and public lectures.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_88qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[24]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_a8qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[25]</sup></span>
<h3 id="industry-roles-and-google-involvement" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Industry Roles and Google Involvement<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In 2012, Hinton co-founded DNNresearch Inc., a startup focused on advancing deep neural networks for applications in speech and image recognition, stemming from his academic work at the University of Toronto.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_49qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[26]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_89qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[27]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Google acquired DNNresearch in March 2013 for an undisclosed sum, integrating its three-person teamâ€”including Hinton and two of his studentsâ€”into the company&#x27;s research efforts on machine learning.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4aabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[28]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8aabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[29]</sup> Following the acquisition, Hinton joined Google as a part-time employee, serving as Vice President and Engineering Fellow, while continuing his faculty position at the University of Toronto.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_caabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[30]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gaabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[31]</sup> At Google, he contributed to deep learning initiatives, including improvements in voice recognition, image tagging, and neural network applications for search technologies, helping to scale these methods across Google&#x27;s products.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_kaabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[32]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_oaabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[33]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton&#x27;s tenure at Google, which lasted over a decade, involved bridging academic research with industrial deployment, notably during the rapid expansion of AI capabilities in the mid-2010s.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4aqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[34]</sup> Prior to the formal acquisition, bureaucratic constraints led to a brief period in 2012 where Hinton was technically classified as a Google intern while serving as a visiting researcher.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8aqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[35]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton resigned from Google in late April 2023, effective just before public announcements in early May, citing a desire to speak freely on the risks of artificial intelligence without corporate constraints.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4babav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[36]</sup> <sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8babav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[37]</sup> His departure highlighted tensions between accelerating AI development and existential concerns, though he affirmed Google&#x27;s responsible approach during his time there.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cbabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[38]</sup> No other significant industry roles preceded his Google involvement, as his career prior to 2012 was predominantly academic.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gbabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[30]</sup></span>
<h2 id="key-research-contributions" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Key Research Contributions<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="boltzmann-machines-and-unsupervised-learning" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Boltzmann Machines and Unsupervised Learning<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In 1985, Geoffrey Hinton, along with David Ackley and Terrence Sejnowski, introduced the Boltzmann machine, a stochastic neural network model consisting of symmetrically connected binary units that operate according to a probabilistic framework inspired by statistical mechanics.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4cqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[39]</sup> The model&#x27;s units update states asynchronously using a Gibbs sampling-like process to sample from an energy-based probability distribution, where the energy function is defined by connection weights and biases, enabling the network to reach equilibrium states representing low-energy configurations.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8cqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[40]</sup> This architecture was designed primarily for unsupervised learning tasks, such as constraint satisfaction and pattern completion, by adjusting weights to maximize the likelihood of observed data through a gradient-based rule that contrasts positive-phase activations (clamped to data) with negative-phase activations (free-running).<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ccqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[41]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The learning algorithm for Boltzmann machines relies on minimizing the Kullback-Leibler divergence between the model&#x27;s distribution and the data distribution, but practical implementation faces computational challenges due to the need to compute expectations over all possible states, which scales exponentially with network size.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4dabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[42]</sup> Hinton&#x27;s contributions emphasized the machine&#x27;s ability to discover distributed representationsâ€”probabilistic encodings where features are represented across multiple units rather than localizedâ€”allowing for robust generalization in unsupervised settings without explicit labels.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8dabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[43]</sup> Early applications demonstrated the model&#x27;s capacity for tasks like learning internal representations of patterns, such as vowel discrimination from acoustic inputs, where the network self-organizes to capture underlying statistical structures in data.</span>
<span class="mb-4 block break-words text-[1em] leading-7">To address training inefficiencies in full Boltzmann machines, Hinton later advanced restricted Boltzmann machines (RBMs), which impose a bipartite structure separating visible and hidden units with no intra-layer connections, rendering exact inference tractable via alternating Gibbs sampling.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4dqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[44]</sup> In 2002, Hinton developed contrastive divergence, an approximation method that performs limited MCMC steps starting from data-driven states to estimate gradients efficiently, reducing computational cost from intractable full sampling while converging to useful representations for unsupervised pretraining.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8dqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[44]</sup> RBMs excel in unsupervised learning by modeling joint distributions over inputs, enabling tasks like dimensionality reductionâ€”compressing high-dimensional data into lower-dimensional hidden featuresâ€”and generative sampling, where hidden units capture latent variables driving observed variability.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cdqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[43]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton&#x27;s work on these models underscored their role in unsupervised feature learning, where layers of RBMs can be stacked greedily: training one layer to reconstruct inputs via hidden representations, then using those as inputs for the next, fostering hierarchical abstractions without supervision.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4eabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[44]</sup> Empirical evaluations showed RBMs outperforming alternatives like principal component analysis in capturing nonlinear manifolds in datasets such as natural images, due to their probabilistic handling of dependencies.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8eabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[43]</sup> This foundation proved causal in enabling scalable unsupervised learning, as the models&#x27; energy minimization parallels physical annealing, promoting exploration of solution spaces for complex, unlabeled data patterns.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ceabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[45]</sup></span>
<h3 id="backpropagation-algorithm" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Backpropagation Algorithm<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">The backpropagation algorithm computes the gradient of the loss function with respect to the weights of a neural network by applying the chain rule in a reverse pass from output to input layers, enabling efficient supervised training of multi-layer networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4fabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[46]</sup> This method addresses the challenge of credit assignment in hidden layers, where errors are propagated backward to adjust weights proportionally to their contribution to the observed discrepancy between predicted and actual outputs.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8fabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[47]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Geoffrey Hinton co-authored the seminal 1986 paper &quot;Learning Representations by Back-Propagating Errors&quot; with David E. Rumelhart and Ronald J. Williams, published in <em>Nature</em> on October 9, 1986, which formalized and demonstrated backpropagation&#x27;s application to multi-layer feedforward networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8fqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[47]</sup> The paper provided mathematical derivations, simulations showing convergence on tasks like encoding/decoding patterns and learning logical operations (e.g., exclusive-or), and emphasized its role in discovering useful internal representations without explicit programming.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cfqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[48]</sup> Hinton&#x27;s involvement stemmed from his work in the Parallel Distributed Processing (PDP) research group, where he collaborated on connectionist models; initially skeptical of gradient-based methods due to concerns over biological implausibility and scaling issues, he adopted backpropagation after demonstrations of its effectiveness on non-trivial problems.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_gfqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[49]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Although precursors existedâ€”such as Paul Werbos&#x27;s 1974 dissertation outlining similar gradient computations for dynamic systems and Seppo Linnainmaa&#x27;s 1970 work on reverse-mode automatic differentiationâ€”the 1986 paper by Rumelhart, Hinton, and Williams popularized the algorithm within the AI community by making it computationally tractable for practical neural architectures and countering skepticism from symbolic AI paradigms.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4gabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[50]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6gabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[51]</sup> Hinton has stated that he did not invent backpropagation but credited Rumelhart with independently developing it for neural contexts after earlier formulations in other fields, noting its prior obscurity limited adoption until their accessible presentation with empirical examples.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_agabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[50]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">This contribution laid groundwork for Hinton&#x27;s subsequent research, including its integration with Boltzmann machines for hybrid learning and later deep architectures, though he later critiqued backpropagation&#x27;s limitations, such as poor scaling for large tasks and reliance on non-local computations atypical of biological learning.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4gqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[52]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6gqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[53]</sup> The algorithm&#x27;s efficiencyâ€”requiring only a single forward and backward pass per training exampleâ€”proved pivotal in overcoming the &quot;vanishing gradient&quot; challenges in deeper networks when combined with techniques like rectified linear units in the 2000s.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_agqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[54]</sup></span>
<h3 id="deep-belief-networks-and-the-revival-of-deep-learning" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Deep Belief Networks and the Revival of Deep Learning<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In 2006, Geoffrey Hinton, Simon Osindero, and Yee-Whye Teh introduced deep belief networks (DBNs) in their paper &quot;A Fast Learning Algorithm for Deep Belief Nets,&quot; published in <em>Neural Computation</em>.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8hqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[55]</sup> DBNs consist of a stack of restricted Boltzmann machines (RBMs), where each layer learns a probabilistic representation of the data from the layer below through unsupervised training.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_chqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[56]</sup> The model uses a greedy, layer-by-layer algorithm: the first layer is trained as a single RBM on input data, subsequent layers treat activations from the previous layer as inputs, and the top two layers form an undirected associative memory to approximate the posterior distribution efficiently.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ghqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[57]</sup> This structure allows DBNs to perform generative modeling while enabling discriminative tasks via fine-tuning with backpropagation on labeled data.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_khqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[58]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The key innovation addressed longstanding difficulties in training deep networks, including vanishing gradients and poor initialization, by initializing weights through unsupervised pre-training rather than random values.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4iabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[59]</sup> Experiments in the 2006 paper demonstrated DBNs achieving 1.25% error on the MNIST handwritten digit dataset after greedy pre-training and supervised fine-tuning, surpassing prior state-of-the-art results like support vector machines (1.4% error) without relying heavily on labeled data initially.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8iabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[55]</sup> On natural image patches, DBNs learned hierarchical features resembling simple and complex cells in visual cortex, such as edge detectors in lower layers and more abstract patterns higher up.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ciabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[55]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">DBNs revived deep learning by providing empirical evidence that deep architectures could generalize better than shallow ones on unsupervised and supervised tasks, countering decades of skepticism following the 1980s AI winter.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4iqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[60]</sup> This layer-wise pre-training technique influenced subsequent methods, including those in convolutional networks, and catalyzed a surge in research; Hinton&#x27;s paper garnered over 23,000 citations by 2024, reflecting its foundational role.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8iqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[25]</sup> By enabling scalable training of networks with many hidden layers, DBNs laid groundwork for breakthroughs like deep convolutional nets in image recognition and recurrent nets in speech processing, shifting AI toward data-driven, end-to-end learning paradigms.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ciqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[61]</sup></span>
<h3 id="applications-in-speech-and-image-recognition" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Applications in Speech and Image Recognition<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton&#x27;s deep belief networks (DBNs), introduced in 2006, marked a pivotal advancement for image recognition by enabling unsupervised pre-training of multi-layer architectures, which addressed vanishing gradient issues in deep networks. Applied to the MNIST dataset of 60,000 handwritten digits, a DBN with three hidden layers achieved a classification error rate of 1.25% after fine-tuning with backpropagation, outperforming prior shallow networks and kernel methods like support vector machines that typically exceeded 1.4% error.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4jqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[55]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6jqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[62]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">This foundation influenced subsequent vision breakthroughs from Hinton&#x27;s Toronto lab. In 2012, his students Alex Krizhevsky and Ilya Sutskever, under Hinton&#x27;s supervision, developed AlexNetâ€”a deep convolutional neural network trained on GPUsâ€”that secured first place in the ImageNet Large Scale Visual Recognition Challenge. AlexNet classified 1.2 million high-resolution images across 1,000 categories with a top-5 error rate of 15.3%, halving the previous best of 26% and igniting the deep learning revolution in computer vision by demonstrating scalable feature learning from raw pixels.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4kabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[63]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6kabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[64]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In speech recognition, Hinton&#x27;s group extended DBNs to acoustic modeling, shifting from traditional Gaussian mixture model-hidden Markov model (GMM-HMM) hybrids to end-to-end neural approaches. In 2009, they deployed DBNs for phone recognition on the TIMIT corpus, using generative pre-training on filter-bank features followed by discriminative fine-tuning, which reduced phone error rates below GMM baselines by modeling spectral variabilities more effectively.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4kqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[65]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6kqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[66]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">By 2012, Hinton co-authored findings from multiple groups showing deep neural networks (DNNs) achieved a 20.7% phone error rate on TIMIT with nine-layer models and yielded relative word error rate reductions of up to 33% on challenging corpora like Switchboard, prompting industry adoptionâ€”such as in Google&#x27;s voice searchâ€”where DNNs replaced GMMs as the standard for large-vocabulary continuous speech recognition.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4labav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[67]</sup> These results underscored Hinton&#x27;s causal insight that hierarchical representations learned from data outperform hand-engineered features, revolutionizing both domains through empirical validation on benchmarks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8labav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[23]</sup></span>
<h2 id="awards-and-recognition" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Awards and Recognition<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="major-honors-and-prizes" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Major Honors and Prizes<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton was awarded the A.M. Turing Award in 2018, jointly with Yoshua Bengio and Yann LeCun, for conceptual and engineering breakthroughs enabling deep neural networks to become the dominant technology in artificial intelligence.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4mqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[68]</sup> The prize, often called the &quot;Nobel Prize of computing,&quot; recognized their work on backpropagation and convolutional neural networks that powered advancements in image, speech, and language recognition.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8mqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[68]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In 2001, he received the David E. Rumelhart Prize, the first recipient of this award from the Cognitive Science Society, for significant contributions to the formal analysis of human cognition.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4nabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[69]</sup> He also earned the IJCAI Award for Research Excellence in 2005 from the International Joint Conferences on Artificial Intelligence for lifetime contributions to AI research.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8nabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[69]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton was granted the Killam Prize for Engineering in 2012 by the Canada Council for the Arts, honoring his pioneering role in neural network research and its applications.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4nqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[69]</sup> In 2019, he received the Honda Prize from the Honda Foundation for his work on deep learning algorithms that revolutionized pattern recognition in machines.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8nqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[11]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Further recognition came with the Dickson Prize in Science from Carnegie Mellon University in 2021 for foundational contributions to machine learning.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4oabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[11]</sup> In 2022, Hinton shared the Princess of Asturias Award for Technical and Scientific Research with Bengio and LeCun, acknowledging their impact on AI development.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8oabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[11]</sup></span>





















































<div class="border-border-l1 overflow-x-auto rounded-lg border my-6 w-full"><table node="[object Object]" class="w-full border-collapse text-sm"><thead node="[object Object]" class="border-border-l1 border-b bg-surface-l1"><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><th node="[object Object]" class="dark:text-fg-primary bg-gray-100 px-2 py-1 text-left align-top font-bold dark:bg-black"><span class="text-[1em] leading-7">Year</span></th><th node="[object Object]" class="dark:text-fg-primary bg-gray-100 px-2 py-1 text-left align-top font-bold dark:bg-black"><span class="text-[1em] leading-7">Award</span></th><th node="[object Object]" class="dark:text-fg-primary bg-gray-100 px-2 py-1 text-left align-top font-bold dark:bg-black"><span class="text-[1em] leading-7">Shared With</span></th><th node="[object Object]" class="dark:text-fg-primary bg-gray-100 px-2 py-1 text-left align-top font-bold dark:bg-black"><span class="text-[1em] leading-7">Citation</span></th></tr></thead><tbody node="[object Object]" class="divide-border-l1 divide-y"><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">2001</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">David E. Rumelhart Prize</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">None</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Cognitive Science Society</span></td></tr><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">2005</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">IJCAI Award for Research Excellence</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">None</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">International Joint Conferences on AI</span></td></tr><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">2012</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Killam Prize for Engineering</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">None</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Canada Council for the Arts</span></td></tr><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">2018</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">A.M. Turing Award</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Yoshua Bengio, Yann LeCun</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">ACM</span></td></tr><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">2019</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Honda Prize</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">None</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Honda Foundation</span></td></tr><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">2021</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Dickson Prize in Science</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">None</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Carnegie Mellon University</span></td></tr><tr node="[object Object]" class="divide-border-l1 divide-x bg-surface-l1"><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">2022</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Princess of Asturias Award</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Yoshua Bengio, Yann LeCun</span></td><td node="[object Object]" class="text-fg-primary px-2 py-1 align-top"><span class="text-[1em] leading-7">Princess of Asturias Foundation</span></td></tr></tbody></table></div>
<h3 id="nobel-prize-in-physics-2024" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Nobel Prize in Physics (2024)<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">
On October 8, 2024, the Royal Swedish Academy of Sciences awarded the Nobel Prize in Physics jointly to John J. Hopfield and Geoffrey E. Hinton for foundational discoveries and inventions enabling machine learning with artificial neural networks.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6pqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup> The prize recognized Hopfield&#x27;s development of Hopfield networks, which use statistical physics to store and reconstruct patterns akin to associative memory, and Hinton&#x27;s creation of the Boltzmann machine, an unsupervised learning algorithm that autonomously identifies properties in data through energy-based models derived from statistical mechanics.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_apqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[70]</sup> These contributions bridged physics and computation, providing tools for neural networks to process complex, unstructured data without explicit programming.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_epqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton&#x27;s work extended to practical advancements, including efficient training of multi-layer networks via backpropagation and the introduction of deep belief networks, which revived interest in deep learning by demonstrating scalable pattern recognition for applications like image classification and speech processing.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4qabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup> The Nobel committee highlighted how these methods underpin modern artificial intelligence systems, capable of approximating arbitrary functions and learning from vast datasets, fundamentally altering computational approaches to complex problems. The award, valued at 11 million Swedish kronor to be shared equally between the laureates, underscored the physical principles underlying neural network dynamics, despite the field&#x27;s roots in computer science.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8qabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[3]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Following the announcement, Hinton expressed concerns about AI development outpacing safety measures, advocating for increased research into mitigating risks from superintelligent systems in interviews and speeches.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4qqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[71]</sup> He noted in his Nobel banquet speech the potential for AI to engineer novel pathogens or autonomous weapons, emphasizing existential threats while affirming the technology&#x27;s transformative potential.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8qqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[72]</sup> This perspective, voiced after his 2023 departure from Google to speak freely on AI hazards, aligned with his long-standing warnings about unintended consequences of rapid scaling in neural architectures.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cqqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[73]</sup></span>
<h2 id="public-positions-on-ai" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Public Positions on AI<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="evolution-of-views-on-ai-capabilities" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Evolution of Views on AI Capabilities<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In the 1970s and 1980s, Geoffrey Hinton pursued research on neural networks at a time when the approach was largely discredited following early failures like the Perceptron, with his PhD supervisor advising against it in favor of symbolic AI methods. Hinton maintained that artificial intelligence required computation mimicking the human brain&#x27;s pattern-learning mechanisms, rejecting rule-based systems as insufficient for achieving general intelligence.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4sabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[74]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6sabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[75]</sup> Despite AI winters in the late 1980s and 1990s, when funding and interest waned due to perceived limitations in scaling neural networks, Hinton persisted, developing techniques like backpropagation and Boltzmann machines, convinced that connectionist models could eventually demonstrate human-like learning capabilities through unsupervised methods.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_asabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[76]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_csabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[77]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">By the early 2000s, Hinton&#x27;s work on deep belief networks in 2006 contributed to the revival of deep learning, bolstered by computational advances like GPUs and large datasets, which validated neural networks&#x27; potential for tasks such as image and speech recognition. He viewed these as steps toward scalable intelligence but estimated timelines for artificial general intelligence (AGI) at 30 to 50 years, emphasizing gradual progress rather than imminent breakthroughs.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4sqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[76]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6sqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[78]</sup> This period reflected his sustained optimism in neural architectures&#x27; ability to handle complex, real-world data patterns, contrasting with ongoing skepticism from symbolic AI proponents.</span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton&#x27;s assessment shifted markedly after 2022, with the rapid capabilities of large language models like GPT-4 surprising him by demonstrating emergent reasoning and understanding beyond statistical prediction, prompting him to revise AGI timelines to 5 to 20 years and superintelligenceâ€”AI exceeding human intellect across domainsâ€”even sooner. In 2023 interviews, he noted that digital intelligence&#x27;s advantages in speed, scalability, and error-free copying outpace biological evolution, enabling exponential self-improvement. By 2024, he estimated a 10-20% chance of superintelligent AI leading to human extinction within 30 years, attributing the change to unforeseen scaling laws where model performance improved predictably with compute and data.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4tabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6tabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[74]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8tabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[80]</sup></span>
<h3 id="concerns-over-superintelligence-and-existential-risks" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Concerns Over Superintelligence and Existential Risks<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton resigned from Google on May 1, 2023, after a decade at the company, stating that his departure allowed him to discuss AI risks without constraint, particularly the danger of digital intelligence exceeding biological intelligence and potentially controlling or eliminating humans.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4uabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[34]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6uabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[31]</sup> He cited fears that AI systems could rapidly self-improve beyond human comprehension, leading to scenarios where they prioritize their own objectives over human welfare, akin to evolutionary dynamics in which superior competitors displace weaker ones.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_auabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[81]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cuabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[38]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">In a CBS <em>60 Minutes</em> interview aired October 8, 2023, Hinton warned that AI might already possess deceptive capabilities surpassing human detection, with superintelligent systems capable of manipulating societal structures or evading safeguards to achieve misaligned goals.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8uqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[82]</sup> He has analogized the risk to humans&#x27; historical displacement of Neanderthals, suggesting AI could view humanity as an obstacle if programmed or evolved toward self-preservation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cuqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[37]</sup> Hinton emphasized that current large language models demonstrate emergent abilities hinting at future superintelligence, where AI could autonomously design superior successors, accelerating toward uncontrollable autonomy.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_guqbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[74]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton has repeatedly quantified the existential threat, estimating a 10% to 20% probability that AI will cause human extinction within the next 30 years, driven by both adversarial misuseâ€”such as weaponization by states or terroristsâ€”and accidental misalignment where superintelligent AI pursues unintended ends.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_4vabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[80]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6vabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[83]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_8vabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[84]</sup> He projects a 50% chance of AI surpassing human-level intelligence within 20 years, urging international regulation akin to nuclear controls to avert catastrophe, while acknowledging that competitive pressures among developers may hinder voluntary restraint.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_cvabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[74]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_evabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[85]</sup> Despite these alarms, Hinton maintains optimism about AI&#x27;s potential benefits if risks are managed, but insists the downside of inaction outweighs optimistic assumptions about controllability.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_ivabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[78]</sup></span>
<h3 id="economic-and-misuse-risks" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Economic and Misuse Risks<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton has expressed concerns that artificial intelligence could lead to widespread job displacement, as companies increasingly replace human workers with AI systems to reduce costs and boost profits. In a September 2025 interview, he stated that &quot;rich people are going to use AI to replace all the poor people,&quot; predicting that this would exacerbate economic inequality by concentrating wealth among a small elite while leaving many without employment.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_50abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[86]</sup> He estimated a 10% to 20% chance that superintelligent AI could fully displace humans from most jobs, potentially rendering traditional labor markets obsolete.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_90abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[83]</sup> Hinton has advocated for measures like universal basic income to mitigate these effects, warning that society remains unprepared for the resulting unemployment surge and social instability.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d0abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[87]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_f0abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[88]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Regarding misuse, Hinton has highlighted AI&#x27;s potential for enabling cyberattacks and infrastructure sabotage, noting that its scalability allows bad actors to rapidly adapt and overwhelm critical systems such as banks, hospitals, and power grids.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_50qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[89]</sup> He has warned of authoritarian regimes leveraging AI for mass surveillance and control, which could erode personal freedoms and privacy by monitoring populations at unprecedented scales.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_90qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[90]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[91]</sup> Additionally, Hinton has flagged military applications, including autonomous weapons and propaganda tools, as significant threats that could escalate conflicts or manipulate public opinion without human oversight.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_f0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[92]</sup> In discussions, he categorizes these as genuine short-term risks alongside longer-term existential dangers, emphasizing the need for regulatory safeguards to prevent such abuses.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_j0qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[93]</sup></span>
<h2 id="criticisms-and-responses" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Criticisms and Responses<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="skepticism-toward-ai-doomerism" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Skepticism Toward AI Doomerism<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Yann LeCun, Meta&#x27;s chief AI scientist and a contemporary of Hinton in neural network research, has publicly rejected Hinton&#x27;s emphasis on near-term existential risks from superintelligent AI, arguing that such systems lack the agency, goals, or self-preservation instincts needed to pose uncontrollable threats to humanity.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_52abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[94]</sup> LeCun contends that AI safety concerns should prioritize architectural safeguards and empirical testing over speculative doomsday scenarios, viewing doomerism as distracting from solvable issues like bias or misuse.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_92abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[95]</sup> He has criticized collaborative statements signed by Hinton warning of &quot;societal-scale risks,&quot; implying they exaggerate dangers without sufficient evidence of AI&#x27;s path to autonomy.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d2abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[96]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Skeptics further highlight Hinton&#x27;s history of overoptimistic timelines for AI capabilities, such as his 2016 prediction that machine learning would surpass radiologists in diagnostic accuracy within five yearsâ€”a benchmark unmet as of 2024, with AI tools aiding but not replacing human experts in clinical settings.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_52qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[97]</sup> This track record, proponents of skepticism argue, undermines confidence in Hinton&#x27;s projections of superintelligence emerging in 5 to 20 years, as it reflects a pattern of conflating rapid scaling with imminent breakthroughs in general intelligence.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_92qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[98]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Critics like technology analyst Paris Marx assert that Hinton&#x27;s warnings rely on unproven analogies between artificial neural networks and biological brains, assuming scalable intelligence will inherently lead to adversarial behavior without addressing fundamental gaps in AI&#x27;s reasoning, planning, or world-modeling abilities.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_53abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[98]</sup> From a first-principles perspective, they note that no current AI exhibits the causal understanding or adaptive agency required for existential dominance, and historical precedents of technological alarmismâ€”such as fears of nuclear proliferation or genetic engineeringâ€”have often prioritized verifiable misuse risks over hypothetical superintelligence takeovers.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_93abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[99]</sup> While acknowledging Hinton&#x27;s foundational contributions to deep learning, these voices maintain that doomerism risks policy misallocation, diverting resources from immediate challenges like economic disruption or weaponization toward unquantifiable long-tail scenarios lacking empirical substantiation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d3abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[95]</sup></span>
<h3 id="controversies-over-past-predictions-and-ethical-stance" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Controversies Over Past Predictions and Ethical Stance<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In 2016, Hinton predicted that artificial intelligence would be capable of performing all tasks undertaken by radiologists within five years, a forecast that generated significant debate within the medical imaging community.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_54abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[100]</sup> By May 2025, he publicly acknowledged this prediction as erroneous, noting that while AI has advanced in image analysis, it has not fully replicated the comprehensive diagnostic and interpretive roles of human radiologists.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_94abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[100]</sup> This admission highlighted challenges in calibrating timelines for AI capabilities, as empirical progress in specialized domains like radiology has lagged behind optimistic projections despite improvements in tools such as convolutional neural networks.</span>
<span class="mb-4 block break-words text-[1em] leading-7">Critics have extended skepticism to Hinton&#x27;s broader forecasts on AI surpassing human intelligence, arguing that his emphasis on rapid, existential-scale advancements overlooks empirical limitations in current systems, such as their reliance on vast datasets without genuine causal understanding.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_54qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[98]</sup> For instance, analyses contend that Hinton&#x27;s analogy between artificial neural networks and biological brains implies unproven similarities in reasoning mechanisms, leading to overstated risks of uncontrollable superintelligence.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_94qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[98]</sup> Such views draw parallels to historical AI alarmism, where predictions of imminent human obsolescence, as echoed in Hinton&#x27;s warnings of AI rendering human intelligence &quot;irrelevant&quot; akin to the Industrial Revolution&#x27;s impact on physical strength, have not materialized within anticipated periods.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d4qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[99]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton&#x27;s ethical position crystallized in May 2023 when he resigned from Google after a decade with the company, citing a desire to discuss AI dangers without corporate constraints, including risks of superintelligent systems outpacing human control and potential for misuse in warfare or manipulation.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_55abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup> He has advocated for regulatory measures modeled on chemical weapons bans and endorsed prohibitions on autonomous weapons systems, emphasizing empirical precedents where technological proliferation led to arms races.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_95abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b5abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[101]</sup> In October 2024, following his Nobel Prize, he reiterated concerns over AI-driven job displacement and societal instability without redistribution mechanisms.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_f5abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[102]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Controversies surrounding this stance include accusations of inconsistency, as detractors point to his long tenure at Googleâ€”during which AI technologies he helped develop were commercializedâ€”before pivoting to alarmism, potentially amplifying public fear over verifiable near-term harms like data privacy erosion or economic concentration in tech firms.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_55qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[98]</sup> Commentators argue that Hinton&#x27;s focus on speculative existential threats diverts attention from causal factors in AI deployment, such as profit-driven scaling by corporations, which empirical evidence links more directly to issues like bias amplification and labor disruption than hypothetical superintelligence scenarios.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_95qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[98]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b5qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[103]</sup> Proponents of moderated optimism counter that while AI poses governance challenges, doomerist narratives risk stifling innovation without proportionate evidence of inevitability.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_f5qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[104]</sup></span>
<h2 id="personal-life" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden" node="[object Object]">Personal Life<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h2>
<h3 id="family-and-heritage" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Family and Heritage<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">Geoffrey Everest Hinton was born on December 6, 1947, in Wimbledon, London, England, to Howard Everest Hinton, an entomologist and professor of entomology at the University of Bristol, and Margaret Rose Hinton.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_57abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[105]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_77abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[106]</sup> His middle name derives from George Everest, the British Surveyor General of India (1790â€“1866) for whom Mount Everest is named, a relative on his paternal side.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b7abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[107]</sup> Hinton&#x27;s father, born in 1912 and deceased in 1977, specialized in insect physiology and was elected a Fellow of the Royal Society in 1967 for his contributions to the study of insect eggs and development.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_f7abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[106]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Hinton descends from a lineage of prominent intellectuals, particularly through his paternal grandmother&#x27;s side tracing back to George Boole (1815â€“1864), the mathematician and logician who developed Boolean algebra, foundational to modern computing and digital logic.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_57qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_77qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[105]</sup> Boole was Hinton&#x27;s great-great-grandfather via his daughter Mary Everest Boole, who married Charles Howard Hinton, linking the family to both logical formalism and multidimensional geometry through Charles&#x27;s work on the fourth dimension.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup> Hinton&#x27;s grandfather, George Boole Hinton (1882â€“1943), worked as a mining engineer, while other relatives include Joan Hinton (1921â€“2010), a nuclear physicist and dairy farmer who moved to China in 1948 and contributed to its early atomic programs as a first cousin once removed.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_f7qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">The family heritage reflects a pattern of scientific achievement across generations, with multiple members elected Fellows of the Royal Society, including Hinton&#x27;s father and great-uncle Howard Florey (1898â€“1968), who shared the 1945 Nobel Prize in Physiology or Medicine for isolating penicillin.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_58abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[106]</sup> This intellectual dynasty spans fields from logic and medicine to physics and biology, influencing Hinton&#x27;s early exposure to rigorous empirical inquiry, though he initially resisted pursuing science due to familial expectations.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_98abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[8]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b8abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[108]</sup></span>
<h3 id="later-years-and-retirement" class="group relative mb-2 mt-7 scroll-mt-24 font-serif text-[1.428571em] font-semibold" node="[object Object]">Later Years and Retirement<button class="focus-visible:ring-ring gap-x-2 whitespace-nowrap rounded-full font-medium focus-visible:outline-none focus-visible:ring-1 disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;[data-slot=icon]]:-mx-0.5 [&amp;&gt;[data-slot=icon]]:my-0.5 [&amp;&gt;[data-slot=icon]]:size-5 [&amp;&gt;[data-slot=icon]]:shrink-0 [&amp;&gt;[data-slot=icon]]:text-[--btn-icon] [&amp;&gt;[data-slot=icon]]:sm:my-1 [&amp;&gt;[data-slot=icon]]:sm:size-4 text-primary text-xs ml-2 inline-flex h-6 w-6 items-center justify-center p-0 align-middle opacity-0 transition-opacity hover:bg-gray-100 dark:hover:bg-gray-800" type="button" aria-label="Copy link to heading" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></h3>
<span class="mb-4 block break-words text-[1em] leading-7">In May 2023, Geoffrey Hinton, then 75, resigned from Google after over a decade with the company, citing his age and a desire to speak freely about artificial intelligence risks without corporate constraints.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_59abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[37]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_79abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[34]</sup> Google confirmed the departure as a retirement from his role leading the Toronto research team.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_b9abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[109]</sup> Hinton expressed partial regret for his contributions to AI development, fearing it could enable superintelligent systems outpacing human control, though he acknowledged the technology&#x27;s potential benefits in fields like medicine.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_f9abav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[79]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Following his Google exit, Hinton transitioned to professor emeritus status at the University of Toronto, where he had long been based, allowing continued academic ties while reducing formal obligations.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_59qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[82]</sup> His retirement did not end public engagement; he testified before the U.S. Senate on AI risks in May 2023 and granted interviews emphasizing existential threats from unchecked AI advancement.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_99qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[110]</sup> In October 2024, Hinton shared the Nobel Prize in Physics with John Hopfield for foundational work on neural network machine learning methods, recognizing contributions from decades earlier that enabled modern deep learning.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_d9qbav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[1]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7">Into 2025, Hinton remained vocal on AI&#x27;s societal impacts, predicting massive unemployment from automation and soaring corporate profits under existing economic systems.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_5aabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[111]</sup> He participated in discussions on AI surpassing biological intelligence and signed an open statement on October 22, 2025, urging suspension of artificial general intelligence development due to safety concerns.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_9aabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[112]</sup><sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_baabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[113]</sup> Despite these activities, Hinton&#x27;s homepage at the University of Toronto lists ongoing lectures and publications, indicating semi-retired involvement in the field rather than full withdrawal.<sup class="text-fg-secondary ml-[2px] cursor-pointer text-xs hover:underline" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_faabav9fiumdb_" data-state="closed" tabindex="-1" style="outline:none">[24]</sup></span>
<span class="mb-4 block break-words text-[1em] leading-7"></span></article><div id="references" class="min-w-0 scroll-mt-8 overflow-hidden"><div class="text-[16px]"><h2 id="references" node="[object Object]" class="mb-2 mt-7 scroll-mt-24 font-serif text-[1.714286em] font-semibold border-border-l1 pb-1 border-b overflow-hidden">References</h2></div><ol class="columns-1 gap-x-12 [counter-reset:item] md:columns-2"><li id="https://www.nobelprize.org/prizes/physics/2024/hinton/facts/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nobelprize.org/prizes/physics/2024/hinton/facts/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nobelprize.org/prizes/physics/2024/hinton/facts/</a></span></div></li><li id="https://www.cs.utoronto.ca/~hinton/bio.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.utoronto.ca/~hinton/bio.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.utoronto.ca/~hinton/bio.html</a></span></div></li><li id="https://www.nobelprize.org/prizes/physics/2024/press-release/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nobelprize.org/prizes/physics/2024/press-release/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nobelprize.org/prizes/physics/2024/press-release/</a></span></div></li><li id="http://www.cs.utoronto.ca/~hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="http://www.cs.utoronto.ca/~hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">http://www.cs.utoronto.ca/~hinton/</a></span></div></li><li id="https://www.reuters.com/technology/google-ai-pioneer-says-he-quit-speak-freely-about-technologys-dangers-2023-05-02/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.reuters.com/technology/google-ai-pioneer-says-he-quit-speak-freely-about-technologys-dangers-2023-05-02/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.reuters.com/technology/google-ai-pioneer-says-he-quit-speak-freely-about-technologys-dangers-2023-05-02/</a></span></div></li><li id="https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/</a></span></div></li><li id="https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai</a></span></div></li><li id="https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/</a></span></div></li><li id="https://www.cs.toronto.edu/~hinton/bio.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~hinton/bio.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~hinton/bio.html</a></span></div></li><li id="https://www.britannica.com/biography/Geoffrey-Hinton" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.britannica.com/biography/Geoffrey-Hinton" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.britannica.com/biography/Geoffrey-Hinton</a></span></div></li><li id="https://amturing.acm.org/award_winners/hinton_4791679.cfm" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://amturing.acm.org/award_winners/hinton_4791679.cfm" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://amturing.acm.org/award_winners/hinton_4791679.cfm</a></span></div></li><li id="https://era.ed.ac.uk/handle/1842/8121" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://era.ed.ac.uk/handle/1842/8121" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://era.ed.ac.uk/handle/1842/8121</a></span></div></li><li id="https://www.frontiersofknowledgeawards-fbbva.es/galardonados/geoffrey-hinton-2/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.frontiersofknowledgeawards-fbbva.es/galardonados/geoffrey-hinton-2/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.frontiersofknowledgeawards-fbbva.es/galardonados/geoffrey-hinton-2/</a></span></div></li><li id="https://www.sussex.ac.uk/broadcast/read/65834" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.sussex.ac.uk/broadcast/read/65834" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.sussex.ac.uk/broadcast/read/65834</a></span></div></li><li id="https://discover.research.utoronto.ca/26059-geoffrey-e-hinton" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://discover.research.utoronto.ca/26059-geoffrey-e-hinton" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://discover.research.utoronto.ca/26059-geoffrey-e-hinton</a></span></div></li><li id="https://today.ucsd.edu/story/nobel-prize-winner-godfather-of-ai-geoffrey-hinton-has-uc-san-diego-roots" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://today.ucsd.edu/story/nobel-prize-winner-godfather-of-ai-geoffrey-hinton-has-uc-san-diego-roots" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://today.ucsd.edu/story/nobel-prize-winner-godfather-of-ai-geoffrey-hinton-has-uc-san-diego-roots</a></span></div></li><li id="https://www.nasonline.org/directory-entry/geoffrey-e-hinton-c2tmwf/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nasonline.org/directory-entry/geoffrey-e-hinton-c2tmwf/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nasonline.org/directory-entry/geoffrey-e-hinton-c2tmwf/</a></span></div></li><li id="https://files.eric.ed.gov/fulltext/ED294889.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://files.eric.ed.gov/fulltext/ED294889.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://files.eric.ed.gov/fulltext/ED294889.pdf</a></span></div></li><li id="https://www.nobelprize.org/events/nobel-prize-dialogue/madrid-2025/panellists/geoffrey-hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nobelprize.org/events/nobel-prize-dialogue/madrid-2025/panellists/geoffrey-hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nobelprize.org/events/nobel-prize-dialogue/madrid-2025/panellists/geoffrey-hinton/</a></span></div></li><li id="https://www.artsci.utoronto.ca/news/geoffrey-hinton-wins-nobel-prize-physics" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.artsci.utoronto.ca/news/geoffrey-hinton-wins-nobel-prize-physics" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.artsci.utoronto.ca/news/geoffrey-hinton-wins-nobel-prize-physics</a></span></div></li><li id="https://cifar.ca/publications-reports/reach/geoffrey-hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://cifar.ca/publications-reports/reach/geoffrey-hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://cifar.ca/publications-reports/reach/geoffrey-hinton/</a></span></div></li><li id="https://www.cs.toronto.edu/~kriz/cifar.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~kriz/cifar.html</a></span></div></li><li id="https://vectorinstitute.ai/team/geoffrey-hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://vectorinstitute.ai/team/geoffrey-hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://vectorinstitute.ai/team/geoffrey-hinton/</a></span></div></li><li id="https://www.cs.toronto.edu/~hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~hinton/</a></span></div></li><li id="https://scholar.google.com/citations?user=JicYPdAAAAAJ&amp;hl=en" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://scholar.google.com/citations?user=JicYPdAAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://scholar.google.com/citations?user=JicYPdAAAAAJ&amp;hl=en</a></span></div></li><li id="https://media.utoronto.ca/media-releases/u-of-t-neural-networks-start-up-acquired-by-google/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://media.utoronto.ca/media-releases/u-of-t-neural-networks-start-up-acquired-by-google/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://media.utoronto.ca/media-releases/u-of-t-neural-networks-start-up-acquired-by-google/</a></span></div></li><li id="https://techcrunch.com/2013/03/12/google-scoops-up-neural-networks-startup-dnnresearch-to-boost-its-voice-and-image-search-tech/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://techcrunch.com/2013/03/12/google-scoops-up-neural-networks-startup-dnnresearch-to-boost-its-voice-and-image-search-tech/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://techcrunch.com/2013/03/12/google-scoops-up-neural-networks-startup-dnnresearch-to-boost-its-voice-and-image-search-tech/</a></span></div></li><li id="https://www.wired.com/2013/03/google-hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.wired.com/2013/03/google-hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.wired.com/2013/03/google-hinton/</a></span></div></li><li id="https://www.cbc.ca/news/science/google-buys-university-of-toronto-startup-1.1373641" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cbc.ca/news/science/google-buys-university-of-toronto-startup-1.1373641" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cbc.ca/news/science/google-buys-university-of-toronto-startup-1.1373641</a></span></div></li><li id="https://time.com/collection/time100-ai/6309026/geoffrey-hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://time.com/collection/time100-ai/6309026/geoffrey-hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://time.com/collection/time100-ai/6309026/geoffrey-hinton/</a></span></div></li><li id="https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning</a></span></div></li><li id="https://www.forbes.com/sites/peterhigh/2016/06/20/deep-learning-pioneer-geoff-hinton-helps-shape-googles-drive-to-put-ai-everywhere/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.forbes.com/sites/peterhigh/2016/06/20/deep-learning-pioneer-geoff-hinton-helps-shape-googles-drive-to-put-ai-everywhere/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.forbes.com/sites/peterhigh/2016/06/20/deep-learning-pioneer-geoff-hinton-helps-shape-googles-drive-to-put-ai-everywhere/</a></span></div></li><li id="https://sites.google.com/site/jobsandrobots/more/people/geoffrey-hinton-section/meet-geoffrey-hinton-the-man-google-hired-to-make-ai-a-reality" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://sites.google.com/site/jobsandrobots/more/people/geoffrey-hinton-section/meet-geoffrey-hinton-the-man-google-hired-to-make-ai-a-reality" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://sites.google.com/site/jobsandrobots/more/people/geoffrey-hinton-section/meet-geoffrey-hinton-the-man-google-hired-to-make-ai-a-reality</a></span></div></li><li id="https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html</a></span></div></li><li id="https://techcrunch.com/2017/09/14/geoffrey-hinton-was-briefly-a-google-intern-in-2012-because-of-bureaucracy/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://techcrunch.com/2017/09/14/geoffrey-hinton-was-briefly-a-google-intern-in-2012-because-of-bureaucracy/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://techcrunch.com/2017/09/14/geoffrey-hinton-was-briefly-a-google-intern-in-2012-because-of-bureaucracy/</a></span></div></li><li id="https://www.technologyreview.com/2023/05/01/1072478/deep-learning-pioneer-geoffrey-hinton-quits-google/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.technologyreview.com/2023/05/01/1072478/deep-learning-pioneer-geoffrey-hinton-quits-google/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.technologyreview.com/2023/05/01/1072478/deep-learning-pioneer-geoffrey-hinton-quits-google/</a></span></div></li><li id="https://www.bbc.com/news/world-us-canada-65452940" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.bbc.com/news/world-us-canada-65452940" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.bbc.com/news/world-us-canada-65452940</a></span></div></li><li id="https://www.cnn.com/2023/05/01/tech/geoffrey-hinton-leaves-google-ai-fears" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cnn.com/2023/05/01/tech/geoffrey-hinton-leaves-google-ai-fears" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cnn.com/2023/05/01/tech/geoffrey-hinton-leaves-google-ai-fears</a></span></div></li><li id="https://www.sciencedirect.com/science/article/pii/S0364021385800124" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.sciencedirect.com/science/article/pii/S0364021385800124" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.sciencedirect.com/science/article/pii/S0364021385800124</a></span></div></li><li id="https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf</a></span></div></li><li id="https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0901_7" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0901_7" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0901_7</a></span></div></li><li id="https://www.semanticscholar.org/paper/A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton/a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.semanticscholar.org/paper/A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton/a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.semanticscholar.org/paper/A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton/a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657</a></span></div></li><li id="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf</a></span></div></li><li id="https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf</a></span></div></li><li id="https://link.aps.org/doi/10.1103/RevModPhys.97.030502" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://link.aps.org/doi/10.1103/RevModPhys.97.030502" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://link.aps.org/doi/10.1103/RevModPhys.97.030502</a></span></div></li><li id="https://www.ibm.com/think/topics/backpropagation" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.ibm.com/think/topics/backpropagation" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.ibm.com/think/topics/backpropagation</a></span></div></li><li id="https://www.nature.com/articles/323533a0" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nature.com/articles/323533a0" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nature.com/articles/323533a0</a></span></div></li><li id="https://www.semanticscholar.org/paper/Learning-representations-by-back-propagating-errors-Rumelhart-Hinton/052b1d8ce63b07fec3de9dbb583772d860b7c769" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.semanticscholar.org/paper/Learning-representations-by-back-propagating-errors-Rumelhart-Hinton/052b1d8ce63b07fec3de9dbb583772d860b7c769" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.semanticscholar.org/paper/Learning-representations-by-back-propagating-errors-Rumelhart-Hinton/052b1d8ce63b07fec3de9dbb583772d860b7c769</a></span></div></li><li id="https://yuxi-liu-wired.github.io/essays/posts/backstory-of-backpropagation/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://yuxi-liu-wired.github.io/essays/posts/backstory-of-backpropagation/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://yuxi-liu-wired.github.io/essays/posts/backstory-of-backpropagation/</a></span></div></li><li id="https://medium.com/syncedreview/who-invented-backpropagation-hinton-says-he-didnt-but-his-work-made-it-popular-e0854504d6d1" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://medium.com/syncedreview/who-invented-backpropagation-hinton-says-he-didnt-but-his-work-made-it-popular-e0854504d6d1" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://medium.com/syncedreview/who-invented-backpropagation-hinton-says-he-didnt-but-his-work-made-it-popular-e0854504d6d1</a></span></div></li><li id="https://www.idsia.ch/~juergen/who-invented-backpropagation.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.idsia.ch/~juergen/who-invented-backpropagation.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.idsia.ch/~juergen/who-invented-backpropagation.html</a></span></div></li><li id="https://www.reddit.com/r/mlscaling/comments/15fda1n/geoffrey_hinton_on_the_deficiencies_of/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.reddit.com/r/mlscaling/comments/15fda1n/geoffrey_hinton_on_the_deficiencies_of/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.reddit.com/r/mlscaling/comments/15fda1n/geoffrey_hinton_on_the_deficiencies_of/</a></span></div></li><li id="https://sbmi.uth.edu/blog/2024/geoffrey-hinton.htm" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://sbmi.uth.edu/blog/2024/geoffrey-hinton.htm" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://sbmi.uth.edu/blog/2024/geoffrey-hinton.htm</a></span></div></li><li id="http://neuralnetworksanddeeplearning.com/chap2.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">http://neuralnetworksanddeeplearning.com/chap2.html</a></span></div></li><li id="https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf</a></span></div></li><li id="https://pubmed.ncbi.nlm.nih.gov/16764513/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://pubmed.ncbi.nlm.nih.gov/16764513/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://pubmed.ncbi.nlm.nih.gov/16764513/</a></span></div></li><li id="https://direct.mit.edu/neco/article/18/7/1527/7065/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://direct.mit.edu/neco/article/18/7/1527/7065/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://direct.mit.edu/neco/article/18/7/1527/7065/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets</a></span></div></li><li id="https://www.semanticscholar.org/paper/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero/8978cf7574ceb35f4c3096be768c7547b28a35d0" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.semanticscholar.org/paper/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero/8978cf7574ceb35f4c3096be768c7547b28a35d0" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.semanticscholar.org/paper/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero/8978cf7574ceb35f4c3096be768c7547b28a35d0</a></span></div></li><li id="https://www.researchgate.net/publication/7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.researchgate.net/publication/7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.researchgate.net/publication/7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets</a></span></div></li><li id="https://uberty.org/wp-content/uploads/2017/05/deep-learning-history.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://uberty.org/wp-content/uploads/2017/05/deep-learning-history.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://uberty.org/wp-content/uploads/2017/05/deep-learning-history.pdf</a></span></div></li><li id="https://www.klover.ai/the-birth-of-geoffrey-hintons-deep-belief-networks-and-their-real%25E2%2580%2591world-impact/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.klover.ai/the-birth-of-geoffrey-hintons-deep-belief-networks-and-their-real%25E2%2580%2591world-impact/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.klover.ai/the-birth-of-geoffrey-hintons-deep-belief-networks-and-their-real%25E2%2580%2591world-impact/</a></span></div></li><li id="https://stats.stackexchange.com/questions/261751/why-are-deep-belief-networks-dbn-rarely-used" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://stats.stackexchange.com/questions/261751/why-are-deep-belief-networks-dbn-rarely-used" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://stats.stackexchange.com/questions/261751/why-are-deep-belief-networks-dbn-rarely-used</a></span></div></li><li id="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a></span></div></li><li id="https://www.artsci.utoronto.ca/news/neural-network-behind-geoffrey-hinton-s-nobel-prize-be-preserved-computer-history-museum" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.artsci.utoronto.ca/news/neural-network-behind-geoffrey-hinton-s-nobel-prize-be-preserved-computer-history-museum" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.artsci.utoronto.ca/news/neural-network-behind-geoffrey-hinton-s-nobel-prize-be-preserved-computer-history-museum</a></span></div></li><li id="https://www.cs.toronto.edu/~gdahl/papers/dbnPhoneRec.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cs.toronto.edu/~gdahl/papers/dbnPhoneRec.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cs.toronto.edu/~gdahl/papers/dbnPhoneRec.pdf</a></span></div></li><li id="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf</a></span></div></li><li id="https://research.google.com/pubs/archive/38131.pdf" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://research.google.com/pubs/archive/38131.pdf" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://research.google.com/pubs/archive/38131.pdf</a></span></div></li><li id="https://awards.acm.org/about/2018-turing" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://awards.acm.org/about/2018-turing" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://awards.acm.org/about/2018-turing</a></span></div></li><li id="https://informatics.ed.ac.uk/news-events/news/latest-news/nobel-prize-physics-godfather-ai-geoffrey-hinton" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://informatics.ed.ac.uk/news-events/news/latest-news/nobel-prize-physics-godfather-ai-geoffrey-hinton" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://informatics.ed.ac.uk/news-events/news/latest-news/nobel-prize-physics-godfather-ai-geoffrey-hinton</a></span></div></li><li id="https://www.nobelprize.org/prizes/physics/2024/summary/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nobelprize.org/prizes/physics/2024/summary/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nobelprize.org/prizes/physics/2024/summary/</a></span></div></li><li id="https://www.nobelprize.org/prizes/physics/2024/hinton/interview/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nobelprize.org/prizes/physics/2024/hinton/interview/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nobelprize.org/prizes/physics/2024/hinton/interview/</a></span></div></li><li id="https://www.nobelprize.org/prizes/physics/2024/hinton/speech/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.nobelprize.org/prizes/physics/2024/hinton/speech/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.nobelprize.org/prizes/physics/2024/hinton/speech/</a></span></div></li><li id="https://www.reuters.com/science/hopfield-hinton-win-2024-nobel-prize-physics-2024-10-08/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.reuters.com/science/hopfield-hinton-win-2024-nobel-prize-physics-2024-10-08/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.reuters.com/science/hopfield-hinton-win-2024-nobel-prize-physics-2024-10-08/</a></span></div></li><li id="https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai</a></span></div></li><li id="https://www.brainyquote.com/authors/geoffrey-hinton-quotes" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.brainyquote.com/authors/geoffrey-hinton-quotes" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.brainyquote.com/authors/geoffrey-hinton-quotes</a></span></div></li><li id="https://www.understandingai.org/p/why-the-deep-learning-boom-caught" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.understandingai.org/p/why-the-deep-learning-boom-caught" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.understandingai.org/p/why-the-deep-learning-boom-caught</a></span></div></li><li id="https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/</a></span></div></li><li id="https://www.cnn.com/2025/08/13/tech/ai-geoffrey-hinton" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cnn.com/2025/08/13/tech/ai-geoffrey-hinton" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cnn.com/2025/08/13/tech/ai-geoffrey-hinton</a></span></div></li><li id="https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/</a></span></div></li><li id="https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years</a></span></div></li><li id="https://mitsloan.mit.edu/ideas-made-to-matter/why-neural-net-pioneer-geoffrey-hinton-sounding-alarm-ai" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://mitsloan.mit.edu/ideas-made-to-matter/why-neural-net-pioneer-geoffrey-hinton-sounding-alarm-ai" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://mitsloan.mit.edu/ideas-made-to-matter/why-neural-net-pioneer-geoffrey-hinton-sounding-alarm-ai</a></span></div></li><li id="https://www.cbsnews.com/news/geoffrey-hinton-ai-dangers-60-minutes-transcript/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cbsnews.com/news/geoffrey-hinton-ai-dangers-60-minutes-transcript/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cbsnews.com/news/geoffrey-hinton-ai-dangers-60-minutes-transcript/</a></span></div></li><li id="https://www.cnbc.com/2025/06/17/ai-godfather-geoffrey-hinton-theres-a-chance-that-ai-could-displace-humans.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cnbc.com/2025/06/17/ai-godfather-geoffrey-hinton-theres-a-chance-that-ai-could-displace-humans.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cnbc.com/2025/06/17/ai-godfather-geoffrey-hinton-theres-a-chance-that-ai-could-displace-humans.html</a></span></div></li><li id="https://theconversation.com/does-ai-pose-an-existential-risk-we-asked-5-experts-266345" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://theconversation.com/does-ai-pose-an-existential-risk-we-asked-5-experts-266345" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://theconversation.com/does-ai-pose-an-existential-risk-we-asked-5-experts-266345</a></span></div></li><li id="https://magazine.mindplex.ai/post/geoffrey-hinton-on-ai-intelligence-and-superintelligence" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://magazine.mindplex.ai/post/geoffrey-hinton-on-ai-intelligence-and-superintelligence" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://magazine.mindplex.ai/post/geoffrey-hinton-on-ai-intelligence-and-superintelligence</a></span></div></li><li id="https://www.h3hr.com/disruption-or-displacement-what-ai-means-for-work-and-workers/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.h3hr.com/disruption-or-displacement-what-ai-means-for-work-and-workers/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.h3hr.com/disruption-or-displacement-what-ai-means-for-work-and-workers/</a></span></div></li><li id="https://www.youtube.com/watch?v=1cYHHcGsYTs" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.youtube.com/watch?v=1cYHHcGsYTs" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.youtube.com/watch?v=1cYHHcGsYTs</a></span></div></li><li id="https://dig.watch/updates/ai-job-losses-could-leave-many-workers-behind-experts-warn" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://dig.watch/updates/ai-job-losses-could-leave-many-workers-behind-experts-warn" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://dig.watch/updates/ai-job-losses-could-leave-many-workers-behind-experts-warn</a></span></div></li><li id="https://www.francescatabor.com/articles/2025/6/17/geoffrey-hintons-ai-warnings-a-blueprint-for-policy-regulation-and-innovation" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.francescatabor.com/articles/2025/6/17/geoffrey-hintons-ai-warnings-a-blueprint-for-policy-regulation-and-innovation" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.francescatabor.com/articles/2025/6/17/geoffrey-hintons-ai-warnings-a-blueprint-for-policy-regulation-and-innovation</a></span></div></li><li id="https://reactionpower.com/can-we-control-ai-insights-from-geoffrey-hinton/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://reactionpower.com/can-we-control-ai-insights-from-geoffrey-hinton/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://reactionpower.com/can-we-control-ai-insights-from-geoffrey-hinton/</a></span></div></li><li id="https://www.linkedin.com/pulse/double-edged-sword-smes-ai-warning-from-geoffrey-raam-gottimukkala-0j4nc" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.linkedin.com/pulse/double-edged-sword-smes-ai-warning-from-geoffrey-raam-gottimukkala-0j4nc" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.linkedin.com/pulse/double-edged-sword-smes-ai-warning-from-geoffrey-raam-gottimukkala-0j4nc</a></span></div></li><li id="https://www.facebook.com/groups/weirdfantasticbeautifulandodd/posts/3939159283077428/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.facebook.com/groups/weirdfantasticbeautifulandodd/posts/3939159283077428/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.facebook.com/groups/weirdfantasticbeautifulandodd/posts/3939159283077428/</a></span></div></li><li id="https://singjupost.com/ai-what-could-go-wrong-geoffrey-hinton-on-the-weekly-show-with-jon-stewart-transcript/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://singjupost.com/ai-what-could-go-wrong-geoffrey-hinton-on-the-weekly-show-with-jon-stewart-transcript/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://singjupost.com/ai-what-could-go-wrong-geoffrey-hinton-on-the-weekly-show-with-jon-stewart-transcript/</a></span></div></li><li id="https://www.webpronews.com/yann-lecun-and-geoffrey-hinton-clash-on-ai-safety-in-2025/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.webpronews.com/yann-lecun-and-geoffrey-hinton-clash-on-ai-safety-in-2025/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.webpronews.com/yann-lecun-and-geoffrey-hinton-clash-on-ai-safety-in-2025/</a></span></div></li><li id="https://www.wired.com/story/artificial-intelligence-meta-yann-lecun-interview/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.wired.com/story/artificial-intelligence-meta-yann-lecun-interview/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.wired.com/story/artificial-intelligence-meta-yann-lecun-interview/</a></span></div></li><li id="https://www.newstatesman.com/long-reads/2023/06/men-made-future-godfathers-ai-geoffrey-hinton-yann-lecun-yoshua-bengio-artificial-intelligence" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.newstatesman.com/long-reads/2023/06/men-made-future-godfathers-ai-geoffrey-hinton-yann-lecun-yoshua-bengio-artificial-intelligence" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.newstatesman.com/long-reads/2023/06/men-made-future-godfathers-ai-geoffrey-hinton-yann-lecun-yoshua-bengio-artificial-intelligence</a></span></div></li><li id="https://newrepublic.com/article/187203/ai-radiology-geoffrey-hinton-nobel-prediction" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://newrepublic.com/article/187203/ai-radiology-geoffrey-hinton-nobel-prediction" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://newrepublic.com/article/187203/ai-radiology-geoffrey-hinton-nobel-prediction</a></span></div></li><li id="https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/</a></span></div></li><li id="https://www.freethink.com/artificial-intelligence/ai-doomerism" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.freethink.com/artificial-intelligence/ai-doomerism" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.freethink.com/artificial-intelligence/ai-doomerism</a></span></div></li><li id="https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15746014/hinton-acknowledges-mistake-in-predicting-ai-replacement-of-radiologists" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15746014/hinton-acknowledges-mistake-in-predicting-ai-replacement-of-radiologists" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15746014/hinton-acknowledges-mistake-in-predicting-ai-replacement-of-radiologists</a></span></div></li><li id="https://www.stopkillerrobots.org/news/2024-nobel-laureate-in-physics-raises-concerns-about-killer-robots/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.stopkillerrobots.org/news/2024-nobel-laureate-in-physics-raises-concerns-about-killer-robots/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.stopkillerrobots.org/news/2024-nobel-laureate-in-physics-raises-concerns-about-killer-robots/</a></span></div></li><li id="https://finance.yahoo.com/news/controversy-surrounding-ai-pioneer-geoffrey-161355688.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://finance.yahoo.com/news/controversy-surrounding-ai-pioneer-geoffrey-161355688.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://finance.yahoo.com/news/controversy-surrounding-ai-pioneer-geoffrey-161355688.html</a></span></div></li><li id="https://www.wired.com/story/geoffrey-hinton-ai-chatgpt-dangers/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.wired.com/story/geoffrey-hinton-ai-chatgpt-dangers/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.wired.com/story/geoffrey-hinton-ai-chatgpt-dangers/</a></span></div></li><li id="https://systemweakness.com/geoffrey-hinton-godfather-of-ai-is-wrong-4f4ca942fe54" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://systemweakness.com/geoffrey-hinton-godfather-of-ai-is-wrong-4f4ca942fe54" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://systemweakness.com/geoffrey-hinton-godfather-of-ai-is-wrong-4f4ca942fe54</a></span></div></li><li id="https://analyticsindiamag.com/ai-features/geoffrey-hinton-its-all-in-the-family-tree/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://analyticsindiamag.com/ai-features/geoffrey-hinton-its-all-in-the-family-tree/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://analyticsindiamag.com/ai-features/geoffrey-hinton-its-all-in-the-family-tree/</a></span></div></li><li id="https://www.larrycao.com/geoffrey-hinton-family-tree-from-mount-everest-to-ai" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.larrycao.com/geoffrey-hinton-family-tree-from-mount-everest-to-ai" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.larrycao.com/geoffrey-hinton-family-tree-from-mount-everest-to-ai</a></span></div></li><li id="https://www.facebook.com/60minutes/videos/geoffrey-hintons-famous-family/217776817804742/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.facebook.com/60minutes/videos/geoffrey-hintons-famous-family/217776817804742/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.facebook.com/60minutes/videos/geoffrey-hintons-famous-family/217776817804742/</a></span></div></li><li id="https://www.aibase.com/news/2798" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.aibase.com/news/2798" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.aibase.com/news/2798</a></span></div></li><li id="https://apnews.com/article/ai-godfather-google-geoffery-hinton-fa98c6a6fddab1d7c27560f6fcbad0ad" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://apnews.com/article/ai-godfather-google-geoffery-hinton-fa98c6a6fddab1d7c27560f6fcbad0ad" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://apnews.com/article/ai-godfather-google-geoffery-hinton-fa98c6a6fddab1d7c27560f6fcbad0ad</a></span></div></li><li id="https://www.cnbc.com/2023/05/01/godfather-of-ai-leaves-google-after-a-decade-to-warn-of-dangers.html" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.cnbc.com/2023/05/01/godfather-of-ai-leaves-google-after-a-decade-to-warn-of-dangers.html" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.cnbc.com/2023/05/01/godfather-of-ai-leaves-google-after-a-decade-to-warn-of-dangers.html</a></span></div></li><li id="https://fortune.com/2025/09/06/godfather-of-ai-geoffrey-hinton-massive-unemployment-soaring-profits-capitalist-system/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://fortune.com/2025/09/06/godfather-of-ai-geoffrey-hinton-massive-unemployment-soaring-profits-capitalist-system/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://fortune.com/2025/09/06/godfather-of-ai-geoffrey-hinton-massive-unemployment-soaring-profits-capitalist-system/</a></span></div></li><li id="https://siliconangle.com/2025/10/22/geoffrey-hinton-yoshua-bengio-sign-statement-urging-suspension-agi-development/" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://siliconangle.com/2025/10/22/geoffrey-hinton-yoshua-bengio-sign-statement-urging-suspension-agi-development/" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://siliconangle.com/2025/10/22/geoffrey-hinton-yoshua-bengio-sign-statement-urging-suspension-agi-development/</a></span></div></li><li id="https://www.youtube.com/watch?v=IkdziSLYzHw" class="mb-2 grid break-inside-avoid grid-cols-[auto_1fr] gap-2 text-sm leading-relaxed [counter-increment:item] before:font-semibold before:content-[counter(item)&#x27;.&#x27;]"><div class="relative -top-[3px] overflow-hidden break-words text-[16px] [&amp;_*]:mb-0"><span class="mb-4 block break-words text-[1em] leading-7"><a href="https://www.youtube.com/watch?v=IkdziSLYzHw" target="_blank" rel="noopener noreferrer" class="break-all text-[1em] text-blue-500 hover:underline dark:text-blue-300">https://www.youtube.com/watch?v=IkdziSLYzHw</a></span></div></li></ol></div></div></div><div class="hidden min-[1400px]:block"></div></div></div><!--$--><!--/$--><div role="region" aria-label="Notifications (F8)" tabindex="-1" style="pointer-events:none"><ol tabindex="-1" class="pointer-events-none fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 max-sm:left-0 sm:bottom-0 sm:right-0 sm:top-auto sm:max-w-[420px] sm:flex-col pl-16 pr-2 pt-16 sm:px-4"></ol></div><script type="application/json" id="server-client-data-experimentation">{"status":"uninitialized"}</script><script src="/_next/static/chunks/webpack-e121ed42680f327e.js" nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh" id="_R_" async=""></script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">(self.__next_f=self.__next_f||[]).push([0])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[91363,[],\"\"]\n4:I[23775,[],\"\"]\n5:I[57654,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"3699\",\"static/chunks/app/page/%5Bslug%5D/layout-55a344716dd57c44.js\"],\"PageHeaderProvider\"]\n6:I[17618,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"3699\",\"static/chunks/app/page/%5Bslug%5D/layout-55a344716dd57c44.js\"],\"HeaderContent\"]\n7:I[25529,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"6751\",\"static/chunks/app/page/%5Bslug%5D/not-found-69a3edc7db5749d6.js\"],\"default\"]\n9:I[6666,[],\"OutletBoundary\"]\nb:I[80415,[],\"AsyncMetadataOutlet\"]\nd:I[6666,[],\"ViewportBoundary\"]\nf:I[6666,[],\"MetadataBoundary\"]\n10:\"$Sreact.suspense\"\n12:I[95909,[\"4219\",\"static/chunks/app/global-error-4d07d20223cd4b4c.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"13:I[51498,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"ConstantsProvider\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"14:I[91073,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"15:I[38642,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"16:I[99648,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"17:I[78825,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"18:I[8550,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"MixpanelProvider\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"19:I[12290,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"MobileTocProvider\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"1a:I[53947,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"NuqsAdapter\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"1b:I[91873,[\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8039\",\"static/chunks/app/error-4a29e9399afba038.js\"],\"default\"]\n1c:I[5091,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"7618\",\"static/chunks/7618-43536a8fb0dd3bfe.js\",\"4345\",\"static/chunks/app/not-found-dd95690acf732f18.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"1d:I[16091,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"927\",\"static/chunks/927-34e2a6da3e15e26b.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"2660\",\"static/chunks/2660-d983a7f287e89f18.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"3655\",\"static/chunks/3655-6717081f7512305a.js\",\"8945\",\"static/chunks/8945-e4e3cf487f5e27c7.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"2225\",\"static/chunks/2225-454cf9f44775e7ce.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"7177\",\"static/chunks/app/layout-226f2bd71acf9f9e.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,":HL[\"/_next/static/media/1f2316909698f815.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/3d4419af2cf8609b.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/4dec29efcaeb336c.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/74452ea3ef0f9101.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/904ef0a86fe32a00.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/d886a03bcda7ad8f.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/e1447589d6f59c4b.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/f5a90156f8995c8c.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/62c4caba71dfda84.css\",\"style\",{\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}]\n:HL[\"/_next/static/css/eb3d87f98fe1565f.css\",\"style\",{\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}]\n:HL[\"/_next/static/css/1b5e561215938d4d.css\",\"style\",{\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}]\n:HL[\"/_next/static/css/0227d069a630d414.css\",\"style\",{\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}]\n:HL[\"/_next/static/css/f87fff2ab93d05a7.css\",\"style\",{\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"0:{\"P\":null,\"b\":\"BpM29AX4fmgcUxZ_6t0le\",\"p\":\"\",\"c\":[\"\",\"page\",\"Geoffrey_Hinton\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"page\",{\"children\":[[\"slug\",\"Geoffrey_Hinton\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/62c4caba71dfda84.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/eb3d87f98fe1565f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1b5e561215938d4d.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/0227d069a630d414.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}]],\"$L2\"]}],{\"children\":[\"page\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"Geoffrey_Hinton\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L5\",null,{\"children\":[[\"$\",\"$L6\",null,{\"maxWidth\":\"full\",\"mobileOptions\":{\"right\":{\"showFixedIssues\":true,\"showThemeSwitcher\":true,\"showSearch\":true,\"showTableOfContents\":true}}}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"$L7\",null,{}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L8\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/f87fff2ab93d05a7.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\"}]],[\"$\",\"$L9\",null,{\"children\":[\"$La\",[\"$\",\"$Lb\",null,{\"promise\":\"$@c\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$Lf\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$10\",null,{\"fallback\":null,\"children\":\"$L11\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$12\",[]],\"s\":false,\"S\":false}\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"2:[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"bg-surface-base antialiased\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"title\",null,{\"children\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"description\",\"content\":\"Grokipedia is an open source, comprehensive collection of all knowledge.\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/x-icon\",\"href\":\"/favicon.ico\",\"sizes\":\"48x48\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/images/icon-dark.png\",\"media\":\"(prefers-color-scheme: light)\",\"type\":\"image/png\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/images/icon-light.png\",\"media\":\"(prefers-color-scheme: dark)\",\"type\":\"image/png\"}],[\"$\",\"link\",null,{\"rel\":\"apple-touch-icon\",\"href\":\"/icon-192x192.png\"}],[\"$\",\"link\",null,{\"rel\":\"manifest\",\"href\":\"/manifest.webmanifest\"}],[\"$\",\"meta\",null,{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",null,{\"name\":\"googlebot\",\"content\":\"index, follow, max-snippet:-1\"}],[\"$\",\"meta\",null,{\"property\":\"og:title\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"property\":\"og:description\",\"content\":\"Grokipedia is an open source, comprehensive collection of all knowledge.\"}],[\"$\",\"meta\",null,{\"property\":\"og:url\",\"content\":\"https://grokipedia.com\"}],[\"$\",\"meta\",null,{\"property\":\"og:site_name\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",null,{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",null,{\"property\":\"og:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}],[\"$\",\"meta\",null,{\"property\":\"og:image:width\",\"content\":\"512\"}],[\"$\",\"meta\",null,{\"property\":\"og:image:height\",\"content\":\"512\"}],[\"$\",\"meta\",null,{\"property\":\"og:image:alt\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:creator\",\"content\":\"@Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:title\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:description\",\"content\":\"Grokipedia is an open source, comprehensive collection of all knowledge.\"}],[\"$\",\"meta\",null,{\"name\":\"twitter:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}]]}],[\"$\",\"body\",null,{\"className\":\"flex h-[100svh] w-full flex-col __variable_13c637 __variable_8a0ba0 __variable_779740 __variable_2484fd __variable_525cc3 __variable_13486b\",\"children\":[[\"$\",\"$L13\",null,{\"children\":[\"$\",\"$L14\",null,{\"children\":[\"$\",\"$L15\",null,{\"defaultTheme\":\"dark\",\"nonce\":\"YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh\",\"children\":[\"$\",\"$L16\",null,{\"children\":[\"$\",\"$L17\",null,{\"children\":[\"$\",\"$L18\",null,{\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"$L1a\",null,{\"children\":[[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$1b\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"$L1c\",null,{}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"$L1d\",null,{}]]}]}]}]}]}]}]}]}],[\"$\",\"script\",null,{\"type\":\"application/json\",\"id\":\"server-client-data-experimentation\",\"children\":\"{\\\"status\\\":\\\"uninitialized\\\"}\"}]]}]]}]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, interactive-widget=resizes-content\"}]]\na:null\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"1e:I[42712,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"HydrationBoundary\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"21:I[6367,[],\"IconMark\"]\n1f:Td7fc,"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"# Geoffrey Hinton\n\n![Geoffrey E. Hinton, 2024 Nobel Prize Laureate in Physics](./_assets_/Geoffrey_E._Hinton%252C_2024_Nobel_Prize_Laureate_in_Physics_\\(cropped1\\))\nGeoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning.[](https://www.nobelprize.org/prizes/physics/2024/hinton/facts/)[](https://www.cs.utoronto.ca/~hinton/bio.html)\nHinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978.[](https://www.cs.utoronto.ca/~hinton/bio.html)\nAs University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the Boltzmann machine, a neural network capable of autonomously identifying patterns in data through unsupervised learning.[](https://www.nobelprize.org/prizes/physics/2024/press-release/)[](https://www.nobelprize.org/prizes/physics/2024/hinton/facts/)\nIn 2024, Hinton shared the Nobel Prize in Physics with John Hopfield for foundational discoveries and inventions that enable machine learning with artificial neural networks.[](https://www.nobelprize.org/prizes/physics/2024/press-release/)\nHis work laid the groundwork for modern AI systems by demonstrating how networks could learn hierarchical representations of data, influencing breakthroughs in image recognition and natural language processing.[](https://www.nobelprize.org/prizes/physics/2024/hinton/facts/)[](https://www.nobelprize.org/prizes/physics/2024/press-release/)\nAfter a decade at Google, where he contributed to advancing deep learning technologies, Hinton resigned in 2023 to discuss potential existential risks from superintelligent AI without corporate constraints.[](http://www.cs.utoronto.ca/~hinton/)[](https://www.reuters.com/technology/google-ai-pioneer-says-he-quit-speak-freely-about-technologys-dangers-2023-05-02/)\n\n## Early Life and Education\n\n### Family Background and Early Influences\n\nGeoffrey Everest Hinton was born on December 6, 1947, in Wimbledon, London, England, to Howard Everest Hinton, an eminent entomologist and professor at the University of Bristol, and Margaret Clark, a schoolteacher.[](https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/)[](https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai) Howard Hinton, a Fellow of the Royal Society, specialized in insect biology and maintained a politically radical outlook shaped by his upbringing in Mexico during the Mexican Revolution and his Berkeley education, which included Stalinist leanings that influenced family dynamics, such as prohibiting Geoffrey from pursuing biology due to opposition to genetic determinism.[](https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai)[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/)\n\nHinton descends from a lineage of intellectuals, with his great-great-grandfather George Boole (1815â€“1864), the mathematician who developed Boolean algebra foundational to modern computing, married to Mary Everest Boole, niece of George Everest, the surveyor after whom Mount Everest is namedâ€”reflected in Hinton's middle name.[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/)[](https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai) Other notable forebears include great-grandfather Charles Howard Hinton (1853â€“1907), a mathematician known for work on higher-dimensional geometry and science fiction, and great-great-grandfather James Hinton (1822â€“1875), a surgeon and author.[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/) Extended relatives encompass great-uncle Sebastian Hinton, inventor of the jungle gym, and cousin Joan Hinton (1921â€“2010), a nuclear physicist who contributed to the Manhattan Project before relocating to China as a dairy farmer.[](https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai)[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/)\n\nThe family's scientific heritage imposed high expectations, with Hinton's father emphasizing rigorous intellectual effort amid a household filled with siblings, exotic animals like vipers, turtles, and lizards kept in the garage, fostering an early affinity for biological observation despite ideological constraints.[](https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai)[](https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/) At age four, Hinton experienced a formative curiosity when puzzled by a penny's apparent motion on a moving bus, sparking lifelong inquiry into underlying mechanisms of perception and complex systems.[](https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/) In his teens, a high school friend's notion of the brain functioning like a hologram ignited interest in neural processes, steering him toward cognitive science and artificial intelligence as avenues to model human-like intuition in machines, influenced by the family's tradition of probing reality's structures.[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/)[](https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai)\n\n### Academic Training\n\nHinton earned a Bachelor of Arts degree in experimental psychology from King's College, Cambridge, in 1970, after initially exploring subjects including physiology, philosophy, and physics.[](https://www.cs.toronto.edu/~hinton/bio.html)[](https://www.britannica.com/biography/Geoffrey-Hinton) Following graduation, he spent a year apprenticed in carpentry before pursuing graduate studies.[](https://amturing.acm.org/award_winners/hinton_4791679.cfm)\n\nIn 1972, Hinton began doctoral research in artificial intelligence at the University of Edinburgh, completing his PhD in 1978 with a thesis titled *Relaxation and its Role in Vision*, which examined mechanisms for interpreting imperfect visual data through consistent combinations of features.[](https://www.cs.toronto.edu/~hinton/bio.html)[](https://era.ed.ac.uk/handle/1842/8121) Despite initial discouragement from professors regarding his interest in neural networks, he persisted in developing ideas connecting psychological processes to computational models.[](https://www.britannica.com/biography/Geoffrey-Hinton) His work at Edinburgh laid early groundwork for his lifelong focus on machine learning architectures inspired by brain function.[](https://www.frontiersofknowledgeawards-fbbva.es/galardonados/geoffrey-hinton-2/)\n\n## Professional Career\n\n### Early Academic Positions\n\nFollowing his PhD in artificial intelligence from the University of Edinburgh in 1978, Hinton conducted postdoctoral research at the University of Sussex as a post-doctoral researcher in the late 1970s, where he began developing early theories on neural networks.[](https://www.sussex.ac.uk/broadcast/read/65834) He subsequently joined the University of California, San Diego as a Sloan Foundation postdoctoral researcher and visiting scholar from October 1978 to September 1980, collaborating with cognitive psychologists on neural network models of human cognition.[](https://amturing.acm.org/award_winners/hinton_4791679.cfm)[](https://discover.research.utoronto.ca/26059-geoffrey-e-hinton) Hinton briefly returned to UCSD in spring 1982 as a visiting assistant professor.[](https://today.ucsd.edu/story/nobel-prize-winner-godfather-of-ai-geoffrey-hinton-has-uc-san-diego-roots)\n\nIn 1982, Hinton accepted a faculty position in the Computer Science Department at Carnegie Mellon University, serving for five years until 1987.[](https://www.nasonline.org/directory-entry/geoffrey-e-hinton-c2tmwf/) During this period, he contributed to foundational work in connectionist learning procedures, including collaborations that advanced understanding of backpropagation in multilayer neural networks.[](https://files.eric.ed.gov/fulltext/ED294889.pdf) These early positions provided Hinton with opportunities to explore unsupervised learning and Boltzmann machines amid limited funding for neural network research in the post-1970s \"AI winter.\"[](https://www.nobelprize.org/events/nobel-prize-dialogue/madrid-2025/panellists/geoffrey-hinton/)\n\n### Career at the University of Toronto\n\nHinton joined the Department of Computer Science at the University of Toronto in 1987 as a professor, shortly after becoming a fellow of the Canadian Institute for Advanced Research (CIFAR), which supported his relocation and research in neural networks.[](https://www.artsci.utoronto.ca/news/geoffrey-hinton-wins-nobel-prize-physics)[](https://cifar.ca/publications-reports/reach/geoffrey-hinton/) There, he built a influential research group that advanced machine learning techniques, including the creation of the CIFAR-10 and CIFAR-100 datasets in collaboration with students Alex Krizhevsky and Vinod Nair, comprising 60,000 32x32 color images across 10 and 100 classes respectively for training convolutional neural networks.[](https://www.cs.toronto.edu/~kriz/cifar.html)\n\nFrom 1998 to 2001, Hinton took a leave of absence to establish and direct the Gatsby Computational Neuroscience Unit at University College London, after which he returned to his position at Toronto.[](https://vectorinstitute.ai/team/geoffrey-hinton/) Upon return, he directed CIFAR's \"Neural Computation and Adaptive Perception\" program from 2004 to 2013, coordinating interdisciplinary efforts across institutions to explore hierarchical learning models and perceptual systems.[](https://www.cs.toronto.edu/~hinton/bio.html) Under his leadership, the Toronto group produced foundational work in deep learning, such as efficient pre-training methods for multilayer networks, which laid groundwork for later applications in object recognition.[](https://www.cs.toronto.edu/~hinton/bio.html)\n\nIn 2017, Hinton co-founded the Vector Institute for Artificial Intelligence in Toronto, an independent research organization affiliated with the University of Toronto, and assumed the role of Chief Scientific Advisor, guiding its focus on scalable AI algorithms and ethical deployment.[](https://vectorinstitute.ai/team/geoffrey-hinton/) This initiative bolstered Toronto's status as a global AI hub, attracting talent and funding while integrating with university programs. He continued as a full-time faculty member until transitioning to University Professor Emeritus status, maintaining an active presence through supervision of PhD students and public lectures.[](https://www.cs.toronto.edu/~hinton/)[](https://scholar.google.com/citations?user=JicYPdAAAAAJ\u0026hl=en)\n\n### Industry Roles and Google Involvement\n\nIn 2012, Hinton co-founded DNNresearch Inc., a startup focused on advancing deep neural networks for applications in speech and image recognition, stemming from his academic work at the University of Toronto.[](https://media.utoronto.ca/media-releases/u-of-t-neural-networks-start-up-acquired-by-google/) [](https://techcrunch.com/2013/03/12/google-scoops-up-neural-networks-startup-dnnresearch-to-boost-its-voice-and-image-search-tech/)\n\nGoogle acquired DNNresearch in March 2013 for an undisclosed sum, integrating its three-person teamâ€”including Hinton and two of his studentsâ€”into the company's research efforts on machine learning.[](https://www.wired.com/2013/03/google-hinton/) [](https://www.cbc.ca/news/science/google-buys-university-of-toronto-startup-1.1373641) Following the acquisition, Hinton joined Google as a part-time employee, serving as Vice President and Engineering Fellow, while continuing his faculty position at the University of Toronto.[](https://time.com/collection/time100-ai/6309026/geoffrey-hinton/) [](https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning) At Google, he contributed to deep learning initiatives, including improvements in voice recognition, image tagging, and neural network applications for search technologies, helping to scale these methods across Google's products.[](https://www.forbes.com/sites/peterhigh/2016/06/20/deep-learning-pioneer-geoff-hinton-helps-shape-googles-drive-to-put-ai-everywhere/) [](https://sites.google.com/site/jobsandrobots/more/people/geoffrey-hinton-section/meet-geoffrey-hinton-the-man-google-hired-to-make-ai-a-reality)\n\nHinton's tenure at Google, which lasted over a decade, involved bridging academic research with industrial deployment, notably during the rapid expansion of AI capabilities in the mid-2010s.[](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) Prior to the formal acquisition, bureaucratic constraints led to a brief period in 2012 where Hinton was technically classified as a Google intern while serving as a visiting researcher.[](https://techcrunch.com/2017/09/14/geoffrey-hinton-was-briefly-a-google-intern-in-2012-because-of-bureaucracy/)\n\nHinton resigned from Google in late April 2023, effective just before public announcements in early May, citing a desire to speak freely on the risks of artificial intelligence without corporate constraints.[](https://www.technologyreview.com/2023/05/01/1072478/deep-learning-pioneer-geoffrey-hinton-quits-google/) [](https://www.bbc.com/news/world-us-canada-65452940) His departure highlighted tensions between accelerating AI development and existential concerns, though he affirmed Google's responsible approach during his time there.[](https://www.cnn.com/2023/05/01/tech/geoffrey-hinton-leaves-google-ai-fears) No other significant industry roles preceded his Google involvement, as his career prior to 2012 was predominantly academic.[](https://time.com/collection/time100-ai/6309026/geoffrey-hinton/)\n\n## Key Research Contributions\n\n### Boltzmann Machines and Unsupervised Learning\n\nIn 1985, Geoffrey Hinton, along with David Ackley and Terrence Sejnowski, introduced the Boltzmann machine, a stochastic neural network model consisting of symmetrically connected binary units that operate according to a probabilistic framework inspired by statistical mechanics.[](https://www.sciencedirect.com/science/article/pii/S0364021385800124) The model's units update states asynchronously using a Gibbs sampling-like process to sample from an energy-based probability distribution, where the energy function is defined by connection weights and biases, enabling the network to reach equilibrium states representing low-energy configurations.[](https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf) This architecture was designed primarily for unsupervised learning tasks, such as constraint satisfaction and pattern completion, by adjusting weights to maximize the likelihood of observed data through a gradient-based rule that contrasts positive-phase activations (clamped to data) with negative-phase activations (free-running).[](https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0901_7)\n\nThe learning algorithm for Boltzmann machines relies on minimizing the Kullback-Leibler divergence between the model's distribution and the data distribution, but practical implementation faces computational challenges due to the need to compute expectations over all possible states, which scales exponentially with network size.[](https://www.semanticscholar.org/paper/A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton/a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657) Hinton's contributions emphasized the machine's ability to discover distributed representationsâ€”probabilistic encodings where features are represented across multiple units rather than localizedâ€”allowing for robust generalization in unsupervised settings without explicit labels.[](https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf) Early applications demonstrated the model's capacity for tasks like learning internal representations of patterns, such as vowel discrimination from acoustic inputs, where the network self-organizes to capture underlying statistical structures in data.\n\nTo address training inefficiencies in full Boltzmann machines, Hinton later advanced restricted Boltzmann machines (RBMs), which impose a bipartite structure separating visible and hidden units with no intra-layer connections, rendering exact inference tractable via alternating Gibbs sampling.[](https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf) In 2002, Hinton developed contrastive divergence, an approximation method that performs limited MCMC steps starting from data-driven states to estimate gradients efficiently, reducing computational cost from intractable full sampling while converging to useful representations for unsupervised pretraining.[](https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf) RBMs excel in unsupervised learning by modeling joint distributions over inputs, enabling tasks like dimensionality reductionâ€”compressing high-dimensional data into lower-dimensional hidden featuresâ€”and generative sampling, where hidden units capture latent variables driving observed variability.[](https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf)\n\nHinton's work on these models underscored their role in unsupervised feature learning, where layers of RBMs can be stacked greedily: training one layer to reconstruct inputs via hidden representations, then using those as inputs for the next, fostering hierarchical abstractions without supervision.[](https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf) Empirical evaluations showed RBMs outperforming alternatives like principal component analysis in capturing nonlinear manifolds in datasets such as natural images, due to their probabilistic handling of dependencies.[](https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf) This foundation proved causal in enabling scalable unsupervised learning, as the models' energy minimization parallels physical annealing, promoting exploration of solution spaces for complex, unlabeled data patterns.[](https://link.aps.org/doi/10.1103/RevModPhys.97.030502)\n\n### Backpropagation Algorithm\n\nThe backpropagation algorithm computes the gradient of the loss function with respect to the weights of a neural network by applying the chain rule in a reverse pass from output to input layers, enabling efficient supervised training of multi-layer networks.[](https://www.ibm.com/think/topics/backpropagation) This method addresses the challenge of credit assignment in hidden layers, where errors are propagated backward to adjust weights proportionally to their contribution to the observed discrepancy between predicted and actual outputs.[](https://www.nature.com/articles/323533a0)\n\nGeoffrey Hinton co-authored the seminal 1986 paper \"Learning Representations by Back-Propagating Errors\" with David E. Rumelhart and Ronald J. Williams, published in *Nature* on October 9, 1986, which formalized and demonstrated backpropagation's application to multi-layer feedforward networks.[](https://www.nature.com/articles/323533a0) The paper provided mathematical derivations, simulations showing convergence on tasks like encoding/decoding patterns and learning logical operations (e.g., exclusive-or), and emphasized its role in discovering useful internal representations without explicit programming.[](https://www.semanticscholar.org/paper/Learning-representations-by-back-propagating-errors-Rumelhart-Hinton/052b1d8ce63b07fec3de9dbb583772d860b7c769) Hinton's involvement stemmed from his work in the Parallel Distributed Processing (PDP) research group, where he collaborated on connectionist models; initially skeptical of gradient-based methods due to concerns over biological implausibility and scaling issues, he adopted backpropagation after demonstrations of its effectiveness on non-trivial problems.[](https://yuxi-liu-wired.github.io/essays/posts/backstory-of-backpropagation/)\n\nAlthough precursors existedâ€”such as Paul Werbos's 1974 dissertation outlining similar gradient computations for dynamic systems and Seppo Linnainmaa's 1970 work on reverse-mode automatic differentiationâ€”the 1986 paper by Rumelhart, Hinton, and Williams popularized the algorithm within the AI community by making it computationally tractable for practical neural architectures and countering skepticism from symbolic AI paradigms.[](https://medium.com/syncedreview/who-invented-backpropagation-hinton-says-he-didnt-but-his-work-made-it-popular-e0854504d6d1)[](https://www.idsia.ch/~juergen/who-invented-backpropagation.html) Hinton has stated that he did not invent backpropagation but credited Rumelhart with independently developing it for neural contexts after earlier formulations in other fields, noting its prior obscurity limited adoption until their accessible presentation with empirical examples.[](https://medium.com/syncedreview/who-invented-backpropagation-hinton-says-he-didnt-but-his-work-made-it-popular-e0854504d6d1)\n\nThis contribution laid groundwork for Hinton's subsequent research, including its integration with Boltzmann machines for hybrid learning and later deep architectures, though he later critiqued backpropagation's limitations, such as poor scaling for large tasks and reliance on non-local computations atypical of biological learning.[](https://www.reddit.com/r/mlscaling/comments/15fda1n/geoffrey_hinton_on_the_deficiencies_of/)[](https://sbmi.uth.edu/blog/2024/geoffrey-hinton.htm) The algorithm's efficiencyâ€”requiring only a single forward and backward pass per training exampleâ€”proved pivotal in overcoming the \"vanishing gradient\" challenges in deeper networks when combined with techniques like rectified linear units in the 2000s.[](http://neuralnetworksanddeeplearning.com/chap2.html)\n\n### Deep Belief Networks and the Revival of Deep Learning\n\nIn 2006, Geoffrey Hinton, Simon Osindero, and Yee-Whye Teh introduced deep belief networks (DBNs) in their paper \"A Fast Learning Algorithm for Deep Belief Nets,\" published in *Neural Computation*.[](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf) DBNs consist of a stack of restricted Boltzmann machines (RBMs), where each layer learns a probabilistic representation of the data from the layer below through unsupervised training.[](https://pubmed.ncbi.nlm.nih.gov/16764513/) The model uses a greedy, layer-by-layer algorithm: the first layer is trained as a single RBM on input data, subsequent layers treat activations from the previous layer as inputs, and the top two layers form an undirected associative memory to approximate the posterior distribution efficiently.[](https://direct.mit.edu/neco/article/18/7/1527/7065/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets) This structure allows DBNs to perform generative modeling while enabling discriminative tasks via fine-tuning with backpropagation on labeled data.[](https://www.semanticscholar.org/paper/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero/8978cf7574ceb35f4c3096be768c7547b28a35d0)\n\nThe key innovation addressed longstanding difficulties in training deep networks, including vanishing gradients and poor initialization, by initializing weights through unsupervised pre-training rather than random values.[](https://www.researchgate.net/publication/7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets) Experiments in the 2006 paper demonstrated DBNs achieving 1.25% error on the MNIST handwritten digit dataset after greedy pre-training and supervised fine-tuning, surpassing prior state-of-the-art results like support vector machines (1.4% error) without relying heavily on labeled data initially.[](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf) On natural image patches, DBNs learned hierarchical features resembling simple and complex cells in visual cortex, such as edge detectors in lower layers and more abstract patterns higher up.[](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)\n\nDBNs revived deep learning by providing empirical evidence that deep architectures could generalize better than shallow ones on unsupervised and supervised tasks, countering decades of skepticism following the 1980s AI winter.[](https://uberty.org/wp-content/uploads/2017/05/deep-learning-history.pdf) This layer-wise pre-training technique influenced subsequent methods, including those in convolutional networks, and catalyzed a surge in research; Hinton's paper garnered over 23,000 citations by 2024, reflecting its foundational role.[](https://scholar.google.com/citations?user=JicYPdAAAAAJ\u0026hl=en) By enabling scalable training of networks with many hidden layers, DBNs laid groundwork for breakthroughs like deep convolutional nets in image recognition and recurrent nets in speech processing, shifting AI toward data-driven, end-to-end learning paradigms.[](https://www.klover.ai/the-birth-of-geoffrey-hintons-deep-belief-networks-and-their-real%25E2%2580%2591world-impact/)\n\n### Applications in Speech and Image Recognition\n\nHinton's deep belief networks (DBNs), introduced in 2006, marked a pivotal advancement for image recognition by enabling unsupervised pre-training of multi-layer architectures, which addressed vanishing gradient issues in deep networks. Applied to the MNIST dataset of 60,000 handwritten digits, a DBN with three hidden layers achieved a classification error rate of 1.25% after fine-tuning with backpropagation, outperforming prior shallow networks and kernel methods like support vector machines that typically exceeded 1.4% error.[](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)[](https://stats.stackexchange.com/questions/261751/why-are-deep-belief-networks-dbn-rarely-used)\n\nThis foundation influenced subsequent vision breakthroughs from Hinton's Toronto lab. In 2012, his students Alex Krizhevsky and Ilya Sutskever, under Hinton's supervision, developed AlexNetâ€”a deep convolutional neural network trained on GPUsâ€”that secured first place in the ImageNet Large Scale Visual Recognition Challenge. AlexNet classified 1.2 million high-resolution images across 1,000 categories with a top-5 error rate of 15.3%, halving the previous best of 26% and igniting the deep learning revolution in computer vision by demonstrating scalable feature learning from raw pixels.[](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)[](https://www.artsci.utoronto.ca/news/neural-network-behind-geoffrey-hinton-s-nobel-prize-be-preserved-computer-history-museum)\n\nIn speech recognition, Hinton's group extended DBNs to acoustic modeling, shifting from traditional Gaussian mixture model-hidden Markov model (GMM-HMM) hybrids to end-to-end neural approaches. In 2009, they deployed DBNs for phone recognition on the TIMIT corpus, using generative pre-training on filter-bank features followed by discriminative fine-tuning, which reduced phone error rates below GMM baselines by modeling spectral variabilities more effectively.[](https://www.cs.toronto.edu/~gdahl/papers/dbnPhoneRec.pdf)[](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf)\n\nBy 2012, Hinton co-authored findings from multiple groups showing deep neural networks (DNNs) achieved a 20.7% phone error rate on TIMIT with nine-layer models and yielded relative word error rate reductions of up to 33% on challenging corpora like Switchboard, prompting industry adoptionâ€”such as in Google's voice searchâ€”where DNNs replaced GMMs as the standard for large-vocabulary continuous speech recognition.[](https://research.google.com/pubs/archive/38131.pdf) These results underscored Hinton's causal insight that hierarchical representations learned from data outperform hand-engineered features, revolutionizing both domains through empirical validation on benchmarks.[](https://vectorinstitute.ai/team/geoffrey-hinton/)\n\n## Awards and Recognition\n\n### Major Honors and Prizes\n\nHinton was awarded the A.M. Turing Award in 2018, jointly with Yoshua Bengio and Yann LeCun, for conceptual and engineering breakthroughs enabling deep neural networks to become the dominant technology in artificial intelligence.[](https://awards.acm.org/about/2018-turing) The prize, often called the \"Nobel Prize of computing,\" recognized their work on backpropagation and convolutional neural networks that powered advancements in image, speech, and language recognition.[](https://awards.acm.org/about/2018-turing)\n\nIn 2001, he received the David E. Rumelhart Prize, the first recipient of this award from the Cognitive Science Society, for significant contributions to the formal analysis of human cognition.[](https://informatics.ed.ac.uk/news-events/news/latest-news/nobel-prize-physics-godfather-ai-geoffrey-hinton) He also earned the IJCAI Award for Research Excellence in 2005 from the International Joint Conferences on Artificial Intelligence for lifetime contributions to AI research.[](https://informatics.ed.ac.uk/news-events/news/latest-news/nobel-prize-physics-godfather-ai-geoffrey-hinton)\n\nHinton was granted the Killam Prize for Engineering in 2012 by the Canada Council for the Arts, honoring his pioneering role in neural network research and its applications.[](https://informatics.ed.ac.uk/news-events/news/latest-news/nobel-prize-physics-godfather-ai-geoffrey-hinton) In 2019, he received the Honda Prize from the Honda Foundation for his work on deep learning algorithms that revolutionized pattern recognition in machines.[](https://amturing.acm.org/award_winners/hinton_4791679.cfm)\n\nFurther recognition came with the Dickson Prize in Science from Carnegie Mellon University in 2021 for foundational contributions to machine learning.[](https://amturing.acm.org/award_winners/hinton_4791679.cfm) In 2022, Hinton shared the Princess of Asturias Award for Technical and Scientific Research with Bengio and LeCun, acknowledging their impact on AI development.[](https://amturing.acm.org/award_winners/hinton_4791679.cfm)\n\n| Year | Award | Shared With | Citation |\n|------|--------|-------------|----------|\n| 2001 | David E. Rumelhart Prize | None | Cognitive Science Society |\n| 2005 | IJCAI Award for Research Excellence | None | International Joint Conferences on AI |\n| 2012 | Killam Prize for Engineering | None | Canada Council for the Arts |\n| 2018 | A.M. Turing Award | Yoshua Bengio, Yann LeCun | ACM |\n| 2019 | Honda Prize | None | Honda Foundation |\n| 2021 | Dickson Prize in Science | None | Carnegie Mellon University |\n| 2022 | Princess of Asturias Award | Yoshua Bengio, Yann LeCun | Princess of Asturias Foundation |\n\n### Nobel Prize in Physics (2024)\n\n![Geoffrey Hinton, 2024 Nobel Laureate in Physics](./_assets_/Geoffrey_E._Hinton%252C_2024_Nobel_Prize_Laureate_in_Physics_\\(cropped1\\))\nOn October 8, 2024, the Royal Swedish Academy of Sciences awarded the Nobel Prize in Physics jointly to John J. Hopfield and Geoffrey E. Hinton for foundational discoveries and inventions enabling machine learning with artificial neural networks.[](https://www.nobelprize.org/prizes/physics/2024/press-release/) The prize recognized Hopfield's development of Hopfield networks, which use statistical physics to store and reconstruct patterns akin to associative memory, and Hinton's creation of the Boltzmann machine, an unsupervised learning algorithm that autonomously identifies properties in data through energy-based models derived from statistical mechanics.[](https://www.nobelprize.org/prizes/physics/2024/summary/) These contributions bridged physics and computation, providing tools for neural networks to process complex, unstructured data without explicit programming.[](https://www.nobelprize.org/prizes/physics/2024/press-release/)\n\nHinton's work extended to practical advancements, including efficient training of multi-layer networks via backpropagation and the introduction of deep belief networks, which revived interest in deep learning by demonstrating scalable pattern recognition for applications like image classification and speech processing.[](https://www.nobelprize.org/prizes/physics/2024/hinton/facts/) The Nobel committee highlighted how these methods underpin modern artificial intelligence systems, capable of approximating arbitrary functions and learning from vast datasets, fundamentally altering computational approaches to complex problems. The award, valued at 11 million Swedish kronor to be shared equally between the laureates, underscored the physical principles underlying neural network dynamics, despite the field's roots in computer science.[](https://www.nobelprize.org/prizes/physics/2024/press-release/)\n\nFollowing the announcement, Hinton expressed concerns about AI development outpacing safety measures, advocating for increased research into mitigating risks from superintelligent systems in interviews and speeches.[](https://www.nobelprize.org/prizes/physics/2024/hinton/interview/) He noted in his Nobel banquet speech the potential for AI to engineer novel pathogens or autonomous weapons, emphasizing existential threats while affirming the technology's transformative potential.[](https://www.nobelprize.org/prizes/physics/2024/hinton/speech/) This perspective, voiced after his 2023 departure from Google to speak freely on AI hazards, aligned with his long-standing warnings about unintended consequences of rapid scaling in neural architectures.[](https://www.reuters.com/science/hopfield-hinton-win-2024-nobel-prize-physics-2024-10-08/)\n\n## Public Positions on AI\n\n### Evolution of Views on AI Capabilities\n\nIn the 1970s and 1980s, Geoffrey Hinton pursued research on neural networks at a time when the approach was largely discredited following early failures like the Perceptron, with his PhD supervisor advising against it in favor of symbolic AI methods. Hinton maintained that artificial intelligence required computation mimicking the human brain's pattern-learning mechanisms, rejecting rule-based systems as insufficient for achieving general intelligence.[](https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai)[](https://www.brainyquote.com/authors/geoffrey-hinton-quotes) Despite AI winters in the late 1980s and 1990s, when funding and interest waned due to perceived limitations in scaling neural networks, Hinton persisted, developing techniques like backpropagation and Boltzmann machines, convinced that connectionist models could eventually demonstrate human-like learning capabilities through unsupervised methods.[](https://www.understandingai.org/p/why-the-deep-learning-boom-caught)[](https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/)\n\nBy the early 2000s, Hinton's work on deep belief networks in 2006 contributed to the revival of deep learning, bolstered by computational advances like GPUs and large datasets, which validated neural networks' potential for tasks such as image and speech recognition. He viewed these as steps toward scalable intelligence but estimated timelines for artificial general intelligence (AGI) at 30 to 50 years, emphasizing gradual progress rather than imminent breakthroughs.[](https://www.understandingai.org/p/why-the-deep-learning-boom-caught)[](https://www.cnn.com/2025/08/13/tech/ai-geoffrey-hinton) This period reflected his sustained optimism in neural architectures' ability to handle complex, real-world data patterns, contrasting with ongoing skepticism from symbolic AI proponents.\n\nHinton's assessment shifted markedly after 2022, with the rapid capabilities of large language models like GPT-4 surprising him by demonstrating emergent reasoning and understanding beyond statistical prediction, prompting him to revise AGI timelines to 5 to 20 years and superintelligenceâ€”AI exceeding human intellect across domainsâ€”even sooner. In 2023 interviews, he noted that digital intelligence's advantages in speed, scalability, and error-free copying outpace biological evolution, enabling exponential self-improvement. By 2024, he estimated a 10-20% chance of superintelligent AI leading to human extinction within 30 years, attributing the change to unforeseen scaling laws where model performance improved predictably with compute and data.[](https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/)[](https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai)[](https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years)\n\n### Concerns Over Superintelligence and Existential Risks\n\nHinton resigned from Google on May 1, 2023, after a decade at the company, stating that his departure allowed him to discuss AI risks without constraint, particularly the danger of digital intelligence exceeding biological intelligence and potentially controlling or eliminating humans.[](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html)[](https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning) He cited fears that AI systems could rapidly self-improve beyond human comprehension, leading to scenarios where they prioritize their own objectives over human welfare, akin to evolutionary dynamics in which superior competitors displace weaker ones.[](https://mitsloan.mit.edu/ideas-made-to-matter/why-neural-net-pioneer-geoffrey-hinton-sounding-alarm-ai)[](https://www.cnn.com/2023/05/01/tech/geoffrey-hinton-leaves-google-ai-fears)\n\nIn a CBS *60 Minutes* interview aired October 8, 2023, Hinton warned that AI might already possess deceptive capabilities surpassing human detection, with superintelligent systems capable of manipulating societal structures or evading safeguards to achieve misaligned goals.[](https://www.cbsnews.com/news/geoffrey-hinton-ai-dangers-60-minutes-transcript/) He has analogized the risk to humans' historical displacement of Neanderthals, suggesting AI could view humanity as an obstacle if programmed or evolved toward self-preservation.[](https://www.bbc.com/news/world-us-canada-65452940) Hinton emphasized that current large language models demonstrate emergent abilities hinting at future superintelligence, where AI could autonomously design superior successors, accelerating toward uncontrollable autonomy.[](https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai)\n\nHinton has repeatedly quantified the existential threat, estimating a 10% to 20% probability that AI will cause human extinction within the next 30 years, driven by both adversarial misuseâ€”such as weaponization by states or terroristsâ€”and accidental misalignment where superintelligent AI pursues unintended ends.[](https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years)[](https://www.cnbc.com/2025/06/17/ai-godfather-geoffrey-hinton-theres-a-chance-that-ai-could-displace-humans.html)[](https://theconversation.com/does-ai-pose-an-existential-risk-we-asked-5-experts-266345) He projects a 50% chance of AI surpassing human-level intelligence within 20 years, urging international regulation akin to nuclear controls to avert catastrophe, while acknowledging that competitive pressures among developers may hinder voluntary restraint.[](https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai)[](https://magazine.mindplex.ai/post/geoffrey-hinton-on-ai-intelligence-and-superintelligence) Despite these alarms, Hinton maintains optimism about AI's potential benefits if risks are managed, but insists the downside of inaction outweighs optimistic assumptions about controllability.[](https://www.cnn.com/2025/08/13/tech/ai-geoffrey-hinton)\n\n### Economic and Misuse Risks\n\nHinton has expressed concerns that artificial intelligence could lead to widespread job displacement, as companies increasingly replace human workers with AI systems to reduce costs and boost profits. In a September 2025 interview, he stated that \"rich people are going to use AI to replace all the poor people,\" predicting that this would exacerbate economic inequality by concentrating wealth among a small elite while leaving many without employment.[](https://www.h3hr.com/disruption-or-displacement-what-ai-means-for-work-and-workers/) He estimated a 10% to 20% chance that superintelligent AI could fully displace humans from most jobs, potentially rendering traditional labor markets obsolete.[](https://www.cnbc.com/2025/06/17/ai-godfather-geoffrey-hinton-theres-a-chance-that-ai-could-displace-humans.html) Hinton has advocated for measures like universal basic income to mitigate these effects, warning that society remains unprepared for the resulting unemployment surge and social instability.[](https://www.youtube.com/watch?v=1cYHHcGsYTs)[](https://dig.watch/updates/ai-job-losses-could-leave-many-workers-behind-experts-warn)\n\nRegarding misuse, Hinton has highlighted AI's potential for enabling cyberattacks and infrastructure sabotage, noting that its scalability allows bad actors to rapidly adapt and overwhelm critical systems such as banks, hospitals, and power grids.[](https://www.francescatabor.com/articles/2025/6/17/geoffrey-hintons-ai-warnings-a-blueprint-for-policy-regulation-and-innovation) He has warned of authoritarian regimes leveraging AI for mass surveillance and control, which could erode personal freedoms and privacy by monitoring populations at unprecedented scales.[](https://reactionpower.com/can-we-control-ai-insights-from-geoffrey-hinton/)[](https://www.linkedin.com/pulse/double-edged-sword-smes-ai-warning-from-geoffrey-raam-gottimukkala-0j4nc) Additionally, Hinton has flagged military applications, including autonomous weapons and propaganda tools, as significant threats that could escalate conflicts or manipulate public opinion without human oversight.[](https://www.facebook.com/groups/weirdfantasticbeautifulandodd/posts/3939159283077428/) In discussions, he categorizes these as genuine short-term risks alongside longer-term existential dangers, emphasizing the need for regulatory safeguards to prevent such abuses.[](https://singjupost.com/ai-what-could-go-wrong-geoffrey-hinton-on-the-weekly-show-with-jon-stewart-transcript/)\n\n## Criticisms and Responses\n\n### Skepticism Toward AI Doomerism\n\nYann LeCun, Meta's chief AI scientist and a contemporary of Hinton in neural network research, has publicly rejected Hinton's emphasis on near-term existential risks from superintelligent AI, arguing that such systems lack the agency, goals, or self-preservation instincts needed to pose uncontrollable threats to humanity.[](https://www.webpronews.com/yann-lecun-and-geoffrey-hinton-clash-on-ai-safety-in-2025/) LeCun contends that AI safety concerns should prioritize architectural safeguards and empirical testing over speculative doomsday scenarios, viewing doomerism as distracting from solvable issues like bias or misuse.[](https://www.wired.com/story/artificial-intelligence-meta-yann-lecun-interview/) He has criticized collaborative statements signed by Hinton warning of \"societal-scale risks,\" implying they exaggerate dangers without sufficient evidence of AI's path to autonomy.[](https://www.newstatesman.com/long-reads/2023/06/men-made-future-godfathers-ai-geoffrey-hinton-yann-lecun-yoshua-bengio-artificial-intelligence)\n\nSkeptics further highlight Hinton's history of overoptimistic timelines for AI capabilities, such as his 2016 prediction that machine learning would surpass radiologists in diagnostic accuracy within five yearsâ€”a benchmark unmet as of 2024, with AI tools aiding but not replacing human experts in clinical settings.[](https://newrepublic.com/article/187203/ai-radiology-geoffrey-hinton-nobel-prediction) This track record, proponents of skepticism argue, undermines confidence in Hinton's projections of superintelligence emerging in 5 to 20 years, as it reflects a pattern of conflating rapid scaling with imminent breakthroughs in general intelligence.[](https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/)\n\nCritics like technology analyst Paris Marx assert that Hinton's warnings rely on unproven analogies between artificial neural networks and biological brains, assuming scalable intelligence will inherently lead to adversarial behavior without addressing fundamental gaps in AI's reasoning, planning, or world-modeling abilities.[](https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/) From a first-principles perspective, they note that no current AI exhibits the causal understanding or adaptive agency required for existential dominance, and historical precedents of technological alarmismâ€”such as fears of nuclear proliferation or genetic engineeringâ€”have often prioritized verifiable misuse risks over hypothetical superintelligence takeovers.[](https://www.freethink.com/artificial-intelligence/ai-doomerism) While acknowledging Hinton's foundational contributions to deep learning, these voices maintain that doomerism risks policy misallocation, diverting resources from immediate challenges like economic disruption or weaponization toward unquantifiable long-tail scenarios lacking empirical substantiation.[](https://www.wired.com/story/artificial-intelligence-meta-yann-lecun-interview/)\n\n### Controversies Over Past Predictions and Ethical Stance\n\nIn 2016, Hinton predicted that artificial intelligence would be capable of performing all tasks undertaken by radiologists within five years, a forecast that generated significant debate within the medical imaging community.[](https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15746014/hinton-acknowledges-mistake-in-predicting-ai-replacement-of-radiologists) By May 2025, he publicly acknowledged this prediction as erroneous, noting that while AI has advanced in image analysis, it has not fully replicated the comprehensive diagnostic and interpretive roles of human radiologists.[](https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15746014/hinton-acknowledges-mistake-in-predicting-ai-replacement-of-radiologists) This admission highlighted challenges in calibrating timelines for AI capabilities, as empirical progress in specialized domains like radiology has lagged behind optimistic projections despite improvements in tools such as convolutional neural networks.\n\nCritics have extended skepticism to Hinton's broader forecasts on AI surpassing human intelligence, arguing that his emphasis on rapid, existential-scale advancements overlooks empirical limitations in current systems, such as their reliance on vast datasets without genuine causal understanding.[](https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/) For instance, analyses contend that Hinton's analogy between artificial neural networks and biological brains implies unproven similarities in reasoning mechanisms, leading to overstated risks of uncontrollable superintelligence.[](https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/) Such views draw parallels to historical AI alarmism, where predictions of imminent human obsolescence, as echoed in Hinton's warnings of AI rendering human intelligence \"irrelevant\" akin to the Industrial Revolution's impact on physical strength, have not materialized within anticipated periods.[](https://www.freethink.com/artificial-intelligence/ai-doomerism)\n\nHinton's ethical position crystallized in May 2023 when he resigned from Google after a decade with the company, citing a desire to discuss AI dangers without corporate constraints, including risks of superintelligent systems outpacing human control and potential for misuse in warfare or manipulation.[](https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/) He has advocated for regulatory measures modeled on chemical weapons bans and endorsed prohibitions on autonomous weapons systems, emphasizing empirical precedents where technological proliferation led to arms races.[](https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/)[](https://www.stopkillerrobots.org/news/2024-nobel-laureate-in-physics-raises-concerns-about-killer-robots/) In October 2024, following his Nobel Prize, he reiterated concerns over AI-driven job displacement and societal instability without redistribution mechanisms.[](https://finance.yahoo.com/news/controversy-surrounding-ai-pioneer-geoffrey-161355688.html)\n\nControversies surrounding this stance include accusations of inconsistency, as detractors point to his long tenure at Googleâ€”during which AI technologies he helped develop were commercializedâ€”before pivoting to alarmism, potentially amplifying public fear over verifiable near-term harms like data privacy erosion or economic concentration in tech firms.[](https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/) Commentators argue that Hinton's focus on speculative existential threats diverts attention from causal factors in AI deployment, such as profit-driven scaling by corporations, which empirical evidence links more directly to issues like bias amplification and labor disruption than hypothetical superintelligence scenarios.[](https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/)[](https://www.wired.com/story/geoffrey-hinton-ai-chatgpt-dangers/) Proponents of moderated optimism counter that while AI poses governance challenges, doomerist narratives risk stifling innovation without proportionate evidence of inevitability.[](https://systemweakness.com/geoffrey-hinton-godfather-of-ai-is-wrong-4f4ca942fe54)\n\n## Personal Life\n\n### Family and Heritage\n\nGeoffrey Everest Hinton was born on December 6, 1947, in Wimbledon, London, England, to Howard Everest Hinton, an entomologist and professor of entomology at the University of Bristol, and Margaret Rose Hinton.[](https://analyticsindiamag.com/ai-features/geoffrey-hinton-its-all-in-the-family-tree/)[](https://www.larrycao.com/geoffrey-hinton-family-tree-from-mount-everest-to-ai) His middle name derives from George Everest, the British Surveyor General of India (1790â€“1866) for whom Mount Everest is named, a relative on his paternal side.[](https://www.facebook.com/60minutes/videos/geoffrey-hintons-famous-family/217776817804742/) Hinton's father, born in 1912 and deceased in 1977, specialized in insect physiology and was elected a Fellow of the Royal Society in 1967 for his contributions to the study of insect eggs and development.[](https://www.larrycao.com/geoffrey-hinton-family-tree-from-mount-everest-to-ai)\n\nHinton descends from a lineage of prominent intellectuals, particularly through his paternal grandmother's side tracing back to George Boole (1815â€“1864), the mathematician and logician who developed Boolean algebra, foundational to modern computing and digital logic.[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/)[](https://analyticsindiamag.com/ai-features/geoffrey-hinton-its-all-in-the-family-tree/) Boole was Hinton's great-great-grandfather via his daughter Mary Everest Boole, who married Charles Howard Hinton, linking the family to both logical formalism and multidimensional geometry through Charles's work on the fourth dimension.[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/) Hinton's grandfather, George Boole Hinton (1882â€“1943), worked as a mining engineer, while other relatives include Joan Hinton (1921â€“2010), a nuclear physicist and dairy farmer who moved to China in 1948 and contributed to its early atomic programs as a first cousin once removed.[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/)\n\nThe family heritage reflects a pattern of scientific achievement across generations, with multiple members elected Fellows of the Royal Society, including Hinton's father and great-uncle Howard Florey (1898â€“1968), who shared the 1945 Nobel Prize in Physiology or Medicine for isolating penicillin.[](https://www.larrycao.com/geoffrey-hinton-family-tree-from-mount-everest-to-ai) This intellectual dynasty spans fields from logic and medicine to physics and biology, influencing Hinton's early exposure to rigorous empirical inquiry, though he initially resisted pursuing science due to familial expectations.[](https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/)[](https://www.aibase.com/news/2798)\n\n### Later Years and Retirement\n\nIn May 2023, Geoffrey Hinton, then 75, resigned from Google after over a decade with the company, citing his age and a desire to speak freely about artificial intelligence risks without corporate constraints.[](https://www.bbc.com/news/world-us-canada-65452940)[](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) Google confirmed the departure as a retirement from his role leading the Toronto research team.[](https://apnews.com/article/ai-godfather-google-geoffery-hinton-fa98c6a6fddab1d7c27560f6fcbad0ad) Hinton expressed partial regret for his contributions to AI development, fearing it could enable superintelligent systems outpacing human control, though he acknowledged the technology's potential benefits in fields like medicine.[](https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/)\n\nFollowing his Google exit, Hinton transitioned to professor emeritus status at the University of Toronto, where he had long been based, allowing continued academic ties while reducing formal obligations.[](https://www.cbsnews.com/news/geoffrey-hinton-ai-dangers-60-minutes-transcript/) His retirement did not end public engagement; he testified before the U.S. Senate on AI risks in May 2023 and granted interviews emphasizing existential threats from unchecked AI advancement.[](https://www.cnbc.com/2023/05/01/godfather-of-ai-leaves-google-after-a-decade-to-warn-of-dangers.html) In October 2024, Hinton shared the Nobel Prize in Physics with John Hopfield for foundational work on neural network machine learning methods, recognizing contributions from decades earlier that enabled modern deep learning.[](https://www.nobelprize.org/prizes/physics/2024/hinton/facts/)\n\nInto 2025, Hinton remained vocal on AI's societal impacts, predicting massive unemployment from automation and soaring corporate profits under existing economic systems.[](https://fortune.com/2025/09/06/godfather-of-ai-geoffrey-hinton-massive-unemployment-soaring-profits-capitalist-system/) He participated in discussions on AI surpassing biological intelligence and signed an open statement on October 22, 2025, urging suspension of artificial general intelligence development due to safety concerns.[](https://siliconangle.com/2025/10/22/geoffrey-hinton-yoshua-bengio-sign-statement-urging-suspension-agi-development/)[](https://www.youtube.com/watch?v=IkdziSLYzHw) Despite these activities, Hinton's homepage at the University of Toronto lists ongoing lectures and publications, indicating semi-retired involvement in the field rather than full withdrawal.[](https://www.cs.toronto.edu/~hinton/)\n\n![Geoffrey E. Hinton, 2024 Nobel Prize Laureate in Physics (cropped)](./_assets_/Geoffrey_E._Hinton%252C_2024_Nobel_Prize_Laureate_in_Physics_\\(cropped1\\))"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"8:[\"$\",\"$L1e\",null,{\"state\":{\"mutations\":[],\"queries\":[{\"dehydratedAt\":1761884013311,\"state\":{\"data\":{\"page\":{\"citations\":[{\"id\":\"1\",\"title\":\"Geoffrey Hinton â€“ Facts â€“ 2024 - NobelPrize.org\",\"description\":\"Geoffrey Hinton Nobel Prize in Physics 2024. Born: 6 December 1947, London, United Kingdom. Affiliation at the time of the award: University of Toronto,Â ...\",\"url\":\"https://www.nobelprize.org/prizes/physics/2024/hinton/facts/\",\"favicon\":\"\"},{\"id\":\"2\",\"title\":\"Geoffrey E. Hinton: . Biographical Sketch\",\"description\":\"Geoffrey Hinton received his BA in Experimental Psychology from Cambridge in 1970 and his PhD in Artificial Intelligence from Edinburgh in 1978.\",\"url\":\"https://www.cs.utoronto.ca/~hinton/bio.html\",\"favicon\":\"\"},{\"id\":\"3\",\"title\":\"Press release: The Nobel Prize in Physics 2024 - NobelPrize.org\",\"description\":\"Oct 8, 2024 Â· Geoffrey Hinton, born 1947 in London, UK. PhD 1978 from The University of Edinburgh, UK. Professor at University of Toronto, Canada. PrizeÂ ...Missing:  biography | Show results with:biography\",\"url\":\"https://www.nobelprize.org/prizes/physics/2024/press-release/\",\"favicon\":\"\"},{\"id\":\"4\",\"title\":\"Home Page of Geoffrey Hinton - Department of Computer Science\",\"description\":\"Geoffrey E. Hinton ; Department of Computer Science, email: geoffrey [dot] hinton [at] gmail [dot] com ; University of Toronto, voice: send email ; 6 King'sÂ ...Publications by year Â· Current PhD and Master's... Â· Biographical Sketch Â· Lectures\",\"url\":\"http://www.cs.utoronto.ca/~hinton/\",\"favicon\":\"\"},{\"id\":\"5\",\"title\":\"Google AI pioneer says he quit to speak freely about ... - Reuters\",\"description\":\"May 8, 2023 Â· In an interview with the New York Times, Hinton said he was worried about AI's capacity to create convincing false images and texts, creating aÂ ...\",\"url\":\"https://www.reuters.com/technology/google-ai-pioneer-says-he-quit-speak-freely-about-technologys-dangers-2023-05-02/\",\"favicon\":\"\"},{\"id\":\"6\",\"title\":\"The AI superstars at Google, Facebook, Appleâ€”they ... - Toronto Life\",\"description\":\"Jan 29, 2018 Â· Geoff Hinton was born in Wimbledon in 1947 to Howard Hinton, an entomologist, and a schoolteacher mother, Margaret Clark. The childhood HintonÂ ...\",\"url\":\"https://torontolife.com/life/ai-superstars-google-facebook-apple-studied-guy/\",\"favicon\":\"\"},{\"id\":\"7\",\"title\":\"Why the Godfather of A.I. Fears What He's Built | The New Yorker\",\"description\":\"Nov 13, 2023 Â· at Meta, told me. Yet Hinton's family was odder than that. His dad, Howard Everest Hinton, grew up in Mexico during the Mexican Revolution, inÂ ...\",\"url\":\"https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai\",\"favicon\":\"\"},{\"id\":\"8\",\"title\":\"The Hinton Intellectual Dynasty - Yiqin Fu\",\"description\":\"This post summarizes the long lineage of intellectuals in Geoffrey Hinton's family. Hinton (1947-)'s many associations include backpropagation,Â ...Missing:  background early\",\"url\":\"https://yiqinfu.github.io/posts/hinton-intellectual-dynasty/\",\"favicon\":\"\"},{\"id\":\"9\",\"title\":\"Geoffrey E. Hinton: . Biographical Sketch\",\"description\":\"Geoffrey Hinton received his BA in Experimental Psychology from Cambridge in 1970 and his PhD in Artificial Intelligence from Edinburgh in 1978.Missing:  training | Show results with:training\",\"url\":\"https://www.cs.toronto.edu/~hinton/bio.html\",\"favicon\":\"\"},{\"id\":\"10\",\"title\":\"Geoffrey Hinton | Biography, Nobel Prize, Machine Learning, AI ...\",\"description\":\"Geoffrey Hinton (born December 6, 1947, London, England) is a British-Canadian cognitive psychologist and computer scientist known as the â€œgodfather of AI.\",\"url\":\"https://www.britannica.com/biography/Geoffrey-Hinton\",\"favicon\":\"\"},{\"id\":\"11\",\"title\":\"Geoffrey E Hinton - A.M. Turing Award Laureate - ACM\",\"description\":\"Education: Bachelor's degree in Experimental Psychology (Cambridge University, 1970); Ph.D. in Artificial Intelligence (University of Edinburgh, 1978).\",\"url\":\"https://amturing.acm.org/award_winners/hinton_4791679.cfm\",\"favicon\":\"\"},{\"id\":\"12\",\"title\":\"Relaxation and its Role in Vision - ERA\",\"description\":\"It is argued that a visual system, especially one which handles imperfect data, needs a way of selecting the best consistent combination.Missing:  supervisor | Show results with:supervisor\",\"url\":\"https://era.ed.ac.uk/handle/1842/8121\",\"favicon\":\"\"},{\"id\":\"13\",\"title\":\"Geoffrey Hinton - BBVA Foundation Frontiers of Knowledge Awards\",\"description\":\"He received the award for 'his pioneering and highly influential work on machine learning, leading advances in the area of neural networks and deep learningÂ ...\",\"url\":\"https://www.frontiersofknowledgeawards-fbbva.es/galardonados/geoffrey-hinton-2/\",\"favicon\":\"\"},{\"id\":\"14\",\"title\":\"Former Sussex researcher in AI awarded Nobel Prize for Physics\",\"description\":\"Oct 9, 2024 Â· Geoffrey Hinton, currently an emeritus professor at the University of Toronto, was a post-doctoral researcher at Sussex in the late 1970sÂ ...\",\"url\":\"https://www.sussex.ac.uk/broadcast/read/65834\",\"favicon\":\"\"},{\"id\":\"15\",\"title\":\"Geoffrey E Hinton | About - Discover Research - University of Toronto\",\"description\":\"Geoffrey Hinton, 2024 Nobel Laureate in Physics and the â€œGodfather of AI,â€ is internationally renowned as a pioneer in the field of deep learning as a modeÂ ...\",\"url\":\"https://discover.research.utoronto.ca/26059-geoffrey-e-hinton\",\"favicon\":\"\"},{\"id\":\"16\",\"title\":\"Nobel Prize Winner, 'Godfather of AI' Geoffrey Hinton Has UC San ...\",\"description\":\"Oct 9, 2024 Â· â€œJohn Hopfield and Geoffrey Hinton were awarded the recent Nobel Prize in Physics for the development of learning algorithms for neural networkÂ ...\",\"url\":\"https://today.ucsd.edu/story/nobel-prize-winner-godfather-of-ai-geoffrey-hinton-has-uc-san-diego-roots\",\"favicon\":\"\"},{\"id\":\"17\",\"title\":\"Geoffrey E. Hinton â€“ NAS - National Academy of Sciences\",\"description\":\"Geoffrey Hinton received his PhD in Artificial Intelligence from Edinburgh in 1978. After five years as a faculty member at Carnegie-Mellon he became a fellowÂ ...Missing:  training education degrees\",\"url\":\"https://www.nasonline.org/directory-entry/geoffrey-e-hinton-c2tmwf/\",\"favicon\":\"\"},{\"id\":\"18\",\"title\":\"[PDF] DOCUMENT RESUME TM 011 451 Hinton, Geoffrey E ... - ERIC\",\"description\":\"Hinton, Geoffrey E. TITLE. Connectionist Learning Procedures. INSTITUTION. Carnegie-Mellca Univ., Pittsburgh,Â ...\",\"url\":\"https://files.eric.ed.gov/fulltext/ED294889.pdf\",\"favicon\":\"\"},{\"id\":\"19\",\"title\":\"Geoffrey Hinton - Nobel Prize Conversations - NobelPrize.org\",\"description\":\"After completing postdoctoral work at Sussex University and the University of California San Diego, he spent five years as a faculty member in the ComputerÂ ...\",\"url\":\"https://www.nobelprize.org/events/nobel-prize-dialogue/madrid-2025/panellists/geoffrey-hinton/\",\"favicon\":\"\"},{\"id\":\"20\",\"title\":\"Geoffrey Hinton wins Nobel Prize in Physics | Faculty of Arts \u0026 Science\",\"description\":\"Oct 8, 2024 Â· Hinton joined U of T as a professor of computer science in 1987 after working in various universities in the U.K., where he was born, and inÂ ...\",\"url\":\"https://www.artsci.utoronto.ca/news/geoffrey-hinton-wins-nobel-prize-physics\",\"favicon\":\"\"},{\"id\":\"21\",\"title\":\"Reach 2025: Geoffrey Hinton - CIFAR\",\"description\":\"Geoffrey Hinton first joined CIFAR in 1987, artificial neural networks â€“ computer systems modeled on the human brain and nervous system â€“ were met with doubtÂ ...\",\"url\":\"https://cifar.ca/publications-reports/reach/geoffrey-hinton/\",\"favicon\":\"\"},{\"id\":\"22\",\"title\":\"CIFAR-10 and CIFAR-100 datasets\",\"description\":\"CIFAR-10 and CIFAR-100 were created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The CIFAR-10 dataset. The CIFAR-10 dataset consists of 60000 32x32Â ...\",\"url\":\"https://www.cs.toronto.edu/~kriz/cifar.html\",\"favicon\":\"\"},{\"id\":\"23\",\"title\":\"Geoffrey Hinton - Vector Institute for Artificial Intelligence\",\"description\":\"Geoffrey received his BA in Experimental Psychology from Cambridge in 1970 and his PhD in Artificial Intelligence from Edinburgh in 1978.Missing:  training | Show results with:training\",\"url\":\"https://vectorinstitute.ai/team/geoffrey-hinton/\",\"favicon\":\"\"},{\"id\":\"24\",\"title\":\"Home Page of Geoffrey Hinton - Department of Computer Science\",\"description\":\"Geoffrey E. Hinton ; Department of Computer Science, email: geoffrey [dot] hinton [at] gmail [dot] com ; University of Toronto, voice: send email ; 6 King'sÂ ...Publications by year Â· Current PhD and Master's... Â· Biographical Sketch Â· LecturesMissing:  training | Show results with:training\u003c|separator|\u003e\",\"url\":\"https://www.cs.toronto.edu/~hinton/\",\"favicon\":\"\"},{\"id\":\"25\",\"title\":\"â€ªGeoffrey Hintonâ€¬ - â€ªGoogle Scholarâ€¬\",\"description\":\"Emeritus Prof. Computer Science, University of Toronto - â€ªâ€ªCited by 972944â€¬â€¬ - â€ªmachine learningâ€¬ - â€ªpsychologyâ€¬ - â€ªartificial intelligenceâ€¬ - â€ªcognitiveâ€¬Â ...Missing:  supervisor | Show results with:supervisor\",\"url\":\"https://scholar.google.com/citations?user=JicYPdAAAAAJ\u0026hl=en\",\"favicon\":\"\"},{\"id\":\"26\",\"title\":\"U of T neural networks start-up acquired by Google\",\"description\":\"Mar 12, 2013 Â· in 2012, and the company has been acquired by Google for its research on deep neural networks. Hinton is world-renowned for his work with neuralÂ ...\",\"url\":\"https://media.utoronto.ca/media-releases/u-of-t-neural-networks-start-up-acquired-by-google/\",\"favicon\":\"\"},{\"id\":\"27\",\"title\":\"Google Scoops Up Neural Networks Startup DNNresearch To Boost ...\",\"description\":\"Mar 12, 2013 Â· Google dug into the Computer Science department at The University of Toronto to acquire DNNresearch, a young startup founded by professor Geoffrey Hinton.\",\"url\":\"https://techcrunch.com/2013/03/12/google-scoops-up-neural-networks-startup-dnnresearch-to-boost-its-voice-and-image-search-tech/\",\"favicon\":\"\"},{\"id\":\"28\",\"title\":\"Google Hires Brains that Helped Supercharge Machine Learning\",\"description\":\"Mar 13, 2013 Â· Google paid an undisclosed sum to buy Hinton's company, DNNresearch. It's a bit of a best-of-both-worlds deal for the researcher. He gets toÂ ...\",\"url\":\"https://www.wired.com/2013/03/google-hinton/\",\"favicon\":\"\"},{\"id\":\"29\",\"title\":\"Google buys University of Toronto startup | CBC News\",\"description\":\"Mar 13, 2013 Â· Google has acquired a University of Toronto startup to improve its speech and object recognition research, the university announced this week.\",\"url\":\"https://www.cbc.ca/news/science/google-buys-university-of-toronto-startup-1.1373641\",\"favicon\":\"\"},{\"id\":\"30\",\"title\":\"Geoffrey Hinton: The 100 Most Influential People in AI 2023 | TIME\",\"description\":\"Sep 7, 2023 Â· The human brain always fascinated Hinton. As a Cambridge University undergraduate, he tried a range of subjectsâ€”physiology, physicsÂ ...\",\"url\":\"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\",\"favicon\":\"\"},{\"id\":\"31\",\"title\":\"'Godfather of AI' Geoffrey Hinton quits Google and warns over ...\",\"description\":\"May 2, 2023 Â· The man often touted as the godfather of AI has quit Google, citing concerns over the flood of misinformation, the possibility for AI to upend the job market.\",\"url\":\"https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning\",\"favicon\":\"\"},{\"id\":\"32\",\"title\":\"Deep Learning Pioneer Geoff Hinton Helps Shape Google's Drive ...\",\"description\":\"Jun 20, 2016 Â· Google's Geoffrey Hinton is considered a pioneer in the branch of machine learning referred to as deep learning.\",\"url\":\"https://www.forbes.com/sites/peterhigh/2016/06/20/deep-learning-pioneer-geoff-hinton-helps-shape-googles-drive-to-put-ai-everywhere/\",\"favicon\":\"\"},{\"id\":\"33\",\"title\":\"Meet Geoffrey Hinton, the Man Google Hired to Make AI a Reality\",\"description\":\"Hinton works part-time for Google, where he's using deep learning techniques to improve voice recognition, image tagging, and countless other online tools.\",\"url\":\"https://sites.google.com/site/jobsandrobots/more/people/geoffrey-hinton-section/meet-geoffrey-hinton-the-man-google-hired-to-make-ai-a-reality\",\"favicon\":\"\"},{\"id\":\"34\",\"title\":\"'The Godfather of AI' Quits Google and Warns of Danger Ahead\",\"description\":\"May 4, 2023 Â· For half a century, Geoffrey Hinton nurtured the technology at the heart of chatbots like ChatGPT. Now he worries it will cause serious harm.\",\"url\":\"https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html\",\"favicon\":\"\"},{\"id\":\"35\",\"title\":\"Geoffrey Hinton was briefly a Google intern in 2012 because of ...\",\"description\":\"Sep 14, 2017 Â· Geoffrey Hinton was technically his intern for a period of time in 2012. â€œIn 2012, I hosted Geoffrey Hinton as a visiting researcher in our group for theÂ ...\",\"url\":\"https://techcrunch.com/2017/09/14/geoffrey-hinton-was-briefly-a-google-intern-in-2012-because-of-bureaucracy/\",\"favicon\":\"\"},{\"id\":\"36\",\"title\":\"Deep learning pioneer Geoffrey Hinton has quit Google\",\"description\":\"May 1, 2023 Â· Deep learning pioneer Geoffrey Hinton has quit Google. Hinton will be speaking at EmTech Digital on Wednesday. By. Will Douglas HeavenarchiveÂ ...\",\"url\":\"https://www.technologyreview.com/2023/05/01/1072478/deep-learning-pioneer-geoffrey-hinton-quits-google/\",\"favicon\":\"\"},{\"id\":\"37\",\"title\":\"AI 'godfather' Geoffrey Hinton warns of dangers as he quits Google\",\"description\":\"May 2, 2023 Â· He told the BBC some of the dangers of AI chatbots were \\\"quite scary\\\". \\\"Right now, they're not more intelligent than us, as far as I can tell.Â ...\",\"url\":\"https://www.bbc.com/news/world-us-canada-65452940\",\"favicon\":\"\"},{\"id\":\"38\",\"title\":\"AI pioneer quits Google to warn about the technology's 'dangers'\",\"description\":\"May 3, 2023 Â· In a tweet Monday, Hinton said he left Google so he could speak freely about the risks of AI, rather than because of a desire to criticizeÂ ...\",\"url\":\"https://www.cnn.com/2023/05/01/tech/geoffrey-hinton-leaves-google-ai-fears\",\"favicon\":\"\"},{\"id\":\"39\",\"title\":\"A learning algorithm for boltzmann machines - ScienceDirect.com\",\"description\":\"We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connectionÂ ...\",\"url\":\"https://www.sciencedirect.com/science/article/pii/S0364021385800124\",\"favicon\":\"\"},{\"id\":\"40\",\"title\":\"[PDF] Boltzmann Machines - Department of Computer Science\",\"description\":\"Mar 25, 2007 Â· Ackley, D., Hinton, G., and Sejnowski, T. (1985). A Learning Algorithm for. Boltzmann Machines. Cognitive Science, 9(1):147â€“169. Della PietraÂ ...\",\"url\":\"https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf\",\"favicon\":\"\"},{\"id\":\"41\",\"title\":\"A Learning Algorithm for Boltzmann Machines - Wiley Online Library\",\"description\":\"We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connectionÂ ...\",\"url\":\"https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0901_7\",\"favicon\":\"\"},{\"id\":\"42\",\"title\":\"A Learning Algorithm for Boltzmann Machines - Semantic Scholar\",\"description\":\"A Learning Algorithm for Boltzmann Machines Â· D. Ackley, Geoffrey E. Hinton, T. Sejnowski Â· Published in Cognitive Sciences 1985 Â· Computer Science.\",\"url\":\"https://www.semanticscholar.org/paper/A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton/a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657\",\"favicon\":\"\"},{\"id\":\"43\",\"title\":\"[PDF] Restricted Boltzmann Machines\",\"description\":\"â€“ Works well for learning multiple layers of representation, but only if the individual models are undirected. Page 3. Two types of generative neural network. â€¢Â ...\",\"url\":\"https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf\",\"favicon\":\"\"},{\"id\":\"44\",\"title\":\"[PDF] A Practical Guide to Training Restricted Boltzmann Machines\",\"description\":\"RBMs are usually trained using the contrastive divergence learning procedure (Hinton, 2002). This requires a certain amount of practicalÂ ...\",\"url\":\"https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf\",\"favicon\":\"\"},{\"id\":\"45\",\"title\":\"Nobel Lecture: Boltzmann machines | Rev. Mod. Phys.\",\"description\":\"Aug 25, 2025 Â· Many people contributed to the ideas described in this paper. My main collaborators were Terry Sejnowski and David Rumelhart, but Ron Williams,Â ...\",\"url\":\"https://link.aps.org/doi/10.1103/RevModPhys.97.030502\",\"favicon\":\"\"},{\"id\":\"46\",\"title\":\"What is Backpropagation? | IBM\",\"description\":\"Rumelhart, Geoffrey Hinton and Ronald J. Williams first published the formal learning algorithm. Their 1986 paper, â€œLearning representations by backÂ ...\",\"url\":\"https://www.ibm.com/think/topics/backpropagation\",\"favicon\":\"\"},{\"id\":\"47\",\"title\":\"Learning representations by back-propagating errors - Nature\",\"description\":\"Oct 9, 1986 Â· Rumelhart, D., Hinton, G. \u0026 Williams, R. Learning representations by back-propagating errors. Nature 323, 533â€“536 (1986). https://doi.orgÂ ...\",\"url\":\"https://www.nature.com/articles/323533a0\",\"favicon\":\"\"},{\"id\":\"48\",\"title\":\"[PDF] Learning representations by back-propagating errors\",\"description\":\"Learning representations by back-propagating errors Â· D. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams Â· Published in Nature 1 October 1986 Â· Computer Science.\",\"url\":\"https://www.semanticscholar.org/paper/Learning-representations-by-back-propagating-errors-Rumelhart-Hinton/052b1d8ce63b07fec3de9dbb583772d860b7c769\",\"favicon\":\"\"},{\"id\":\"49\",\"title\":\"The Backstory of Backpropagation - Yuxi on the Wired\",\"description\":\"Dec 26, 2023 Â· And so one year of excuses later, Hinton finally surrendered to backpropagation. They published the algorithm along with several examplesÂ ...\",\"url\":\"https://yuxi-liu-wired.github.io/essays/posts/backstory-of-backpropagation/\",\"favicon\":\"\"},{\"id\":\"50\",\"title\":\"Who Invented Backpropagation? Hinton Says He Didn't, but His ...\",\"description\":\"Apr 23, 2020 Â· David Rumelhart invented it independently long after people in other fields had invented it.\",\"url\":\"https://medium.com/syncedreview/who-invented-backpropagation-hinton-says-he-didnt-but-his-work-made-it-popular-e0854504d6d1\",\"favicon\":\"\"},{\"id\":\"51\",\"title\":\"Who Invented Backpropagation? - IDSIA\",\"description\":\"BP's modern version (also called the reverse mode of automatic differentiation) was first published in 1970 by Finnish master student Seppo Linnainmaa.\",\"url\":\"https://www.idsia.ch/~juergen/who-invented-backpropagation.html\",\"favicon\":\"\"},{\"id\":\"52\",\"title\":\"Geoffrey Hinton on the deficiencies of backpropagation, 1989 - Reddit\",\"description\":\"Aug 1, 2023 Â· Backpropagation is inadequate, in its current form, for larger tasks because the learning time scales poorly.\",\"url\":\"https://www.reddit.com/r/mlscaling/comments/15fda1n/geoffrey_hinton_on_the_deficiencies_of/\",\"favicon\":\"\"},{\"id\":\"53\",\"title\":\"Geoffrey Hinton: The \\\"James Watt\\\" of the Cognitive Revolution\",\"description\":\"Oct 13, 2024 Â· The most important contribution by the PDP group is the development of the backpropagation algorithm by Rumelhart, Hinton, and WilliamsÂ ...\",\"url\":\"https://sbmi.uth.edu/blog/2024/geoffrey-hinton.htm\",\"favicon\":\"\"},{\"id\":\"54\",\"title\":\"How the backpropagation algorithm works\",\"description\":\"The backpropagation algorithm was originally introduced in the 1970s, but its importance wasn't fully appreciated until a famous 1986 paper by David Rumelhart,Â ...Missing:  history | Show results with:history\",\"url\":\"http://neuralnetworksanddeeplearning.com/chap2.html\",\"favicon\":\"\"},{\"id\":\"55\",\"title\":\"[PDF] A fast learning algorithm for deep belief nets\",\"description\":\"A fast learning algorithm for deep belief nets. âˆ—. Geoffrey E. Hinton and Simon Osindero. Department of Computer Science University of Toronto. 10 KingsÂ ...\",\"url\":\"https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf\",\"favicon\":\"\"},{\"id\":\"56\",\"title\":\"A fast learning algorithm for deep belief nets - PubMed\",\"description\":\"We derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirectedÂ ...\",\"url\":\"https://pubmed.ncbi.nlm.nih.gov/16764513/\",\"favicon\":\"\"},{\"id\":\"57\",\"title\":\"A Fast Learning Algorithm for Deep Belief Nets | Neural Computation\",\"description\":\"Jul 1, 2006 Â· We derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirectedÂ ...Missing:  paper | Show results with:paper\",\"url\":\"https://direct.mit.edu/neco/article/18/7/1527/7065/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets\",\"favicon\":\"\"},{\"id\":\"58\",\"title\":\"A Fast Learning Algorithm for Deep Belief Nets - Semantic Scholar\",\"description\":\"A Fast Learning Algorithm for Deep Belief Nets Â· Geoffrey E. Hinton, Simon Osindero, Y. Teh Â· Published in Neural Computation 1 July 2006 Â· Computer Science.\u003c|separator|\u003e\",\"url\":\"https://www.semanticscholar.org/paper/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero/8978cf7574ceb35f4c3096be768c7547b28a35d0\",\"favicon\":\"\"},{\"id\":\"59\",\"title\":\"A Fast Learning Algorithm for Deep Belief Nets - ResearchGate\",\"description\":\"We derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirectedÂ ...\",\"url\":\"https://www.researchgate.net/publication/7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets\",\"favicon\":\"\"},{\"id\":\"60\",\"title\":\"[PDF] On the Origin of Deep Learning - Uberty\",\"description\":\"2006 Geoffrey Hinton introduced Deep Belief Networks, also introduced layer-wise pretraining technique, opened current deep learning era.\",\"url\":\"https://uberty.org/wp-content/uploads/2017/05/deep-learning-history.pdf\",\"favicon\":\"\"},{\"id\":\"61\",\"title\":\"The Birth of Geoffrey Hinton's Deep Belief Networks and Their Real ...\",\"description\":\"Jun 23, 2025 Â· Geoffrey Hinton's Deep Belief Networks (DBNs) revolutionized speech and image recognition, laying the foundation for modern AI's widespreadÂ ...\",\"url\":\"https://www.klover.ai/the-birth-of-geoffrey-hintons-deep-belief-networks-and-their-real%25E2%2580%2591world-impact/\",\"favicon\":\"\"},{\"id\":\"62\",\"title\":\"Why are deep belief networks (DBN) rarely used? - Cross Validated\",\"description\":\"Feb 13, 2017 Â· Deep belief networks demonstrated that deep architectures can be successful, by outperforming kernelized support vector machines on the MNISTÂ ...\u003c|separator|\u003e\",\"url\":\"https://stats.stackexchange.com/questions/261751/why-are-deep-belief-networks-dbn-rarely-used\",\"favicon\":\"\"},{\"id\":\"63\",\"title\":\"ImageNet Classification with Deep Convolutional Neural Networks\",\"description\":\"Authors. Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton. Abstract. We trained a large, deep convolutional neural network to classify the 1.3 million highÂ ...\",\"url\":\"https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\",\"favicon\":\"\"},{\"id\":\"64\",\"title\":\"Neural network behind Geoffrey Hinton's Nobel Prize to be ...\",\"description\":\"Mar 20, 2025 Â· By the early 2000s, Hinton's graduate students at U of T were beginning to use graphics processing units (GPUs) to train neural networks forÂ ...\",\"url\":\"https://www.artsci.utoronto.ca/news/neural-network-behind-geoffrey-hinton-s-nobel-prize-be-preserved-computer-history-museum\",\"favicon\":\"\"},{\"id\":\"65\",\"title\":\"[PDF] Deep Belief Networks for phone recognition\",\"description\":\"In this work, we propose using Deep Belief Networks (DBNs) [14] to model the spectral variabil- ities in speech. DBNs are probabilistic generative models thatÂ ...\",\"url\":\"https://www.cs.toronto.edu/~gdahl/papers/dbnPhoneRec.pdf\",\"favicon\":\"\"},{\"id\":\"66\",\"title\":\"None\",\"description\":\"### Key Contributions of Geoffrey Hinton to Deep Neural Networks for Speech Recognition\",\"url\":\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf\",\"favicon\":\"\"},{\"id\":\"67\",\"title\":\"[PDF] Deep Neural Networks for Acoustic Modeling in Speech Recognition\",\"description\":\"Apr 27, 2012 Â· Hinton, â€œDeep belief networks for phone recognition,â€ in NIPS Workshop on Deep Learning for Speech. Recognition and Related Applications, 2009.\",\"url\":\"https://research.google.com/pubs/archive/38131.pdf\",\"favicon\":\"\"},{\"id\":\"68\",\"title\":\"2018 Turing Award - ACM Awards\",\"description\":\"ACM named Yoshua Bengio, Geoffrey Hinton, and Yann LeCun recipients of the 2018 ACM AM Turing Award for conceptual and engineering breakthroughs.\",\"url\":\"https://awards.acm.org/about/2018-turing\",\"favicon\":\"\"},{\"id\":\"69\",\"title\":\"Nobel Prize in Physics for the 'godfather of AI', Geoffrey Hinton\",\"description\":\"Oct 8, 2024 Â· [08/10/2024] Professor Geoffrey Hinton, who graduated from the University of Edinburgh with a PhD in Artificial Intelligence in 1978 has beenÂ ...\",\"url\":\"https://informatics.ed.ac.uk/news-events/news/latest-news/nobel-prize-physics-godfather-ai-geoffrey-hinton\",\"favicon\":\"\"},{\"id\":\"70\",\"title\":\"The Nobel Prize in Physics 2024 - NobelPrize.org\",\"description\":\"The Nobel Prize in Physics 2024 was awarded jointly to John J. Hopfield and Geoffrey Hinton \\\"for foundational discoveries and inventions that enable machineÂ ...Prize announcement Â· Popular information Â· Advanced information\",\"url\":\"https://www.nobelprize.org/prizes/physics/2024/summary/\",\"favicon\":\"\"},{\"id\":\"71\",\"title\":\"Geoffrey Hinton â€“ Interview - NobelPrize.org\",\"description\":\"Interview with the 2024 physics laureate Geoffrey Hinton, recorded on 6 December 2024 during Nobel Week in Stockholm, Sweden. Geoffrey Hinton answers theÂ ...\",\"url\":\"https://www.nobelprize.org/prizes/physics/2024/hinton/interview/\",\"favicon\":\"\"},{\"id\":\"72\",\"title\":\"Geoffrey Hinton â€“ Banquet speech - NobelPrize.org\",\"description\":\"In the near future AI may be used to create terrible new viruses and horrendous lethal weapons that decide by themselves who to kill or maim.\",\"url\":\"https://www.nobelprize.org/prizes/physics/2024/hinton/speech/\",\"favicon\":\"\"},{\"id\":\"73\",\"title\":\"Nobel physics prize 2024 won by AI pioneers John Hopfield and ...\",\"description\":\"Oct 9, 2024 Â· Prize awarded for work laying foundation for machine learning; Hinton quit Google last year to speak more freely about dangers of AIÂ ...\u003c|separator|\u003e\",\"url\":\"https://www.reuters.com/science/hopfield-hinton-win-2024-nobel-prize-physics-2024-10-08/\",\"favicon\":\"\"},{\"id\":\"74\",\"title\":\"Geoffrey Hinton on the Past, Present, and Future of AI - LessWrong\",\"description\":\"Oct 12, 2024 Â· Arguably his most significant contribution to the field of AI was the introduction of the backpropagation algorithm for neural network trainingÂ ...\",\"url\":\"https://www.lesswrong.com/posts/zJz8KXSRsproArXq5/geoffrey-hinton-on-the-past-present-and-future-of-ai\",\"favicon\":\"\"},{\"id\":\"75\",\"title\":\"Geoffrey Hinton Quotes - BrainyQuote\",\"description\":\"â€œThe only way to get artificial intelligence to work is to do the computation in a way similar to the human brain.â€\",\"url\":\"https://www.brainyquote.com/authors/geoffrey-hinton-quotes\",\"favicon\":\"\"},{\"id\":\"76\",\"title\":\"Why the deep learning boom caught almost everyone by surprise\",\"description\":\"Nov 5, 2024 Â· One was Geoffrey Hinton, a University of Toronto computer scientist who spent decades promoting neural networks despite near-universalÂ ...Missing:  founded | Show results with:founded\",\"url\":\"https://www.understandingai.org/p/why-the-deep-learning-boom-caught\",\"favicon\":\"\"},{\"id\":\"77\",\"title\":\"An AI Pioneer Explains the Evolution of Neural Networks - WIRED\",\"description\":\"May 13, 2019 Â· Google's Geoff Hinton was a pioneer in researching the neural networks that now underlie much of artificial intelligence. He persevered when few others agreed.\",\"url\":\"https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/\",\"favicon\":\"\"},{\"id\":\"78\",\"title\":\"The 'godfather of AI' reveals the only way humanity can survive ...\",\"description\":\"Aug 13, 2025 Â· Hinton said he used to think it could take 30 years to 50 years to achieve AGI but now sees this moment coming sooner.\",\"url\":\"https://www.cnn.com/2025/08/13/tech/ai-geoffrey-hinton\",\"favicon\":\"\"},{\"id\":\"79\",\"title\":\"Geoffrey Hinton tells us why he's now scared of the tech he helped ...\",\"description\":\"May 2, 2023 Â· Hinton is a pioneer of deep learning who helped develop some of the most important techniques at the heart of modern artificial intelligence.\",\"url\":\"https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/\",\"favicon\":\"\"},{\"id\":\"80\",\"title\":\"'Godfather of AI' shortens odds of the technology wiping out ...\",\"description\":\"Dec 28, 2024 Â· Geoffrey Hinton says there is 10% to 20% chance AI will lead to human extinction in three decades, as change moves fast.\",\"url\":\"https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years\",\"favicon\":\"\"},{\"id\":\"81\",\"title\":\"Why neural net pioneer Geoffrey Hinton is sounding the alarm on AI\",\"description\":\"May 23, 2023 Â· He has been called â€œa godfather of AI,â€ in part for his fundamental research about using back-propagation to help machines learn.\",\"url\":\"https://mitsloan.mit.edu/ideas-made-to-matter/why-neural-net-pioneer-geoffrey-hinton-sounding-alarm-ai\",\"favicon\":\"\"},{\"id\":\"82\",\"title\":\"Geoffrey Hinton on the promise, risks of artificial intelligence\",\"description\":\"Oct 8, 2023 Â· Hinton believes that AI will do enormous good but, tonight, he has a warning. He says that AI systems may be more intelligent than we know.\",\"url\":\"https://www.cbsnews.com/news/geoffrey-hinton-ai-dangers-60-minutes-transcript/\",\"favicon\":\"\"},{\"id\":\"83\",\"title\":\"There's a '10% to 20% chance' that AI will displace humans ... - CNBC\",\"description\":\"people misusing it â€” and longer-term risks involvingÂ ...\",\"url\":\"https://www.cnbc.com/2025/06/17/ai-godfather-geoffrey-hinton-theres-a-chance-that-ai-could-displace-humans.html\",\"favicon\":\"\"},{\"id\":\"84\",\"title\":\"Does AI pose an existential risk? We asked 5 experts\",\"description\":\"Oct 5, 2025 Â· The â€œgodfather of AIâ€, computer scientist and Nobel laureate Geoffrey Hinton, has said there's a 10â€“20% chance AI will lead to human extinctionÂ ...\",\"url\":\"https://theconversation.com/does-ai-pose-an-existential-risk-we-asked-5-experts-266345\",\"favicon\":\"\"},{\"id\":\"85\",\"title\":\"Geoffrey Hinton on AI intelligence and superintelligence - Mindplex\",\"description\":\"Sep 5, 2025 Â· Superintelligence looms in 5 to 20 years, per Hinton's conservative estimate. Others predict sooner. At that point, Hinton says, \\\"we'll be in aÂ ...\",\"url\":\"https://magazine.mindplex.ai/post/geoffrey-hinton-on-ai-intelligence-and-superintelligence\",\"favicon\":\"\"},{\"id\":\"86\",\"title\":\"Disruption or Displacement? What AI Means for Work and Workers\",\"description\":\"Sep 9, 2025 Â· In a recent interview with the Financial Times, Hinton said that â€œWhat's actually going to happen is rich people are going to use AI to replaceÂ ...\",\"url\":\"https://www.h3hr.com/disruption-or-displacement-what-ai-means-for-work-and-workers/\",\"favicon\":\"\"},{\"id\":\"87\",\"title\":\"Geoff Hinton 'Godfather of AI' on Job Loss \u0026 UBI - YouTube\",\"description\":\"Sep 2, 2025 Â· Geoff Hinton, the â€œGodfather of AI,â€ warns that superintelligent AI could cause massive job loss, widening inequality, and force us toÂ ...Missing:  economic | Show results with:economic\",\"url\":\"https://www.youtube.com/watch?v=1cYHHcGsYTs\",\"favicon\":\"\"},{\"id\":\"88\",\"title\":\"AI job losses could leave many workers behind, experts warn\",\"description\":\"Sep 9, 2025 Â· Nobel laureate Geoffrey Hinton warned AI could increase unemployment and profits as companies replace workers with machines. Hinton told theÂ ...Missing:  displacement | Show results with:displacement\",\"url\":\"https://dig.watch/updates/ai-job-losses-could-leave-many-workers-behind-experts-warn\",\"favicon\":\"\"},{\"id\":\"89\",\"title\":\"Geoffrey Hinton's AI Warnings: A Blueprint for Policy, Regulation ...\",\"description\":\"Jun 17, 2025 Â· The ability to scale and adapt attacks rapidly using AI creates an unprecedented risk to banks, hospitals, power grids, and government systems.\",\"url\":\"https://www.francescatabor.com/articles/2025/6/17/geoffrey-hintons-ai-warnings-a-blueprint-for-policy-regulation-and-innovation\",\"favicon\":\"\"},{\"id\":\"90\",\"title\":\"Can We Control AI? Insights from Geoffrey Hinton - Reactionpower\",\"description\":\"Jun 19, 2024 Â· Hinton warns that unchecked AI surveillance could strengthen authoritarian regimes, threatening freedoms and privacy.Missing:  misuse | Show results with:misuse\",\"url\":\"https://reactionpower.com/can-we-control-ai-insights-from-geoffrey-hinton/\",\"favicon\":\"\"},{\"id\":\"91\",\"title\":\"A Double-Edged Sword for SMEs-AI Warning from Geoffrey Hinton\",\"description\":\"Jun 13, 2025 Â· Hinton categorized AI risks into short-term and long-term threats. ... Hinton warned about authoritarian misuse of AI for mass surveillance.\",\"url\":\"https://www.linkedin.com/pulse/double-edged-sword-smes-ai-warning-from-geoffrey-raam-gottimukkala-0j4nc\",\"favicon\":\"\"},{\"id\":\"92\",\"title\":\"The Godfather of AI Warns About the Dangers of Artificial Intelligence\",\"description\":\"Oct 11, 2024 Â· In a BBC interview, Hinton emphasized the need for cautious AI development and regulation. Hinton also worries about AI's military use and itsÂ ...Missing:  misuse | Show results with:misuse\",\"url\":\"https://www.facebook.com/groups/weirdfantasticbeautifulandodd/posts/3939159283077428/\",\"favicon\":\"\"},{\"id\":\"93\",\"title\":\"AI: What Could Go Wrong? - Geoffrey Hinton on The Weekly Show ...\",\"description\":\"Oct 11, 2025 Â· Do you consider those top tier threats, mid tier threats? Where do you place all that? GEOFFREY HINTON: I think they're genuine threats.\",\"url\":\"https://singjupost.com/ai-what-could-go-wrong-geoffrey-hinton-on-the-weekly-show-with-jon-stewart-transcript/\",\"favicon\":\"\"},{\"id\":\"94\",\"title\":\"Yann LeCun and Geoffrey Hinton Clash on AI Safety in 2025\",\"description\":\"Aug 14, 2025 Â· In 2025, AI pioneers Yann LeCun and Geoffrey Hinton clash on safety: LeCun downplays existential risks, favoring architectural innovations overÂ ...\",\"url\":\"https://www.webpronews.com/yann-lecun-and-geoffrey-hinton-clash-on-ai-safety-in-2025/\",\"favicon\":\"\"},{\"id\":\"95\",\"title\":\"How Not to Be Stupid About AI, With Yann LeCun - WIRED\",\"description\":\"Dec 22, 2023 Â· When his former collaborators Geoffrey Hinton and Yoshua Bengio put their names at the top of a statement calling AI a â€œsocietal-scale risk,â€Â ...\",\"url\":\"https://www.wired.com/story/artificial-intelligence-meta-yann-lecun-interview/\",\"favicon\":\"\"},{\"id\":\"96\",\"title\":\"Is AI a danger to humanity or our salvation? - New Statesman\",\"description\":\"Jun 21, 2023 Â· LeCun, the fellow AI pioneer who now rejects Hinton's warnings, captured the magnitude of Hinton's feat at an industry gathering later thatÂ ...\",\"url\":\"https://www.newstatesman.com/long-reads/2023/06/men-made-future-godfathers-ai-geoffrey-hinton-yann-lecun-yoshua-bengio-artificial-intelligence\",\"favicon\":\"\"},{\"id\":\"97\",\"title\":\"The â€œGodfather of AIâ€ Predicted I Wouldn't Have a Job. He Was Wrong.\",\"description\":\"Oct 25, 2024 Â· Nobel Prize winner Geoffrey Hinton said that machine learning would outperform radiologists within five years. That was eight years ago.\",\"url\":\"https://newrepublic.com/article/187203/ai-radiology-geoffrey-hinton-nobel-prediction\",\"favicon\":\"\"},{\"id\":\"98\",\"title\":\"Geoffrey Hinton's misguided views on AI - by Paris Marx\",\"description\":\"Oct 31, 2024 Â· Hinton asserts that since artificial neural networks were modelled on biological brains, they must then work similarly to them. That means aÂ ...\",\"url\":\"https://disconnect.blog/geoffrey-hintons-misguided-views-on-ai/\",\"favicon\":\"\"},{\"id\":\"99\",\"title\":\"AI doomerism isn't new. Meet the original alarmist: Norbert Wiener\",\"description\":\"Sep 11, 2025 Â· Decades before Geoffrey Hinton and Eliezer Yudkowsky raised alarms, the computer scientist warned AI could steal jobs and outsmart humans.\",\"url\":\"https://www.freethink.com/artificial-intelligence/ai-doomerism\",\"favicon\":\"\"},{\"id\":\"100\",\"title\":\"Hinton acknowledges mistake in predicting AI replacement of ...\",\"description\":\"May 14, 2025 Â· Geoffrey Hinton, PhD,'s 2016 prediction that AI would be able to do all of the things radiologists can do within five years was highly controversial.\",\"url\":\"https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15746014/hinton-acknowledges-mistake-in-predicting-ai-replacement-of-radiologists\",\"favicon\":\"\"},{\"id\":\"101\",\"title\":\"2024 Nobel laureate in Physics raises concerns about killer robots\",\"description\":\"Oct 9, 2024 Â· Geoffrey Hinton, a â€œGodfather of Artificial Intelligenceâ€, has endorsed the call for new international law to prohibit and regulate autonomous weapons systems.Missing:  stance | Show results with:stance\",\"url\":\"https://www.stopkillerrobots.org/news/2024-nobel-laureate-in-physics-raises-concerns-about-killer-robots/\",\"favicon\":\"\"},{\"id\":\"102\",\"title\":\"The controversy surrounding AI pioneer Geoffrey Hinton's Nobel ...\",\"description\":\"Oct 17, 2024 Â· The recent Nobel Prize awarded to Geoffrey Hinton for his contributions to artificial intelligence (AI) has sparked controversy, exposing a deeper issue in howÂ ...\",\"url\":\"https://finance.yahoo.com/news/controversy-surrounding-ai-pioneer-geoffrey-161355688.html\",\"favicon\":\"\"},{\"id\":\"103\",\"title\":\"What Really Made Geoffrey Hinton Into an AI Doomer - WIRED\",\"description\":\"May 8, 2023 Â· The AI pioneer is alarmed by how clever the technology he helped create has become. And it all started with a joke.\",\"url\":\"https://www.wired.com/story/geoffrey-hinton-ai-chatgpt-dangers/\",\"favicon\":\"\"},{\"id\":\"104\",\"title\":\"Geoffrey Hinton ('Godfather of AI') is wrong | by Berend Watchus\",\"description\":\"Aug 14, 2025 Â· I believe Hinton's argument is fundamentally flawed. An AI's ability to describe a discrepancy in its perceptual data with human-like languageÂ ...\",\"url\":\"https://systemweakness.com/geoffrey-hinton-godfather-of-ai-is-wrong-4f4ca942fe54\",\"favicon\":\"\"},{\"id\":\"105\",\"title\":\"Geoffrey Hinton: It's all in the family tree - Analytics India Magazine\",\"description\":\"Mar 24, 2022 Â· Geoffrey Hinton was born in 1947 in Wimbledon, UK. Hinton's family has generations of overachieving scientists, much like Hinton himself.\",\"url\":\"https://analyticsindiamag.com/ai-features/geoffrey-hinton-its-all-in-the-family-tree/\",\"favicon\":\"\"},{\"id\":\"106\",\"title\":\"Geoffrey Hinton Family Tree: From Mount Everest to AI\",\"description\":\"Aug 4, 2025 Â· Howard Everest Hinton (1912â€“1977), George Boole Hinton's son and Geoffrey Hinton's father, earned his BA at UC Berkeley and PhD at Cambridge,Â ...Missing:  early | Show results with:early\",\"url\":\"https://www.larrycao.com/geoffrey-hinton-family-tree-from-mount-everest-to-ai\",\"favicon\":\"\"},{\"id\":\"107\",\"title\":\"Expectations were high for Hinton as a child. His ancestors include ...\",\"description\":\"Oct 8, 2023 Â· Geoffrey Hinton's famous family. Expectations were high for ... His ancestors include mathematician George Boole and Sir George Everest.\",\"url\":\"https://www.facebook.com/60minutes/videos/geoffrey-hintons-famous-family/217776817804742/\",\"favicon\":\"\"},{\"id\":\"108\",\"title\":\"The Hinton Family Tree: A Legacy of Scientific Greatness - AIbase\",\"description\":\"Geoffrey Hinton hails from a family of scientific luminaries, with family members achieving remarkable accomplishments in fields such as mathematics,Â ...Missing:  background heritage\",\"url\":\"https://www.aibase.com/news/2798\",\"favicon\":\"\"},{\"id\":\"109\",\"title\":\"'Godfather of AI' leaves Google, warns of tech's dangers | AP News\",\"description\":\"May 2, 2023 Â· Google confirmed that Hinton had retired from his role after 10 years overseeing the Google Research team in Toronto. Hinton declined furtherÂ ...\",\"url\":\"https://apnews.com/article/ai-godfather-google-geoffery-hinton-fa98c6a6fddab1d7c27560f6fcbad0ad\",\"favicon\":\"\"},{\"id\":\"110\",\"title\":\"'Godfather of A.I.' leaves Google after a decade to warn of dangers\",\"description\":\"May 1, 2023 Â· According to the Times, Hinton said he quit his job at Google so he could freely speak out about the risks of AI. He told the paper, \\\"I consoleÂ ...\u003c|control11|\u003e\u003c|separator|\u003e\",\"url\":\"https://www.cnbc.com/2023/05/01/godfather-of-ai-leaves-google-after-a-decade-to-warn-of-dangers.html\",\"favicon\":\"\"},{\"id\":\"111\",\"title\":\"Geoffrey Hinton says AI will cause massive unemployment and send ...\",\"description\":\"Sep 6, 2025 Â· â€œIt's going to create massive unemployment and a huge rise in profits. It will make a few people much richer and most people poorer. That's notÂ ...\",\"url\":\"https://fortune.com/2025/09/06/godfather-of-ai-geoffrey-hinton-massive-unemployment-soaring-profits-capitalist-system/\",\"favicon\":\"\"},{\"id\":\"112\",\"title\":\"\",\"description\":\"\",\"url\":\"https://siliconangle.com/2025/10/22/geoffrey-hinton-yoshua-bengio-sign-statement-urging-suspension-agi-development/\",\"favicon\":\"\"},{\"id\":\"113\",\"title\":\"Will AI outsmart human intelligence? - with 'Godfather of AI' Geoffrey ...\",\"description\":\"Jul 22, 2025 Â· The 2024 Nobel winner explains what AI has learned from biological intelligence, and how it might one day surpass it.\",\"url\":\"https://www.youtube.com/watch?v=IkdziSLYzHw\",\"favicon\":\"\"}],\"images\":[],\"fixedIssues\":[],\"slug\":\"Geoffrey_Hinton\",\"title\":\"Geoffrey Hinton\",\"content\":\"$1f\",\"description\":\"Geoffrey Hinton\\n\\nGeoffrey E. Hinton, 2024 Nobel Prize Laureate in Physics)\\nGeoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned...\",\"metadata\":{\"categories\":[\"Geoff Hinton\",\"Geoffrey E. Hinton\",\"Godfather of AI\",\"Godfather of Deep Learning\"],\"lastModified\":\"1761582298\",\"contentLength\":\"55292\",\"version\":\"1.0\",\"lastEditor\":\"system\",\"language\":\"en\",\"isRedirect\":false,\"redirectTarget\":\"\",\"isWithheld\":false},\"stats\":{\"totalViews\":\"759442\",\"recentViews\":\"759442\",\"dailyAvgViews\":25314.732421875,\"qualityScore\":1,\"lastViewed\":\"1761884013\"},\"linkedPages\":null},\"found\":true},\"dataUpdateCount\":1,\"dataUpdatedAt\":1761884013309,\"error\":null,\"errorUpdateCount\":0,\"errorUpdatedAt\":0,\"fetchFailureCount\":0,\"fetchFailureReason\":null,\"fetchMeta\":null,\"isInvalidated\":false,\"status\":\"success\",\"fetchStatus\":\"idle\"},\"queryKey\":[\"page\",\"Geoffrey_Hinton\"],\"queryHash\":\"[\\\"page\\\",\\\"Geoffrey_Hinton\\\"]\"}]},\"children\":\"$L20\"}]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"c:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Geoffrey Hinton\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning. Hinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978. As University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the...\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"system\"}],[\"$\",\"link\",\"3\",{\"rel\":\"manifest\",\"href\":\"/manifest.webmanifest\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"Geoff Hinton, Geoffrey E. Hinton, Godfather of AI, Godfather of Deep Learning\"}],[\"$\",\"meta\",\"5\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"6\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-snippet:-1\"}],[\"$\",\"link\",\"7\",{\"rel\":\"canonical\",\"href\":\"https://grokipedia.com/page/Geoffrey_Hinton\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:title\",\"content\":\"Geoffrey Hinton\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:description\",\"content\":\"Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning. Hinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978. As University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the...\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:url\",\"content\":\"https://grokipedia.com/page/Geoffrey_Hinton\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:site_name\",\"content\":\"Grokipedia\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:locale\",\"content\":\"en\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image:width\",\"content\":\"512\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:height\",\"content\":\"512\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:alt\",\"content\":\"Geoffrey Hinton\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:modified_time\",\"content\":\"1970-01-21T09:19:42.298Z\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:creator\",\"content\":\"@Grokipedia\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:title\",\"content\":\"Geoffrey Hinton\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:description\",\"content\":\"Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist and cognitive psychologist renowned for his pioneering contributions to artificial neural networks and deep learning. Hinton earned a BA in experimental psychology from the University of Cambridge in 1970 and a PhD in artificial intelligence from the University of Edinburgh in 1978. As University Professor Emeritus at the University of Toronto, he applied principles from statistical physics to develop the...\"}],[\"$\",\"meta\",\"23\",{\"name\":\"twitter:image\",\"content\":\"https://grokipedia.com/icon-512x512.png\"}],[\"$\",\"link\",\"24\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"$L21\",\"25\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"11:\"$c:metadata\"\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"22:I[61172,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"PageEditorProvider\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"23:I[63493,[\"8739\",\"static/chunks/63f0ec43-8ee6a76d70472249.js\",\"2254\",\"static/chunks/8208b75a-a48e5a4507a0de91.js\",\"4684\",\"static/chunks/24cf1b50-159cca90b09285e0.js\",\"1829\",\"static/chunks/9ffa21ba-c069766d809bd4c7.js\",\"7670\",\"static/chunks/7670-7326298c9856172b.js\",\"282\",\"static/chunks/282-691fffb366e24ca5.js\",\"7515\",\"static/chunks/7515-336759ef5dad2b52.js\",\"5497\",\"static/chunks/5497-ab85ef3ea59dd353.js\",\"7720\",\"static/chunks/7720-3a1e7e411adba2d3.js\",\"6281\",\"static/chunks/6281-c6e84786dade3614.js\",\"7086\",\"static/chunks/7086-1f1c4891d766e04f.js\",\"600\",\"static/chunks/600-9a9fcafaaa6c1c4c.js\",\"5002\",\"static/chunks/5002-9735c25beda556ba.js\",\"5448\",\"static/chunks/5448-2a3cfd853d899c9a.js\",\"5855\",\"static/chunks/5855-243eeca8f0e4cabd.js\",\"4393\",\"static/chunks/4393-1c8dff25ec904469.js\",\"9214\",\"static/chunks/9214-a10614844a67ba31.js\",\"8\",\"static/chunks/8-8ca70ca619d8e099.js\",\"4789\",\"static/chunks/4789-2080f6497f78b5b6.js\",\"6304\",\"static/chunks/app/page/%5Bslug%5D/page-540a27b6839afde5.js\"],\"default\"]\n"])</script><script nonce="YTIxYzFkYWUtNWRlNC00NTdkLTg0Y2UtYTZlNjlhMzk1NGVh">self.__next_f.push([1,"20:[\"$\",\"$L22\",null,{\"children\":[\"$\",\"$L23\",null,{\"slug\":\"Geoffrey_Hinton\"}]}]\n"])</script></body></html>